{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"CSV\");\n",
    "Pkg.add(\"Random\");\n",
    "Pkg.add(\"DataStructures\");\n",
    "Pkg.add(\"BenchmarkTools\");\n",
    "Pkg.add(\"DataFrames\");\n",
    "Pkg.add(\"Statistics\");\n",
    "Pkg.add(\"Dates\");\n",
    "Pkg.add(\"Gadfly\");\n",
    "Pkg.add(\"MLBase\");\n",
    "Pkg.add(\"DecisionTree\");\n",
    "Pkg.add(\"GLM\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, GLM, Statistics, Dates, Gadfly, Random, MLBase;\n",
    "include(\"utils/precipitation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ouvrages_surverse.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID_ouvrage, Latitude, Longitude, Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages = CSV.read(\"data/ouvrages-surverses.csv\");\n",
    "colnames = [\"N_Env\", \"ID_SOMA\", \"ID_OUVRAGE\", \"NOM\", \"SOMA_SEC\", \"REGION\", \"TP_X\", \"TP_Y\", \"TP_Z\", \"TP_LAT\", \"TP_LNG\", \"EMI_X\", \"EMI_Y\", \"EMI_LNG\", \"EMI_LAT\"];\n",
    "names!(ouvrages, Symbol.(colnames));\n",
    "select!(ouvrages, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing Z index with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages.TP_Z = coalesce.(ouvrages.TP_Z, mean(ouvrages[completecases(ouvrages), :].TP_Z));\n",
    "first(shuffleDf(ouvrages), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualtion des données chargées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages, x=:TP_Z, Geom.histogram(bincount=50), Guide.xlabel(\"Height of TropPlein\"),Guide.ylabel(\"Frequency\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages,x=:TP_LNG, y=:TP_LAT, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Surverses.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO_ouvrage, Date, Surverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\", missingstring=\"-99999\");\n",
    "\n",
    "first(shuffleDf(surverses),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter non rain surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raison = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "surverses[!,:RAISON] = raison;\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove missing data and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = dropmissing(surverses, disallowmissing=true);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "first(shuffleDf(surverses), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Precipitation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date, Heure, McTavish, Bellevue, Assomption, Trudeau, StHubert\n",
    "\n",
    "Contient toutes les données de précipitation des années 2013 à 2019 (train et test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and filter months between May & October included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitations, Symbol(\"St-Hubert\")=>:StHubert);\n",
    "\n",
    "precipitations = filter(row -> month(row.date) > 4, precipitations);\n",
    "precipitations = filter(row -> month(row.date) < 11, precipitations); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(precipitations),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing data by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD WAY\n",
    "\n",
    "#precipitation[!,:McTavish] = coalesce.(precipitation[:,:McTavish], 0);\n",
    "#precipitation[!,:Bellevue] = coalesce.(precipitation[:,:Bellevue], 0);\n",
    "#precipitation[!,:Assomption] = coalesce.(precipitation[:,:Assomption], 0);\n",
    "#precipitation[!,:Trudeau] = coalesce.(precipitation[:,:Trudeau], 0);\n",
    "#precipitation[!,:StHubert] = coalesce.(precipitation[:,:StHubert], 0);\n",
    "\n",
    "#first(shuffleDf(precipitation), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_by_day = by(precipitations, :date,  \n",
    "                            McTavish = :McTavish=>mean_wo_missing, \n",
    "                            Bellevue = :Bellevue=>mean_wo_missing, \n",
    "                            Assomption = :Assomption=>mean_wo_missing,\n",
    "                            Trudeau = :Trudeau=>mean_wo_missing,\n",
    "                            StHubert = :StHubert=>mean_wo_missing)\n",
    "\n",
    "for i=1:size(precipitations,1)\n",
    "    if isequal(precipitations[i, :McTavish], missing)\n",
    "        precipitations[i,:McTavish] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:McTavish][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Bellevue], missing)\n",
    "        precipitations[i,:Bellevue] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Bellevue][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Assomption], missing)\n",
    "        precipitations[i,:Assomption] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Assomption][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Trudeau], missing)\n",
    "        precipitations[i,:Trudeau] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Trudeau][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :StHubert], missing)\n",
    "        precipitations[i,:StHubert] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:StHubert][1]\n",
    "    end\n",
    "end\n",
    "\n",
    "first(shuffleDf(precipitations), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Precipitation aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of precipitation for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>sum, \n",
    "            Bellevue = :Bellevue=>sum,\n",
    "            Assomption = :Assomption=>sum, \n",
    "            Trudeau = :Trudeau=>sum, \n",
    "            StHubert = :StHubert=>sum);\n",
    "first(shuffleDf(pcp_sum), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation visuelle des données enregistrées des différentes stations. \n",
    "(C'est intéractif ! Vous pouvez choisir quelles distributions voir !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_sum\n",
    "df_for_plot = filter(row -> year(row.date) == 2018, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum precipitation in an hour for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>maximum,\n",
    "            Bellevue = :Bellevue=>maximum, \n",
    "            Assomption = :Assomption=>maximum,\n",
    "            Trudeau = :Trudeau=>maximum,\n",
    "            StHubert = :StHubert=>maximum)\n",
    "first(shuffleDf(pcp_max),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation visuelle des données enregistrées des différentes stations\n",
    "\n",
    "(C'est intéractif ! Vous pouvez choisir quelles distributions voir !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_max\n",
    "df_for_plot = filter(row -> year(row.date) == 2018, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum precipitation during three consecutive hours in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max3h = by(precipitations, :date,\n",
    "                McTavish = :McTavish=>maximum3,\n",
    "                Bellevue = :Bellevue=>maximum3,\n",
    "                Assomption = :Assomption=>maximum3,\n",
    "                Trudeau = :Trudeau=>maximum3,\n",
    "                StHubert = :StHubert=>maximum3)\n",
    "first(shuffleDf(pcp_max3h),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation visuelle des données enregistrées des différentes stations\n",
    "\n",
    "(C'est intéractif ! Vous pouvez choisir quelles distributions voir !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_max3h\n",
    "df_for_plot = filter(row -> year(row.date) == 2018, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of all three agregations for 1 meteo station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mct_sum = pcp_sum[:,[1,2]]\n",
    "rename!(mct_sum,:McTavish => :Sum);\n",
    "mct_sum = filter(row -> year(row.date) == 2018, mct_sum);\n",
    "\n",
    "mct_max = pcp_max[:,[1,2]]\n",
    "rename!(mct_max,:McTavish => :Max);\n",
    "mct_max = filter(row -> year(row.date) == 2018, mct_max);\n",
    "\n",
    "mct_max3h = pcp_max3h[:,[1,2]]\n",
    "rename!(mct_max3h,:McTavish => :Max3h);\n",
    "mct_max3h = filter(row -> year(row.date) == 2018, mct_max3h);\n",
    "\n",
    "df_for_plot = join(mct_sum, mct_max3h, on = :date);\n",
    "df_for_plot = join(df_for_plot, mct_max, on = :date);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = CSV.read(\"data/test.csv\"); #NO_OUVRAGE, DATE\n",
    "rename!(X_test, :NO_OUVRAGE => :ID_OUVRAGE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = join(ouvrages, X_test, on =:ID_OUVRAGE);\n",
    "features = join(ouvrages, surverses, on =:ID_OUVRAGE);\n",
    "first(shuffleDf(features), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_geo_plot = filter(row -> row.DATE == Date(2018,7,25), features)\n",
    "df_for_geo_plot[:SURVERSE] = convert(Array{Bool,1}, df_for_geo_plot[:SURVERSE])\n",
    "plot(df_for_geo_plot, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:SURVERSE, Guide.title(\"2018-07-25, état des surverses\"))\n",
    "#first(df_for_geo_plot,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add precipitation data to features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stations lat-lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = DataFrame(STATION = String[], LAT = Float64[], LNG = Float64[]);\n",
    "\n",
    "push!(station_df, [\"McTavish\", 45.504742, -73.579167]);\n",
    "push!(station_df, [\"Bellevue\", 45.427222, -73.929167]);\n",
    "push!(station_df, [\"Assomption\", 45.809444, -73.434722]);\n",
    "push!(station_df, [\"Trudeau\", 45.467778, -73.741667]);\n",
    "push!(station_df, [\"StHubert\", 45.5175, -73.416944]);\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add pcp_sum, pcp_max, pcp_max3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function addColsForPrecipationPerDay(df)\n",
    "    df[!, :PCP_SUM] = zeros(size(df, 1));\n",
    "    df[!, :PCP_MAX] = zeros(size(df, 1));\n",
    "    df[!, :PCP_MAX3] = zeros(size(df, 1));\n",
    "    df[!, :METEO] = fill(\"\", size(df, 1));\n",
    "    return df\n",
    "end\n",
    "\n",
    "X_test = addColsForPrecipationPerDay(X_test)\n",
    "permutecols!(X_test, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3]);\n",
    "    \n",
    "features = addColsForPrecipationPerDay(features)\n",
    "permutecols!(features, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3, :SURVERSE]);\n",
    "\n",
    "first(shuffleDf(features), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find closest station to each ouvrage and add pcp_sum and pcp_max to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fillPrecipitationWithClosestMeteoStation(df)\n",
    "    for i=1:size(df, 1)\n",
    "        id_ouvrage = df[i, 1]; \n",
    "        closest_station = \"McTavish\"; # initial value\n",
    "        shortest_dist = -1;\n",
    "\n",
    "        # Find closest station\n",
    "        for j=1:size(station_df, 1)\n",
    "            dist = findDistance(df[i, :TP_LAT], df[i, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "\n",
    "            if shortest_dist == -1 || dist < shortest_dist\n",
    "                shortest_dist = dist;\n",
    "                closest_station = station_df[j, :STATION];\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Augment comb with a weighted p_sum, based on the distance to the station\n",
    "        p_sum = pcp_sum[∈([df[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "    #     comb[i, :PCP_SUM] = p_sum[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_SUM] = p_sum[1]; \n",
    "\n",
    "        # Augment comb with a weighted p_max, based on the distance to the station\n",
    "        p_max = pcp_max[∈([df[i, :DATE]]).(pcp_max.date), Symbol(closest_station)]\n",
    "    #     comb[i, :PCP_MAX] = p_max[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_MAX] = p_max[1];\n",
    "\n",
    "        # Augment comb with a weighted p_max3h, based on the distance to the station\n",
    "        p_max3 = pcp_max3h[∈([df[i, :DATE]]).(pcp_max3h.date), Symbol(closest_station)]\n",
    "    #     comb[i, :PCP_MAX3] = p_max3[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_MAX3] = p_max3[1]; \n",
    "\n",
    "        df[i, :METEO] = closest_station\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = fillPrecipitationWithClosestMeteoStation(X_test)\n",
    "features = fillPrecipitationWithClosestMeteoStation(features)\n",
    "first(shuffleDf(features), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outlier in PCP_SUM and PCP_MAX AND PCP_MAX3 that cause compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "X_test[X_test[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "X_test[X_test[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;\n",
    "\n",
    "features[features[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "features[features[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "features[features[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;\n",
    "\n",
    "# first(shuffleDf(filter(row -> row.SURVERSE == 1, features)), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP location colored by their affiliation to its closest meteo station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_geo_plot = filter(row -> row.DATE == Date(2018,7,25), features)\n",
    "df_for_geo_plot[:SURVERSE] = convert(Array{Bool,1}, df_for_geo_plot[:SURVERSE])\n",
    "plot(df_for_geo_plot, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:METEO, Guide.title(\"2018-07-25, Regroupement par station météo\"))\n",
    "#first(df_for_geo_plot,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouvrage 3350-07D for 2018, when it overflow and quantity based on max3h rain fallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3260-01D dans Rivière-des-Prairies\n",
    "# 3350-07D dans Ahunstic\n",
    "# 4240-01D dans Pointe-aux-Trembles\n",
    "# 4350-01D dans le Vieux-Montréal\n",
    "# 4380-01D dans Verdun\n",
    "\n",
    "id_ouvrage_to_show = \"3350-07D\"\n",
    "df_temp = filter(row -> row.ID_OUVRAGE ∈ [id_ouvrage_to_show], features)\n",
    "df_temp = filter(row -> year(row.DATE) == 2018, df_temp);\n",
    "df_temp = df_temp[!,[:ID_OUVRAGE, :DATE, :PCP_MAX3, :SURVERSE]]\n",
    "df_temp[:SURVERSE] = convert(Array{Bool,1}, df_temp[:SURVERSE])\n",
    "\n",
    "\n",
    "\n",
    "plot(df_temp, x=:DATE, y=:PCP_MAX3, Geom.point, color=:SURVERSE,Guide.title(id_ouvrage_to_show))\n",
    "#first(shuffleDf(df_temp), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dates into months and days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function splitDateByMonthAndDay(df)\n",
    "    df[!,:MONTH] = month.(df.DATE);\n",
    "    df[!,:DAY] = month.(df.DATE);\n",
    "    return df\n",
    "end\n",
    "\n",
    "X_test = splitDateByMonthAndDay(X_test)\n",
    "features = splitDateByMonthAndDay(features)\n",
    "first(shuffleDf(features[!, [:DATE, :MONTH, :DAY]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataframes into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function partitionTrainTest(data, at = 0.8) # https://discourse.julialang.org/t/simple-tool-for-train-test-split/473/2\n",
    "    n = nrow(data)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return data[train_idx,:], data[test_idx,:]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standarizeTrainTestCol(X_train, X_test, col)\n",
    "    mean_train_col = mean(X_train[!, col]);\n",
    "    std_train_col = std(X_train[!, col]);\n",
    "    X_train[!, col] = (X_train[!, col] .- mean_train_col) ./ std_train_col;\n",
    "    X_test[!, col] = (X_test[!, col] .- mean_train_col) ./ std_train_col;\n",
    "    \n",
    "    return X_train, X_test\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Standardize the PCP and Date before splitting into X_train and X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = filter(row-> year(row.DATE) .< 2019, features)\n",
    "\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_LAT)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_LNG)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_Z)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_SUM)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_MAX)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_MAX3)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :MONTH)\n",
    "X_train_all, X_test = standarizeTrainTestCol(X_train, X_test, :DAY)\n",
    "\n",
    "X_train, X_val = partitionTrainTest(X_train_all, 0.8)\n",
    "\n",
    "first(shuffleDf(X_train),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(X_test),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(X_val),5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
