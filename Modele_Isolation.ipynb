{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, GLM, Statistics, Dates, Gadfly, Random, MLBase, DecisionTree;\n",
    "include(\"utils/precipitation.jl\");\n",
    "include(\"utils/random-forest.jl\");\n",
    "include(\"utils/reg-log.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_soumission = 19;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partitionTrainTest (generic function with 2 methods)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function partitionTrainTest(data, at = 0.8) # https://discourse.julialang.org/t/simple-tool-for-train-test-split/473/2\n",
    "    n = nrow(data)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return data[train_idx,:], data[test_idx,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_form = @formula(SURVERSE ~ McTavish_sum + McTavish_max3 + \n",
    "                               Bellevue_sum + Bellevue_max3 + \n",
    "                               Assomption_sum + Assomption_max3 + \n",
    "                               Trudeau_sum + Trudeau_max3 + \n",
    "                               StHubert_sum + StHubert_max3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ft = [:McTavish_sum, :McTavish_max, :McTavish_max3,\n",
    "            :Bellevue_sum, :Bellevue_max, :Bellevue_max3,\n",
    "            :Assomption_sum, :Assomption_max, :Assomption_max3,\n",
    "            :Trudeau_sum, :Trudeau_max, :Trudeau_max3,\n",
    "            :StHubert_sum, :StHubert_max, :StHubert_max3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>param</th><th>min</th><th>max</th><th>step</th></tr><tr><th></th><th>String</th><th>Int8</th><th>Int8</th><th>Int8</th></tr></thead><tbody><p>4 rows × 4 columns</p><tr><th>1</th><td>nft</td><td>3</td><td>7</td><td>1</td></tr><tr><th>2</th><td>ntrees</td><td>75</td><td>120</td><td>15</td></tr><tr><th>3</th><td>podata</td><td>75</td><td>95</td><td>5</td></tr><tr><th>4</th><td>maxd</td><td>5</td><td>12</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& param & min & max & step\\\\\n",
       "\t\\hline\n",
       "\t& String & Int8 & Int8 & Int8\\\\\n",
       "\t\\hline\n",
       "\t1 & nft & 3 & 7 & 1 \\\\\n",
       "\t2 & ntrees & 75 & 120 & 15 \\\\\n",
       "\t3 & podata & 75 & 95 & 5 \\\\\n",
       "\t4 & maxd & 5 & 12 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "4×4 DataFrame\n",
       "│ Row │ param  │ min  │ max  │ step │\n",
       "│     │ \u001b[90mString\u001b[39m │ \u001b[90mInt8\u001b[39m │ \u001b[90mInt8\u001b[39m │ \u001b[90mInt8\u001b[39m │\n",
       "├─────┼────────┼──────┼──────┼──────┤\n",
       "│ 1   │ nft    │ 3    │ 7    │ 1    │\n",
       "│ 2   │ ntrees │ 75   │ 120  │ 15   │\n",
       "│ 3   │ podata │ 75   │ 95   │ 5    │\n",
       "│ 4   │ maxd   │ 5    │ 12   │ 1    │"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rf = DataFrame(param=String[], min=Int8[], max=Int8[], step=Int8[]);\n",
    "\n",
    "push!(params_rf, [\"nft\", 3, 7, 1]);\n",
    "push!(params_rf, [\"ntrees\", 75, 120, 15]);\n",
    "push!(params_rf, [\"podata\", 75, 95, 5]);\n",
    "push!(params_rf, [\"maxd\", 5, 12, 1]);\n",
    "\n",
    "params_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 3260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 17)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_3260.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65, 0.6666666666666666)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[3, 75, 90, 7], 0.6862745098039216)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.6896551724137931)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 16)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_3260.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 3260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>McTavish_sum</th><th>Bellevue_sum</th><th>Assomption_sum</th><th>Trudeau_sum</th><th>StHubert_sum</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 7 columns</p><tr><th>1</th><td>2019-05-02</td><td>0</td><td>26.0</td><td>19.0</td><td>15.0</td><td>13.0</td><td>17.0</td></tr><tr><th>2</th><td>2019-05-09</td><td>0</td><td>89.0</td><td>67.0</td><td>77.0</td><td>86.0</td><td>67.0</td></tr><tr><th>3</th><td>2019-05-10</td><td>1</td><td>385.0</td><td>265.0</td><td>286.0</td><td>285.0</td><td>316.0</td></tr><tr><th>4</th><td>2019-05-15</td><td>0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>2019-05-20</td><td>0</td><td>46.0</td><td>5.0</td><td>49.0</td><td>53.0</td><td>50.0</td></tr><tr><th>6</th><td>2019-05-23</td><td>0</td><td>182.0</td><td>0.0</td><td>351.0</td><td>159.0</td><td>213.0</td></tr><tr><th>7</th><td>2019-05-24</td><td>0</td><td>13.0</td><td>0.0</td><td>22.0</td><td>15.0</td><td>14.0</td></tr><tr><th>8</th><td>2019-05-26</td><td>0</td><td>3.0</td><td>0.0</td><td>21.0</td><td>5.0</td><td>7.0</td></tr><tr><th>9</th><td>2019-05-30</td><td>0</td><td>7.0</td><td>0.0</td><td>13.0</td><td>12.0</td><td>10.0</td></tr><tr><th>10</th><td>2019-06-02</td><td>0</td><td>93.0</td><td>0.0</td><td>62.0</td><td>68.0</td><td>62.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& DATE & SURVERSE & McTavish\\_sum & Bellevue\\_sum & Assomption\\_sum & Trudeau\\_sum & StHubert\\_sum\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-02 & 0 & 26.0 & 19.0 & 15.0 & 13.0 & 17.0 \\\\\n",
       "\t2 & 2019-05-09 & 0 & 89.0 & 67.0 & 77.0 & 86.0 & 67.0 \\\\\n",
       "\t3 & 2019-05-10 & 1 & 385.0 & 265.0 & 286.0 & 285.0 & 316.0 \\\\\n",
       "\t4 & 2019-05-15 & 0 & 2.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 2019-05-20 & 0 & 46.0 & 5.0 & 49.0 & 53.0 & 50.0 \\\\\n",
       "\t6 & 2019-05-23 & 0 & 182.0 & 0.0 & 351.0 & 159.0 & 213.0 \\\\\n",
       "\t7 & 2019-05-24 & 0 & 13.0 & 0.0 & 22.0 & 15.0 & 14.0 \\\\\n",
       "\t8 & 2019-05-26 & 0 & 3.0 & 0.0 & 21.0 & 5.0 & 7.0 \\\\\n",
       "\t9 & 2019-05-30 & 0 & 7.0 & 0.0 & 13.0 & 12.0 & 10.0 \\\\\n",
       "\t10 & 2019-06-02 & 0 & 93.0 & 0.0 & 62.0 & 68.0 & 62.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×7 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ DATE       │ SURVERSE │ McTavish_sum │ Bellevue_sum │ Assomption_sum │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m        │\n",
       "├─────┼────────────┼──────────┼──────────────┼──────────────┼────────────────┤\n",
       "│ 1   │ 2019-05-02 │ 0        │ 26.0         │ 19.0         │ 15.0           │\n",
       "│ 2   │ 2019-05-09 │ 0        │ 89.0         │ 67.0         │ 77.0           │\n",
       "│ 3   │ 2019-05-10 │ 1        │ 385.0        │ 265.0        │ 286.0          │\n",
       "│ 4   │ 2019-05-15 │ 0        │ 2.0          │ 0.0          │ 0.0            │\n",
       "│ 5   │ 2019-05-20 │ 0        │ 46.0         │ 5.0          │ 49.0           │\n",
       "│ 6   │ 2019-05-23 │ 0        │ 182.0        │ 0.0          │ 351.0          │\n",
       "│ 7   │ 2019-05-24 │ 0        │ 13.0         │ 0.0          │ 22.0           │\n",
       "│ 8   │ 2019-05-26 │ 0        │ 3.0          │ 0.0          │ 21.0           │\n",
       "│ 9   │ 2019-05-30 │ 0        │ 7.0          │ 0.0          │ 13.0           │\n",
       "│ 10  │ 2019-06-02 │ 0        │ 93.0         │ 0.0          │ 62.0           │"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3260 = test_set;\n",
    "pred_3260[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :McTavish_sum, :Bellevue_sum, :Assomption_sum, :Trudeau_sum, :StHubert_sum];\n",
    "first(pred_3260[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 17)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_3350.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.8253968253968254)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[7, 90, 90, 9], 0.8333333333333334)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.8333333333333334)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 16)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_3350.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>McTavish_sum</th><th>Bellevue_sum</th><th>Assomption_sum</th><th>Trudeau_sum</th><th>StHubert_sum</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 7 columns</p><tr><th>1</th><td>2019-05-01</td><td>1</td><td>79.0</td><td>52.0</td><td>58.0</td><td>47.0</td><td>68.0</td></tr><tr><th>2</th><td>2019-05-02</td><td>0</td><td>26.0</td><td>19.0</td><td>15.0</td><td>13.0</td><td>17.0</td></tr><tr><th>3</th><td>2019-05-08</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>2019-05-09</td><td>1</td><td>89.0</td><td>67.0</td><td>77.0</td><td>86.0</td><td>67.0</td></tr><tr><th>5</th><td>2019-05-10</td><td>1</td><td>385.0</td><td>265.0</td><td>286.0</td><td>285.0</td><td>316.0</td></tr><tr><th>6</th><td>2019-05-11</td><td>0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>2019-05-13</td><td>0</td><td>18.0</td><td>22.0</td><td>0.0</td><td>9.0</td><td>5.0</td></tr><tr><th>8</th><td>2019-05-14</td><td>1</td><td>95.0</td><td>130.0</td><td>62.0</td><td>104.0</td><td>84.0</td></tr><tr><th>9</th><td>2019-05-18</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td></tr><tr><th>10</th><td>2019-05-19</td><td>1</td><td>65.0</td><td>56.0</td><td>37.0</td><td>57.0</td><td>62.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& DATE & SURVERSE & McTavish\\_sum & Bellevue\\_sum & Assomption\\_sum & Trudeau\\_sum & StHubert\\_sum\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 1 & 79.0 & 52.0 & 58.0 & 47.0 & 68.0 \\\\\n",
       "\t2 & 2019-05-02 & 0 & 26.0 & 19.0 & 15.0 & 13.0 & 17.0 \\\\\n",
       "\t3 & 2019-05-08 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 2019-05-09 & 1 & 89.0 & 67.0 & 77.0 & 86.0 & 67.0 \\\\\n",
       "\t5 & 2019-05-10 & 1 & 385.0 & 265.0 & 286.0 & 285.0 & 316.0 \\\\\n",
       "\t6 & 2019-05-11 & 0 & 2.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 2019-05-13 & 0 & 18.0 & 22.0 & 0.0 & 9.0 & 5.0 \\\\\n",
       "\t8 & 2019-05-14 & 1 & 95.0 & 130.0 & 62.0 & 104.0 & 84.0 \\\\\n",
       "\t9 & 2019-05-18 & 0 & 0.0 & 0.0 & 0.0 & 2.0 & 0.0 \\\\\n",
       "\t10 & 2019-05-19 & 1 & 65.0 & 56.0 & 37.0 & 57.0 & 62.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×7 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ DATE       │ SURVERSE │ McTavish_sum │ Bellevue_sum │ Assomption_sum │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m        │\n",
       "├─────┼────────────┼──────────┼──────────────┼──────────────┼────────────────┤\n",
       "│ 1   │ 2019-05-01 │ 1        │ 79.0         │ 52.0         │ 58.0           │\n",
       "│ 2   │ 2019-05-02 │ 0        │ 26.0         │ 19.0         │ 15.0           │\n",
       "│ 3   │ 2019-05-08 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 4   │ 2019-05-09 │ 1        │ 89.0         │ 67.0         │ 77.0           │\n",
       "│ 5   │ 2019-05-10 │ 1        │ 385.0        │ 265.0        │ 286.0          │\n",
       "│ 6   │ 2019-05-11 │ 0        │ 2.0          │ 0.0          │ 0.0            │\n",
       "│ 7   │ 2019-05-13 │ 0        │ 18.0         │ 22.0         │ 0.0            │\n",
       "│ 8   │ 2019-05-14 │ 1        │ 95.0         │ 130.0        │ 62.0           │\n",
       "│ 9   │ 2019-05-18 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 10  │ 2019-05-19 │ 1        │ 65.0         │ 56.0         │ 37.0           │"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3350 = test_set;\n",
    "pred_3350[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :McTavish_sum, :Bellevue_sum, :Assomption_sum, :Trudeau_sum, :StHubert_sum];\n",
    "first(pred_3350[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 17)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_4240.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.7272727272727273)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[3, 75, 80, 9], 0.8)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.7619047619047619)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 16)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4240.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>McTavish_sum</th><th>Bellevue_sum</th><th>Assomption_sum</th><th>Trudeau_sum</th><th>StHubert_sum</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 7 columns</p><tr><th>1</th><td>2019-05-07</td><td>0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>2019-05-09</td><td>0</td><td>89.0</td><td>67.0</td><td>77.0</td><td>86.0</td><td>67.0</td></tr><tr><th>3</th><td>2019-05-10</td><td>1</td><td>385.0</td><td>265.0</td><td>286.0</td><td>285.0</td><td>316.0</td></tr><tr><th>4</th><td>2019-05-15</td><td>0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>2019-05-21</td><td>0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>2.0</td><td>0.0</td></tr><tr><th>6</th><td>2019-05-22</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td></tr><tr><th>7</th><td>2019-05-23</td><td>0</td><td>182.0</td><td>0.0</td><td>351.0</td><td>159.0</td><td>213.0</td></tr><tr><th>8</th><td>2019-05-24</td><td>0</td><td>13.0</td><td>0.0</td><td>22.0</td><td>15.0</td><td>14.0</td></tr><tr><th>9</th><td>2019-05-25</td><td>0</td><td>0.0</td><td>0.0</td><td>7.0</td><td>4.0</td><td>6.0</td></tr><tr><th>10</th><td>2019-06-01</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& DATE & SURVERSE & McTavish\\_sum & Bellevue\\_sum & Assomption\\_sum & Trudeau\\_sum & StHubert\\_sum\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-07 & 0 & 3.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t2 & 2019-05-09 & 0 & 89.0 & 67.0 & 77.0 & 86.0 & 67.0 \\\\\n",
       "\t3 & 2019-05-10 & 1 & 385.0 & 265.0 & 286.0 & 285.0 & 316.0 \\\\\n",
       "\t4 & 2019-05-15 & 0 & 2.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 2019-05-21 & 0 & 0.0 & 0.0 & 3.0 & 2.0 & 0.0 \\\\\n",
       "\t6 & 2019-05-22 & 0 & 0.0 & 0.0 & 0.0 & 2.0 & 0.0 \\\\\n",
       "\t7 & 2019-05-23 & 0 & 182.0 & 0.0 & 351.0 & 159.0 & 213.0 \\\\\n",
       "\t8 & 2019-05-24 & 0 & 13.0 & 0.0 & 22.0 & 15.0 & 14.0 \\\\\n",
       "\t9 & 2019-05-25 & 0 & 0.0 & 0.0 & 7.0 & 4.0 & 6.0 \\\\\n",
       "\t10 & 2019-06-01 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×7 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ DATE       │ SURVERSE │ McTavish_sum │ Bellevue_sum │ Assomption_sum │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m        │\n",
       "├─────┼────────────┼──────────┼──────────────┼──────────────┼────────────────┤\n",
       "│ 1   │ 2019-05-07 │ 0        │ 3.0          │ 0.0          │ 0.0            │\n",
       "│ 2   │ 2019-05-09 │ 0        │ 89.0         │ 67.0         │ 77.0           │\n",
       "│ 3   │ 2019-05-10 │ 1        │ 385.0        │ 265.0        │ 286.0          │\n",
       "│ 4   │ 2019-05-15 │ 0        │ 2.0          │ 0.0          │ 0.0            │\n",
       "│ 5   │ 2019-05-21 │ 0        │ 0.0          │ 0.0          │ 3.0            │\n",
       "│ 6   │ 2019-05-22 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 7   │ 2019-05-23 │ 0        │ 182.0        │ 0.0          │ 351.0          │\n",
       "│ 8   │ 2019-05-24 │ 0        │ 13.0         │ 0.0          │ 22.0           │\n",
       "│ 9   │ 2019-05-25 │ 0        │ 0.0          │ 0.0          │ 7.0            │\n",
       "│ 10  │ 2019-06-01 │ 0        │ 0.0          │ 0.0          │ 0.0            │"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4240 = test_set;\n",
    "pred_4240[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :McTavish_sum, :Bellevue_sum, :Assomption_sum, :Trudeau_sum, :StHubert_sum];\n",
    "first(pred_4240[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 17)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_4350.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.7058823529411765)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[4, 105, 80, 7], 0.7017543859649122)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.7058823529411765)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 16)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4350.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>McTavish_sum</th><th>Bellevue_sum</th><th>Assomption_sum</th><th>Trudeau_sum</th><th>StHubert_sum</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 7 columns</p><tr><th>1</th><td>2019-05-03</td><td>0</td><td>34.0</td><td>27.0</td><td>34.0</td><td>31.0</td><td>44.0</td></tr><tr><th>2</th><td>2019-05-04</td><td>0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td></tr><tr><th>3</th><td>2019-05-07</td><td>0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>2019-05-08</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>2019-05-10</td><td>1</td><td>385.0</td><td>265.0</td><td>286.0</td><td>285.0</td><td>316.0</td></tr><tr><th>6</th><td>2019-05-11</td><td>0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>2019-05-12</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>2019-05-21</td><td>0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>2.0</td><td>0.0</td></tr><tr><th>9</th><td>2019-05-22</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td></tr><tr><th>10</th><td>2019-05-23</td><td>0</td><td>182.0</td><td>0.0</td><td>351.0</td><td>159.0</td><td>213.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& DATE & SURVERSE & McTavish\\_sum & Bellevue\\_sum & Assomption\\_sum & Trudeau\\_sum & StHubert\\_sum\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-03 & 0 & 34.0 & 27.0 & 34.0 & 31.0 & 44.0 \\\\\n",
       "\t2 & 2019-05-04 & 0 & 2.0 & 0.0 & 0.0 & 2.0 & 0.0 \\\\\n",
       "\t3 & 2019-05-07 & 0 & 3.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 2019-05-08 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 2019-05-10 & 1 & 385.0 & 265.0 & 286.0 & 285.0 & 316.0 \\\\\n",
       "\t6 & 2019-05-11 & 0 & 2.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 2019-05-12 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t8 & 2019-05-21 & 0 & 0.0 & 0.0 & 3.0 & 2.0 & 0.0 \\\\\n",
       "\t9 & 2019-05-22 & 0 & 0.0 & 0.0 & 0.0 & 2.0 & 0.0 \\\\\n",
       "\t10 & 2019-05-23 & 0 & 182.0 & 0.0 & 351.0 & 159.0 & 213.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×7 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ DATE       │ SURVERSE │ McTavish_sum │ Bellevue_sum │ Assomption_sum │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m        │\n",
       "├─────┼────────────┼──────────┼──────────────┼──────────────┼────────────────┤\n",
       "│ 1   │ 2019-05-03 │ 0        │ 34.0         │ 27.0         │ 34.0           │\n",
       "│ 2   │ 2019-05-04 │ 0        │ 2.0          │ 0.0          │ 0.0            │\n",
       "│ 3   │ 2019-05-07 │ 0        │ 3.0          │ 0.0          │ 0.0            │\n",
       "│ 4   │ 2019-05-08 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 5   │ 2019-05-10 │ 1        │ 385.0        │ 265.0        │ 286.0          │\n",
       "│ 6   │ 2019-05-11 │ 0        │ 2.0          │ 0.0          │ 0.0            │\n",
       "│ 7   │ 2019-05-12 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 8   │ 2019-05-21 │ 0        │ 0.0          │ 0.0          │ 3.0            │\n",
       "│ 9   │ 2019-05-22 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 10  │ 2019-05-23 │ 0        │ 182.0        │ 0.0          │ 351.0          │"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4350 = test_set;\n",
    "pred_4350[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :McTavish_sum, :Bellevue_sum, :Assomption_sum, :Trudeau_sum, :StHubert_sum];\n",
    "first(pred_4350[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 17)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_4380.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65, 0.6086956521739131)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[3, 75, 90, 7], 0.7459770114942528)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.6666666666666666)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 16)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4380.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>McTavish_sum</th><th>Bellevue_sum</th><th>Assomption_sum</th><th>Trudeau_sum</th><th>StHubert_sum</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 7 columns</p><tr><th>1</th><td>2019-05-02</td><td>0</td><td>26.0</td><td>19.0</td><td>15.0</td><td>13.0</td><td>17.0</td></tr><tr><th>2</th><td>2019-05-04</td><td>0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td></tr><tr><th>3</th><td>2019-05-05</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>2019-05-06</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>2019-05-08</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>2019-05-09</td><td>0</td><td>89.0</td><td>67.0</td><td>77.0</td><td>86.0</td><td>67.0</td></tr><tr><th>7</th><td>2019-05-10</td><td>1</td><td>385.0</td><td>265.0</td><td>286.0</td><td>285.0</td><td>316.0</td></tr><tr><th>8</th><td>2019-05-17</td><td>0</td><td>5.0</td><td>11.0</td><td>0.0</td><td>3.0</td><td>5.0</td></tr><tr><th>9</th><td>2019-05-18</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td></tr><tr><th>10</th><td>2019-05-28</td><td>0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>15.0</td><td>10.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& DATE & SURVERSE & McTavish\\_sum & Bellevue\\_sum & Assomption\\_sum & Trudeau\\_sum & StHubert\\_sum\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-02 & 0 & 26.0 & 19.0 & 15.0 & 13.0 & 17.0 \\\\\n",
       "\t2 & 2019-05-04 & 0 & 2.0 & 0.0 & 0.0 & 2.0 & 0.0 \\\\\n",
       "\t3 & 2019-05-05 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 2019-05-06 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 2019-05-08 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t6 & 2019-05-09 & 0 & 89.0 & 67.0 & 77.0 & 86.0 & 67.0 \\\\\n",
       "\t7 & 2019-05-10 & 1 & 385.0 & 265.0 & 286.0 & 285.0 & 316.0 \\\\\n",
       "\t8 & 2019-05-17 & 0 & 5.0 & 11.0 & 0.0 & 3.0 & 5.0 \\\\\n",
       "\t9 & 2019-05-18 & 0 & 0.0 & 0.0 & 0.0 & 2.0 & 0.0 \\\\\n",
       "\t10 & 2019-05-28 & 0 & 3.0 & 0.0 & 0.0 & 15.0 & 10.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×7 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ DATE       │ SURVERSE │ McTavish_sum │ Bellevue_sum │ Assomption_sum │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m        │\n",
       "├─────┼────────────┼──────────┼──────────────┼──────────────┼────────────────┤\n",
       "│ 1   │ 2019-05-02 │ 0        │ 26.0         │ 19.0         │ 15.0           │\n",
       "│ 2   │ 2019-05-04 │ 0        │ 2.0          │ 0.0          │ 0.0            │\n",
       "│ 3   │ 2019-05-05 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 4   │ 2019-05-06 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 5   │ 2019-05-08 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 6   │ 2019-05-09 │ 0        │ 89.0         │ 67.0         │ 77.0           │\n",
       "│ 7   │ 2019-05-10 │ 1        │ 385.0        │ 265.0        │ 286.0          │\n",
       "│ 8   │ 2019-05-17 │ 0        │ 5.0          │ 11.0         │ 0.0            │\n",
       "│ 9   │ 2019-05-18 │ 0        │ 0.0          │ 0.0          │ 0.0            │\n",
       "│ 10  │ 2019-05-28 │ 0        │ 3.0          │ 0.0          │ 0.0            │"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4380 = test_set;\n",
    "pred_4380[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :McTavish_sum, :Bellevue_sum, :Assomption_sum, :Trudeau_sum, :StHubert_sum];\n",
    "first(pred_4380[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 3)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/test.csv\");\n",
    "test_set[!, :SURVERSE] = zeros(size(test_set, 1));\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque ligne de test_set\n",
    "\n",
    "    - On check l'ID de l'ouvrage pour savoir quel prediction load\n",
    "    - On va chercher la prediction à telle date pour cet ouvrage\n",
    "    - On le met à la ligne courante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(test_set, 1)\n",
    "    curr_ouvrage = test_set[i, 1];\n",
    "    pred_to_use = nothing;\n",
    "    if curr_ouvrage == \"3260-01D\"\n",
    "        pred_to_use = pred_3260;\n",
    "    elseif curr_ouvrage == \"3350-07D\"\n",
    "        pred_to_use = pred_3350;\n",
    "    elseif curr_ouvrage == \"4240-01D\"\n",
    "        pred_to_use = pred_4240;\n",
    "    elseif curr_ouvrage == \"4350-01D\"\n",
    "        pred_to_use = pred_4350;\n",
    "    elseif curr_ouvrage == \"4380-01D\"\n",
    "        pred_to_use = pred_4380;\n",
    "    end\n",
    "    \n",
    "    curr_date = test_set[i, :DATE];\n",
    "    pred_res = filter(row -> row.DATE == curr_date, pred_to_use);\n",
    "    \n",
    "    test_set[i, :SURVERSE] = pred_res[1, :SURVERSE];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>10 rows × 3 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-05-02</td><td>0</td></tr><tr><th>2</th><td>3260-01D</td><td>2019-05-09</td><td>0</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-05-10</td><td>1</td></tr><tr><th>4</th><td>3260-01D</td><td>2019-05-15</td><td>0</td></tr><tr><th>5</th><td>3260-01D</td><td>2019-05-20</td><td>0</td></tr><tr><th>6</th><td>3260-01D</td><td>2019-05-23</td><td>0</td></tr><tr><th>7</th><td>3260-01D</td><td>2019-05-24</td><td>0</td></tr><tr><th>8</th><td>3260-01D</td><td>2019-05-26</td><td>0</td></tr><tr><th>9</th><td>3260-01D</td><td>2019-05-30</td><td>0</td></tr><tr><th>10</th><td>3350-07D</td><td>2019-05-01</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-05-02 & 0 \\\\\n",
       "\t2 & 3260-01D & 2019-05-09 & 0 \\\\\n",
       "\t3 & 3260-01D & 2019-05-10 & 1 \\\\\n",
       "\t4 & 3260-01D & 2019-05-15 & 0 \\\\\n",
       "\t5 & 3260-01D & 2019-05-20 & 0 \\\\\n",
       "\t6 & 3260-01D & 2019-05-23 & 0 \\\\\n",
       "\t7 & 3260-01D & 2019-05-24 & 0 \\\\\n",
       "\t8 & 3260-01D & 2019-05-26 & 0 \\\\\n",
       "\t9 & 3260-01D & 2019-05-30 & 0 \\\\\n",
       "\t10 & 3350-07D & 2019-05-01 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-05-02 │ 0        │\n",
       "│ 2   │ 3260-01D   │ 2019-05-09 │ 0        │\n",
       "│ 3   │ 3260-01D   │ 2019-05-10 │ 1        │\n",
       "│ 4   │ 3260-01D   │ 2019-05-15 │ 0        │\n",
       "│ 5   │ 3260-01D   │ 2019-05-20 │ 0        │\n",
       "│ 6   │ 3260-01D   │ 2019-05-23 │ 0        │\n",
       "│ 7   │ 3260-01D   │ 2019-05-24 │ 0        │\n",
       "│ 8   │ 3260-01D   │ 2019-05-26 │ 0        │\n",
       "│ 9   │ 3260-01D   │ 2019-05-30 │ 0        │\n",
       "│ 10  │ 3350-07D   │ 2019-05-01 │ 1        │"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[!, :SURVERSE] = convert(Array{Int}, test_set[!, :SURVERSE]);\n",
    "first(test_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"submissions/mc-submission-19.csv\""
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = test_set[:,:NO_OUVRAGE].*\"_\".*string.(test_set[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=test_set[:, :SURVERSE])\n",
    "CSV.write(\"submissions/mc-submission-$(no_soumission).csv\",sampleSubmission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
