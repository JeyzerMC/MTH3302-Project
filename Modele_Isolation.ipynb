{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading DataFrames support into Gadfly.jl\n",
      "└ @ Gadfly /home/chaime/.julia/packages/Gadfly/09PWZ/src/mapping.jl:228\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, GLM, Statistics, Dates, Gadfly, Random, MLBase, DecisionTree;\n",
    "include(\"utils/precipitation.jl\");\n",
    "include(\"utils/random-forest.jl\");\n",
    "include(\"utils/reg-log.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_soumission = 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partitionTrainTest (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function partitionTrainTest(data, at = 0.8) # https://discourse.julialang.org/t/simple-tool-for-train-test-split/473/2\n",
    "    n = nrow(data)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return data[train_idx,:], data[test_idx,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_form = @formula(SURVERSE ~ FS_sum + FS_max3 + \n",
    "                               SS_sum + SS_max3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ft = [:FS_sum, :FS_max, :FS_max3,\n",
    "            :SS_sum, :SS_max, :SS_max3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>param</th><th>min</th><th>max</th><th>step</th></tr><tr><th></th><th>String</th><th>Int8</th><th>Int8</th><th>Int8</th></tr></thead><tbody><p>4 rows × 4 columns</p><tr><th>1</th><td>nft</td><td>2</td><td>6</td><td>1</td></tr><tr><th>2</th><td>ntrees</td><td>20</td><td>50</td><td>10</td></tr><tr><th>3</th><td>podata</td><td>75</td><td>95</td><td>5</td></tr><tr><th>4</th><td>maxd</td><td>5</td><td>12</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& param & min & max & step\\\\\n",
       "\t\\hline\n",
       "\t& String & Int8 & Int8 & Int8\\\\\n",
       "\t\\hline\n",
       "\t1 & nft & 2 & 6 & 1 \\\\\n",
       "\t2 & ntrees & 20 & 50 & 10 \\\\\n",
       "\t3 & podata & 75 & 95 & 5 \\\\\n",
       "\t4 & maxd & 5 & 12 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "4×4 DataFrame\n",
       "│ Row │ param  │ min  │ max  │ step │\n",
       "│     │ \u001b[90mString\u001b[39m │ \u001b[90mInt8\u001b[39m │ \u001b[90mInt8\u001b[39m │ \u001b[90mInt8\u001b[39m │\n",
       "├─────┼────────┼──────┼──────┼──────┤\n",
       "│ 1   │ nft    │ 2    │ 6    │ 1    │\n",
       "│ 2   │ ntrees │ 20   │ 50   │ 10   │\n",
       "│ 3   │ podata │ 75   │ 95   │ 5    │\n",
       "│ 4   │ maxd   │ 5    │ 12   │ 1    │"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rf = DataFrame(param=String[], min=Int8[], max=Int8[], step=Int8[]);\n",
    "\n",
    "push!(params_rf, [\"nft\", 2, 6, 1]);\n",
    "push!(params_rf, [\"ntrees\", 20, 50, 10]);\n",
    "push!(params_rf, [\"podata\", 75, 95, 5]);\n",
    "push!(params_rf, [\"maxd\", 5, 12, 1]);\n",
    "\n",
    "params_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 3260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_3260.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35, 0.7142857142857143)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 47\n",
       "Depth:  11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = convert(Matrix{Float64}, train_set[:, names_ft]);\n",
    "train_labels = convert(Array{Int64}, train_set[!,:SURVERSE]);\n",
    "\n",
    "dt_model = build_tree(train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 45\n",
       "Depth:  11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = prune_tree(dt_model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470588235294118"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = convert(Matrix{Float64}, val_set[:, names_ft]);\n",
    "val_labels = convert(Array{Int64}, val_set[!,:SURVERSE]);\n",
    "\n",
    "val_pred_dt = apply_tree(dt_model, val_features);\n",
    "r = roc(val_labels, val_pred_dt);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[3, 30, 85, 8], 0.7777777777777777)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45, 0.7142857142857143)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_3260.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 3260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-02</td><td>0</td><td>-0.068677</td><td>0.0211726</td><td>-0.0891232</td><td>-0.0297023</td></tr><tr><th>2</th><td>2019-05-09</td><td>0</td><td>0.71368</td><td>1.3347</td><td>0.50862</td><td>0.923961</td></tr><tr><th>3</th><td>2019-05-10</td><td>1</td><td>4.38952</td><td>2.62861</td><td>3.48538</td><td>2.006</td></tr><tr><th>4</th><td>2019-05-15</td><td>0</td><td>-0.366718</td><td>-0.370924</td><td>-0.292356</td><td>-0.304797</td></tr><tr><th>5</th><td>2019-05-20</td><td>0</td><td>0.17969</td><td>0.452479</td><td>0.305387</td><td>0.575507</td></tr><tr><th>6</th><td>2019-05-23</td><td>1</td><td>1.86859</td><td>2.39336</td><td>2.25403</td><td>3.10638</td></tr><tr><th>7</th><td>2019-05-24</td><td>0</td><td>-0.230116</td><td>-0.194481</td><td>-0.124988</td><td>-0.048042</td></tr><tr><th>8</th><td>2019-05-26</td><td>0</td><td>-0.354299</td><td>-0.351319</td><td>-0.208672</td><td>-0.17642</td></tr><tr><th>9</th><td>2019-05-30</td><td>0</td><td>-0.304626</td><td>-0.2729</td><td>-0.172807</td><td>-0.121401</td></tr><tr><th>10</th><td>2019-06-02</td><td>0</td><td>0.763353</td><td>0.668132</td><td>0.448846</td><td>0.39211</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-02 & 0 & -0.068677 & 0.0211726 & -0.0891232 & -0.0297023 \\\\\n",
       "\t2 & 2019-05-09 & 0 & 0.71368 & 1.3347 & 0.50862 & 0.923961 \\\\\n",
       "\t3 & 2019-05-10 & 1 & 4.38952 & 2.62861 & 3.48538 & 2.006 \\\\\n",
       "\t4 & 2019-05-15 & 0 & -0.366718 & -0.370924 & -0.292356 & -0.304797 \\\\\n",
       "\t5 & 2019-05-20 & 0 & 0.17969 & 0.452479 & 0.305387 & 0.575507 \\\\\n",
       "\t6 & 2019-05-23 & 1 & 1.86859 & 2.39336 & 2.25403 & 3.10638 \\\\\n",
       "\t7 & 2019-05-24 & 0 & -0.230116 & -0.194481 & -0.124988 & -0.048042 \\\\\n",
       "\t8 & 2019-05-26 & 0 & -0.354299 & -0.351319 & -0.208672 & -0.17642 \\\\\n",
       "\t9 & 2019-05-30 & 0 & -0.304626 & -0.2729 & -0.172807 & -0.121401 \\\\\n",
       "\t10 & 2019-06-02 & 0 & 0.763353 & 0.668132 & 0.448846 & 0.39211 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3   │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-02 │ 0        │ -0.068677 │ 0.0211726 │ -0.0891232 │\n",
       "│ 2   │ 2019-05-09 │ 0        │ 0.71368   │ 1.3347    │ 0.50862    │\n",
       "│ 3   │ 2019-05-10 │ 1        │ 4.38952   │ 2.62861   │ 3.48538    │\n",
       "│ 4   │ 2019-05-15 │ 0        │ -0.366718 │ -0.370924 │ -0.292356  │\n",
       "│ 5   │ 2019-05-20 │ 0        │ 0.17969   │ 0.452479  │ 0.305387   │\n",
       "│ 6   │ 2019-05-23 │ 1        │ 1.86859   │ 2.39336   │ 2.25403    │\n",
       "│ 7   │ 2019-05-24 │ 0        │ -0.230116 │ -0.194481 │ -0.124988  │\n",
       "│ 8   │ 2019-05-26 │ 0        │ -0.354299 │ -0.351319 │ -0.208672  │\n",
       "│ 9   │ 2019-05-30 │ 0        │ -0.304626 │ -0.2729   │ -0.172807  │\n",
       "│ 10  │ 2019-06-02 │ 0        │ 0.763353  │ 0.668132  │ 0.448846   │"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3260 = test_set;\n",
    "pred_3260[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_3260[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_3350.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.8387096774193549)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070175438596491"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[2, 20, 80, 6], 0.8375219170075978)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.8524590163934426)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275862068965517"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_3350.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max</th><th>SS_sum</th><th>SS_max</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>1</td><td>0.251784</td><td>0.266921</td><td>0.512872</td><td>0.288286</td></tr><tr><th>2</th><td>2019-05-02</td><td>0</td><td>-0.221197</td><td>-0.15615</td><td>-0.0597502</td><td>-0.0342671</td></tr><tr><th>3</th><td>2019-05-08</td><td>0</td><td>-0.402043</td><td>-0.416502</td><td>-0.340659</td><td>-0.35682</td></tr><tr><th>4</th><td>2019-05-09</td><td>1</td><td>0.794321</td><td>0.982888</td><td>0.620914</td><td>0.852754</td></tr><tr><th>5</th><td>2019-05-10</td><td>1</td><td>3.56265</td><td>1.14561</td><td>3.81896</td><td>1.41722</td></tr><tr><th>6</th><td>2019-05-11</td><td>0</td><td>-0.402043</td><td>-0.416502</td><td>-0.319051</td><td>-0.303061</td></tr><tr><th>7</th><td>2019-05-13</td><td>0</td><td>-0.276842</td><td>-0.123606</td><td>-0.146184</td><td>0.127009</td></tr><tr><th>8</th><td>2019-05-14</td><td>1</td><td>1.04472</td><td>0.169289</td><td>0.685739</td><td>0.234527</td></tr><tr><th>9</th><td>2019-05-18</td><td>0</td><td>-0.37422</td><td>-0.351414</td><td>-0.340659</td><td>-0.35682</td></tr><tr><th>10</th><td>2019-05-19</td><td>1</td><td>0.390896</td><td>0.462185</td><td>0.361613</td><td>0.261407</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max & SS\\_sum & SS\\_max\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 1 & 0.251784 & 0.266921 & 0.512872 & 0.288286 \\\\\n",
       "\t2 & 2019-05-02 & 0 & -0.221197 & -0.15615 & -0.0597502 & -0.0342671 \\\\\n",
       "\t3 & 2019-05-08 & 0 & -0.402043 & -0.416502 & -0.340659 & -0.35682 \\\\\n",
       "\t4 & 2019-05-09 & 1 & 0.794321 & 0.982888 & 0.620914 & 0.852754 \\\\\n",
       "\t5 & 2019-05-10 & 1 & 3.56265 & 1.14561 & 3.81896 & 1.41722 \\\\\n",
       "\t6 & 2019-05-11 & 0 & -0.402043 & -0.416502 & -0.319051 & -0.303061 \\\\\n",
       "\t7 & 2019-05-13 & 0 & -0.276842 & -0.123606 & -0.146184 & 0.127009 \\\\\n",
       "\t8 & 2019-05-14 & 1 & 1.04472 & 0.169289 & 0.685739 & 0.234527 \\\\\n",
       "\t9 & 2019-05-18 & 0 & -0.37422 & -0.351414 & -0.340659 & -0.35682 \\\\\n",
       "\t10 & 2019-05-19 & 1 & 0.390896 & 0.462185 & 0.361613 & 0.261407 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max    │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-01 │ 1        │ 0.251784  │ 0.266921  │ 0.512872   │\n",
       "│ 2   │ 2019-05-02 │ 0        │ -0.221197 │ -0.15615  │ -0.0597502 │\n",
       "│ 3   │ 2019-05-08 │ 0        │ -0.402043 │ -0.416502 │ -0.340659  │\n",
       "│ 4   │ 2019-05-09 │ 1        │ 0.794321  │ 0.982888  │ 0.620914   │\n",
       "│ 5   │ 2019-05-10 │ 1        │ 3.56265   │ 1.14561   │ 3.81896    │\n",
       "│ 6   │ 2019-05-11 │ 0        │ -0.402043 │ -0.416502 │ -0.319051  │\n",
       "│ 7   │ 2019-05-13 │ 0        │ -0.276842 │ -0.123606 │ -0.146184  │\n",
       "│ 8   │ 2019-05-14 │ 1        │ 1.04472   │ 0.169289  │ 0.685739   │\n",
       "│ 9   │ 2019-05-18 │ 0        │ -0.37422  │ -0.351414 │ -0.340659  │\n",
       "│ 10  │ 2019-05-19 │ 1        │ 0.390896  │ 0.462185  │ 0.361613   │"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3350 = test_set;\n",
    "pred_3350[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_3350[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_4240.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.6451612903225806)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[5, 50, 95, 9], 0.6547619047619048)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15, 0.6666666666666666)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185185185185185"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 9)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4240.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-07</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373886</td><td>-0.388186</td></tr><tr><th>2</th><td>2019-05-09</td><td>0</td><td>0.623037</td><td>1.13181</td><td>0.529064</td><td>0.928872</td></tr><tr><th>3</th><td>2019-05-10</td><td>1</td><td>4.26944</td><td>2.45726</td><td>2.97993</td><td>1.10685</td></tr><tr><th>4</th><td>2019-05-15</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373886</td><td>-0.388186</td></tr><tr><th>5</th><td>2019-05-21</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.338706</td><td>-0.334792</td></tr><tr><th>6</th><td>2019-05-22</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373886</td><td>-0.388186</td></tr><tr><th>7</th><td>2019-05-23</td><td>1</td><td>2.76109</td><td>3.80518</td><td>3.74216</td><td>4.70207</td></tr><tr><th>8</th><td>2019-05-24</td><td>0</td><td>-0.153104</td><td>-0.0588493</td><td>-0.115901</td><td>0.00337169</td></tr><tr><th>9</th><td>2019-05-25</td><td>0</td><td>-0.270258</td><td>-0.283502</td><td>-0.2918</td><td>-0.2636</td></tr><tr><th>10</th><td>2019-06-01</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373886</td><td>-0.388186</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-07 & 0 & -0.358123 & -0.373363 & -0.373886 & -0.388186 \\\\\n",
       "\t2 & 2019-05-09 & 0 & 0.623037 & 1.13181 & 0.529064 & 0.928872 \\\\\n",
       "\t3 & 2019-05-10 & 1 & 4.26944 & 2.45726 & 2.97993 & 1.10685 \\\\\n",
       "\t4 & 2019-05-15 & 0 & -0.358123 & -0.373363 & -0.373886 & -0.388186 \\\\\n",
       "\t5 & 2019-05-21 & 0 & -0.358123 & -0.373363 & -0.338706 & -0.334792 \\\\\n",
       "\t6 & 2019-05-22 & 0 & -0.358123 & -0.373363 & -0.373886 & -0.388186 \\\\\n",
       "\t7 & 2019-05-23 & 1 & 2.76109 & 3.80518 & 3.74216 & 4.70207 \\\\\n",
       "\t8 & 2019-05-24 & 0 & -0.153104 & -0.0588493 & -0.115901 & 0.00337169 \\\\\n",
       "\t9 & 2019-05-25 & 0 & -0.270258 & -0.283502 & -0.2918 & -0.2636 \\\\\n",
       "\t10 & 2019-06-01 & 0 & -0.358123 & -0.373363 & -0.373886 & -0.388186 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3    │ SS_sum    │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼────────────┼──────────┼───────────┼────────────┼───────────┤\n",
       "│ 1   │ 2019-05-07 │ 0        │ -0.358123 │ -0.373363  │ -0.373886 │\n",
       "│ 2   │ 2019-05-09 │ 0        │ 0.623037  │ 1.13181    │ 0.529064  │\n",
       "│ 3   │ 2019-05-10 │ 1        │ 4.26944   │ 2.45726    │ 2.97993   │\n",
       "│ 4   │ 2019-05-15 │ 0        │ -0.358123 │ -0.373363  │ -0.373886 │\n",
       "│ 5   │ 2019-05-21 │ 0        │ -0.358123 │ -0.373363  │ -0.338706 │\n",
       "│ 6   │ 2019-05-22 │ 0        │ -0.358123 │ -0.373363  │ -0.373886 │\n",
       "│ 7   │ 2019-05-23 │ 1        │ 2.76109   │ 3.80518    │ 3.74216   │\n",
       "│ 8   │ 2019-05-24 │ 0        │ -0.153104 │ -0.0588493 │ -0.115901 │\n",
       "│ 9   │ 2019-05-25 │ 0        │ -0.270258 │ -0.283502  │ -0.2918   │\n",
       "│ 10  │ 2019-06-01 │ 0        │ -0.358123 │ -0.373363  │ -0.373886 │"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4240 = test_set;\n",
    "pred_4240[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_4240[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_4350.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.7058823529411765)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[4, 30, 80, 12], 0.9181286549707601)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.7777777777777778)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 9)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4350.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-03</td><td>0</td><td>0.0306699</td><td>0.119197</td><td>0.039479</td><td>0.0507577</td></tr><tr><th>2</th><td>2019-05-04</td><td>0</td><td>-0.366718</td><td>-0.370924</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>3</th><td>2019-05-07</td><td>0</td><td>-0.354299</td><td>-0.351319</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>4</th><td>2019-05-08</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>5</th><td>2019-05-10</td><td>1</td><td>4.38952</td><td>2.62861</td><td>0.588891</td><td>0.338935</td></tr><tr><th>6</th><td>2019-05-11</td><td>0</td><td>-0.366718</td><td>-0.370924</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>7</th><td>2019-05-12</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>8</th><td>2019-05-21</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>9</th><td>2019-05-22</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>10</th><td>2019-05-23</td><td>0</td><td>1.86859</td><td>2.39336</td><td>0.380842</td><td>0.524855</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-03 & 0 & 0.0306699 & 0.119197 & 0.039479 & 0.0507577 \\\\\n",
       "\t2 & 2019-05-04 & 0 & -0.366718 & -0.370924 & -0.0493965 & -0.0514987 \\\\\n",
       "\t3 & 2019-05-07 & 0 & -0.354299 & -0.351319 & -0.0493965 & -0.0514987 \\\\\n",
       "\t4 & 2019-05-08 & 0 & -0.391555 & -0.410134 & -0.0493965 & -0.0514987 \\\\\n",
       "\t5 & 2019-05-10 & 1 & 4.38952 & 2.62861 & 0.588891 & 0.338935 \\\\\n",
       "\t6 & 2019-05-11 & 0 & -0.366718 & -0.370924 & -0.0493965 & -0.0514987 \\\\\n",
       "\t7 & 2019-05-12 & 0 & -0.391555 & -0.410134 & -0.0493965 & -0.0514987 \\\\\n",
       "\t8 & 2019-05-21 & 0 & -0.391555 & -0.410134 & -0.0493965 & -0.0514987 \\\\\n",
       "\t9 & 2019-05-22 & 0 & -0.391555 & -0.410134 & -0.0493965 & -0.0514987 \\\\\n",
       "\t10 & 2019-05-23 & 0 & 1.86859 & 2.39336 & 0.380842 & 0.524855 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3   │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-03 │ 0        │ 0.0306699 │ 0.119197  │ 0.039479   │\n",
       "│ 2   │ 2019-05-04 │ 0        │ -0.366718 │ -0.370924 │ -0.0493965 │\n",
       "│ 3   │ 2019-05-07 │ 0        │ -0.354299 │ -0.351319 │ -0.0493965 │\n",
       "│ 4   │ 2019-05-08 │ 0        │ -0.391555 │ -0.410134 │ -0.0493965 │\n",
       "│ 5   │ 2019-05-10 │ 1        │ 4.38952   │ 2.62861   │ 0.588891   │\n",
       "│ 6   │ 2019-05-11 │ 0        │ -0.366718 │ -0.370924 │ -0.0493965 │\n",
       "│ 7   │ 2019-05-12 │ 0        │ -0.391555 │ -0.410134 │ -0.0493965 │\n",
       "│ 8   │ 2019-05-21 │ 0        │ -0.391555 │ -0.410134 │ -0.0493965 │\n",
       "│ 9   │ 2019-05-22 │ 0        │ -0.391555 │ -0.410134 │ -0.0493965 │\n",
       "│ 10  │ 2019-05-23 │ 0        │ 1.86859   │ 2.39336   │ 0.380842   │"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4350 = test_set;\n",
    "pred_4350[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_4350[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/ouvrage_4380.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.7407407407407407)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int8[3, 20, 85, 6], 0.6683569979716024)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.7407407407407407)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896551724137931"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 9)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4380.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= best_threshold] .= 1.0;\n",
    "test_pred[test_pred .< best_threshold] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-02</td><td>0</td><td>-0.068677</td><td>0.0211726</td><td>-0.035388</td><td>-0.0117939</td></tr><tr><th>2</th><td>2019-05-04</td><td>0</td><td>-0.366718</td><td>-0.370924</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>3</th><td>2019-05-05</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>4</th><td>2019-05-06</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>5</th><td>2019-05-08</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>6</th><td>2019-05-09</td><td>0</td><td>0.71368</td><td>1.3347</td><td>0.201957</td><td>0.366876</td></tr><tr><th>7</th><td>2019-05-10</td><td>1</td><td>4.38952</td><td>2.62861</td><td>1.38394</td><td>0.796521</td></tr><tr><th>8</th><td>2019-05-17</td><td>0</td><td>-0.329463</td><td>-0.351319</td><td>-0.0923509</td><td>-0.084615</td></tr><tr><th>9</th><td>2019-05-18</td><td>0</td><td>-0.391555</td><td>-0.410134</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>10</th><td>2019-05-28</td><td>0</td><td>-0.354299</td><td>-0.351319</td><td>-0.0686164</td><td>-0.0482044</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-02 & 0 & -0.068677 & 0.0211726 & -0.035388 & -0.0117939 \\\\\n",
       "\t2 & 2019-05-04 & 0 & -0.366718 & -0.370924 & -0.116085 & -0.121026 \\\\\n",
       "\t3 & 2019-05-05 & 0 & -0.391555 & -0.410134 & -0.116085 & -0.121026 \\\\\n",
       "\t4 & 2019-05-06 & 0 & -0.391555 & -0.410134 & -0.116085 & -0.121026 \\\\\n",
       "\t5 & 2019-05-08 & 0 & -0.391555 & -0.410134 & -0.116085 & -0.121026 \\\\\n",
       "\t6 & 2019-05-09 & 0 & 0.71368 & 1.3347 & 0.201957 & 0.366876 \\\\\n",
       "\t7 & 2019-05-10 & 1 & 4.38952 & 2.62861 & 1.38394 & 0.796521 \\\\\n",
       "\t8 & 2019-05-17 & 0 & -0.329463 & -0.351319 & -0.0923509 & -0.084615 \\\\\n",
       "\t9 & 2019-05-18 & 0 & -0.391555 & -0.410134 & -0.116085 & -0.121026 \\\\\n",
       "\t10 & 2019-05-28 & 0 & -0.354299 & -0.351319 & -0.0686164 & -0.0482044 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3   │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-02 │ 0        │ -0.068677 │ 0.0211726 │ -0.035388  │\n",
       "│ 2   │ 2019-05-04 │ 0        │ -0.366718 │ -0.370924 │ -0.116085  │\n",
       "│ 3   │ 2019-05-05 │ 0        │ -0.391555 │ -0.410134 │ -0.116085  │\n",
       "│ 4   │ 2019-05-06 │ 0        │ -0.391555 │ -0.410134 │ -0.116085  │\n",
       "│ 5   │ 2019-05-08 │ 0        │ -0.391555 │ -0.410134 │ -0.116085  │\n",
       "│ 6   │ 2019-05-09 │ 0        │ 0.71368   │ 1.3347    │ 0.201957   │\n",
       "│ 7   │ 2019-05-10 │ 1        │ 4.38952   │ 2.62861   │ 1.38394    │\n",
       "│ 8   │ 2019-05-17 │ 0        │ -0.329463 │ -0.351319 │ -0.0923509 │\n",
       "│ 9   │ 2019-05-18 │ 0        │ -0.391555 │ -0.410134 │ -0.116085  │\n",
       "│ 10  │ 2019-05-28 │ 0        │ -0.354299 │ -0.351319 │ -0.0686164 │"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4380 = test_set;\n",
    "pred_4380[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_4380[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/test.csv\");\n",
    "test_set[!, :SURVERSE] = zeros(size(test_set, 1));\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque ligne de test_set\n",
    "\n",
    "    - On check l'ID de l'ouvrage pour savoir quel prediction load\n",
    "    - On va chercher la prediction à telle date pour cet ouvrage\n",
    "    - On le met à la ligne courante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(test_set, 1)\n",
    "    curr_ouvrage = test_set[i, 1];\n",
    "    pred_to_use = nothing;\n",
    "    if curr_ouvrage == \"3260-01D\"\n",
    "        pred_to_use = pred_3260;\n",
    "    elseif curr_ouvrage == \"3350-07D\"\n",
    "        pred_to_use = pred_3350;\n",
    "    elseif curr_ouvrage == \"4240-01D\"\n",
    "        pred_to_use = pred_4240;\n",
    "    elseif curr_ouvrage == \"4350-01D\"\n",
    "        pred_to_use = pred_4350;\n",
    "    elseif curr_ouvrage == \"4380-01D\"\n",
    "        pred_to_use = pred_4380;\n",
    "    end\n",
    "    \n",
    "    curr_date = test_set[i, :DATE];\n",
    "    pred_res = filter(row -> row.DATE == curr_date, pred_to_use);\n",
    "    \n",
    "    test_set[i, :SURVERSE] = pred_res[1, :SURVERSE];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>10 rows × 3 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-05-02</td><td>0</td></tr><tr><th>2</th><td>3260-01D</td><td>2019-05-09</td><td>0</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-05-10</td><td>1</td></tr><tr><th>4</th><td>3260-01D</td><td>2019-05-15</td><td>0</td></tr><tr><th>5</th><td>3260-01D</td><td>2019-05-20</td><td>0</td></tr><tr><th>6</th><td>3260-01D</td><td>2019-05-23</td><td>1</td></tr><tr><th>7</th><td>3260-01D</td><td>2019-05-24</td><td>0</td></tr><tr><th>8</th><td>3260-01D</td><td>2019-05-26</td><td>0</td></tr><tr><th>9</th><td>3260-01D</td><td>2019-05-30</td><td>0</td></tr><tr><th>10</th><td>3350-07D</td><td>2019-05-01</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-05-02 & 0 \\\\\n",
       "\t2 & 3260-01D & 2019-05-09 & 0 \\\\\n",
       "\t3 & 3260-01D & 2019-05-10 & 1 \\\\\n",
       "\t4 & 3260-01D & 2019-05-15 & 0 \\\\\n",
       "\t5 & 3260-01D & 2019-05-20 & 0 \\\\\n",
       "\t6 & 3260-01D & 2019-05-23 & 1 \\\\\n",
       "\t7 & 3260-01D & 2019-05-24 & 0 \\\\\n",
       "\t8 & 3260-01D & 2019-05-26 & 0 \\\\\n",
       "\t9 & 3260-01D & 2019-05-30 & 0 \\\\\n",
       "\t10 & 3350-07D & 2019-05-01 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-05-02 │ 0        │\n",
       "│ 2   │ 3260-01D   │ 2019-05-09 │ 0        │\n",
       "│ 3   │ 3260-01D   │ 2019-05-10 │ 1        │\n",
       "│ 4   │ 3260-01D   │ 2019-05-15 │ 0        │\n",
       "│ 5   │ 3260-01D   │ 2019-05-20 │ 0        │\n",
       "│ 6   │ 3260-01D   │ 2019-05-23 │ 1        │\n",
       "│ 7   │ 3260-01D   │ 2019-05-24 │ 0        │\n",
       "│ 8   │ 3260-01D   │ 2019-05-26 │ 0        │\n",
       "│ 9   │ 3260-01D   │ 2019-05-30 │ 0        │\n",
       "│ 10  │ 3350-07D   │ 2019-05-01 │ 1        │"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[!, :SURVERSE] = convert(Array{Int}, test_set[!, :SURVERSE]);\n",
    "first(test_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"submissions/mc-submission-20.csv\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = test_set[:,:NO_OUVRAGE].*\"_\".*string.(test_set[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=test_set[:, :SURVERSE])\n",
    "CSV.write(\"submissions/mc-submission-$(no_soumission).csv\",sampleSubmission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
