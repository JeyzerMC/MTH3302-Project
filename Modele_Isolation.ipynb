{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading DataFrames support into Gadfly.jl\n",
      "└ @ Gadfly /home/chaime/.julia/packages/Gadfly/09PWZ/src/mapping.jl:228\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, GLM, Statistics, Dates, Gadfly, Random, MLBase, DecisionTree;\n",
    "include(\"utils/precipitation.jl\");\n",
    "include(\"utils/random-forest.jl\");\n",
    "include(\"utils/reg-log.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_soumission = 22;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partitionTrainTest (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function partitionTrainTest(data, at = 0.8) # https://discourse.julialang.org/t/simple-tool-for-train-test-split/473/2\n",
    "    n = nrow(data)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return data[train_idx,:], data[test_idx,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_form = @formula(SURVERSE ~ FS_sum + FS_max + \n",
    "                               SS_sum + SS_max);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: missing separator in array expression",
     "output_type": "error",
     "traceback": [
      "syntax: missing separator in array expression",
      ""
     ]
    }
   ],
   "source": [
    "names_ft = [:FS_sum, :FS_max\n",
    "            :SS_sum, :SS_max];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = DataFrame(param=String[], min=Int8[], max=Int8[], step=Int8[]);\n",
    "\n",
    "push!(params_rf, [\"nft\", 2, 6, 1]);\n",
    "push!(params_rf, [\"ntrees\", 50, 100, 10]);\n",
    "push!(params_rf, [\"podata\", 75, 95, 5]);\n",
    "push!(params_rf, [\"maxd\", 15, 27, 2]);\n",
    "\n",
    "params_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 3260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/oversampled/ouvrage_3260.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.8262243285939969)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233305156382079"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 286\n",
       "Depth:  31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = convert(Matrix{Float64}, train_set[:, names_ft]);\n",
    "train_labels = convert(Array{Int64}, train_set[!,:SURVERSE]);\n",
    "\n",
    "dt_model = build_tree(train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 268\n",
       "Depth:  31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = prune_tree(dt_model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185303514376997"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = convert(Matrix{Float64}, val_set[:, names_ft]);\n",
    "val_labels = convert(Array{Int64}, val_set[!,:SURVERSE]);\n",
    "\n",
    "val_pred_dt = apply_tree(dt_model, val_features);\n",
    "r = roc(val_labels, val_pred_dt);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest [TODO: RUN LATER, TOO LONG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUICK RANDOM FOREST ESTIMATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9537254901960784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_params = [2, 60, 80, 25];\n",
    "get_rf_direct(train_set, val_set, names_ft, estimated_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUICK REPLACEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "# val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.9278033794162827)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117174959871589"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_3260.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "# test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= 0.5] .= 1.0;\n",
    "test_pred[test_pred .< 0.5] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 3260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max</th><th>SS_sum</th><th>SS_max</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-02</td><td>0</td><td>-0.0635098</td><td>-0.0332178</td><td>-0.0891232</td><td>-0.016819</td></tr><tr><th>2</th><td>2019-05-09</td><td>1</td><td>0.742849</td><td>1.01886</td><td>0.50862</td><td>0.620324</td></tr><tr><th>3</th><td>2019-05-10</td><td>1</td><td>4.53146</td><td>1.68837</td><td>3.48538</td><td>1.14162</td></tr><tr><th>4</th><td>2019-05-15</td><td>0</td><td>-0.370694</td><td>-0.35203</td><td>-0.292356</td><td>-0.306429</td></tr><tr><th>5</th><td>2019-05-20</td><td>0</td><td>0.192477</td><td>0.859456</td><td>0.305387</td><td>0.79409</td></tr><tr><th>6</th><td>2019-05-23</td><td>1</td><td>1.93319</td><td>1.59272</td><td>2.25403</td><td>2.56071</td></tr><tr><th>7</th><td>2019-05-24</td><td>0</td><td>-0.229901</td><td>-0.128861</td><td>-0.124988</td><td>0.0411031</td></tr><tr><th>8</th><td>2019-05-26</td><td>0</td><td>-0.357895</td><td>-0.320149</td><td>-0.208672</td><td>-0.161624</td></tr><tr><th>9</th><td>2019-05-30</td><td>0</td><td>-0.306698</td><td>-0.192624</td><td>-0.172807</td><td>-0.016819</td></tr><tr><th>10</th><td>2019-06-02</td><td>0</td><td>0.794047</td><td>0.381238</td><td>0.448846</td><td>0.127986</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max & SS\\_sum & SS\\_max\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-02 & 0 & -0.0635098 & -0.0332178 & -0.0891232 & -0.016819 \\\\\n",
       "\t2 & 2019-05-09 & 1 & 0.742849 & 1.01886 & 0.50862 & 0.620324 \\\\\n",
       "\t3 & 2019-05-10 & 1 & 4.53146 & 1.68837 & 3.48538 & 1.14162 \\\\\n",
       "\t4 & 2019-05-15 & 0 & -0.370694 & -0.35203 & -0.292356 & -0.306429 \\\\\n",
       "\t5 & 2019-05-20 & 0 & 0.192477 & 0.859456 & 0.305387 & 0.79409 \\\\\n",
       "\t6 & 2019-05-23 & 1 & 1.93319 & 1.59272 & 2.25403 & 2.56071 \\\\\n",
       "\t7 & 2019-05-24 & 0 & -0.229901 & -0.128861 & -0.124988 & 0.0411031 \\\\\n",
       "\t8 & 2019-05-26 & 0 & -0.357895 & -0.320149 & -0.208672 & -0.161624 \\\\\n",
       "\t9 & 2019-05-30 & 0 & -0.306698 & -0.192624 & -0.172807 & -0.016819 \\\\\n",
       "\t10 & 2019-06-02 & 0 & 0.794047 & 0.381238 & 0.448846 & 0.127986 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum     │ FS_max     │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼────────────┼────────────┼────────────┤\n",
       "│ 1   │ 2019-05-02 │ 0        │ -0.0635098 │ -0.0332178 │ -0.0891232 │\n",
       "│ 2   │ 2019-05-09 │ 1        │ 0.742849   │ 1.01886    │ 0.50862    │\n",
       "│ 3   │ 2019-05-10 │ 1        │ 4.53146    │ 1.68837    │ 3.48538    │\n",
       "│ 4   │ 2019-05-15 │ 0        │ -0.370694  │ -0.35203   │ -0.292356  │\n",
       "│ 5   │ 2019-05-20 │ 0        │ 0.192477   │ 0.859456   │ 0.305387   │\n",
       "│ 6   │ 2019-05-23 │ 1        │ 1.93319    │ 1.59272    │ 2.25403    │\n",
       "│ 7   │ 2019-05-24 │ 0        │ -0.229901  │ -0.128861  │ -0.124988  │\n",
       "│ 8   │ 2019-05-26 │ 0        │ -0.357895  │ -0.320149  │ -0.208672  │\n",
       "│ 9   │ 2019-05-30 │ 0        │ -0.306698  │ -0.192624  │ -0.172807  │\n",
       "│ 10  │ 2019-06-02 │ 0        │ 0.794047   │ 0.381238   │ 0.448846   │"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3260 = test_set;\n",
    "pred_3260[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max, :SS_sum, :SS_max];\n",
    "first(pred_3260[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/oversampled/ouvrage_3350.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.8368421052631579)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.804490177736202"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 332\n",
       "Depth:  34"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = convert(Matrix{Float64}, train_set[:, names_ft]);\n",
    "train_labels = convert(Array{Int64}, train_set[!,:SURVERSE]);\n",
    "\n",
    "dt_model = build_tree(train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 307\n",
       "Depth:  34"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = prune_tree(dt_model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043927648578811"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = convert(Matrix{Float64}, val_set[:, names_ft]);\n",
    "val_labels = convert(Array{Int64}, val_set[!,:SURVERSE]);\n",
    "\n",
    "val_pred_dt = apply_tree(dt_model, val_features);\n",
    "r = roc(val_labels, val_pred_dt);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUICK RANDOM FOREST ESTIMATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941696113074205"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_params = [3, 40, 80, 20];\n",
    "get_rf_direct(train_set, val_set, names_ft, estimated_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUICK REPLACEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "# val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35, 0.9184549356223176)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042076991942704"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_3350.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "# test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= 0.5] .= 1.0;\n",
    "test_pred[test_pred .< 0.5] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-01</td><td>1</td><td>0.256732</td><td>0.476482</td><td>0.534936</td><td>0.609527</td></tr><tr><th>2</th><td>2019-05-02</td><td>0</td><td>-0.21833</td><td>-0.18342</td><td>-0.0552547</td><td>0.0260547</td></tr><tr><th>3</th><td>2019-05-08</td><td>0</td><td>-0.399971</td><td>-0.425384</td><td>-0.344782</td><td>-0.362927</td></tr><tr><th>4</th><td>2019-05-09</td><td>1</td><td>0.801656</td><td>1.46634</td><td>0.646292</td><td>1.21068</td></tr><tr><th>5</th><td>2019-05-10</td><td>1</td><td>3.58217</td><td>2.3462</td><td>3.94245</td><td>2.37762</td></tr><tr><th>6</th><td>2019-05-11</td><td>0</td><td>-0.399971</td><td>-0.425384</td><td>-0.322511</td><td>-0.327565</td></tr><tr><th>7</th><td>2019-05-13</td><td>0</td><td>-0.274219</td><td>-0.227413</td><td>-0.14434</td><td>-0.0446692</td></tr><tr><th>8</th><td>2019-05-14</td><td>1</td><td>1.05316</td><td>0.542472</td><td>0.713106</td><td>0.415036</td></tr><tr><th>9</th><td>2019-05-18</td><td>0</td><td>-0.372026</td><td>-0.381391</td><td>-0.344782</td><td>-0.362927</td></tr><tr><th>10</th><td>2019-05-19</td><td>0</td><td>0.396456</td><td>0.586466</td><td>0.379036</td><td>0.415036</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-01 & 1 & 0.256732 & 0.476482 & 0.534936 & 0.609527 \\\\\n",
       "\t2 & 2019-05-02 & 0 & -0.21833 & -0.18342 & -0.0552547 & 0.0260547 \\\\\n",
       "\t3 & 2019-05-08 & 0 & -0.399971 & -0.425384 & -0.344782 & -0.362927 \\\\\n",
       "\t4 & 2019-05-09 & 1 & 0.801656 & 1.46634 & 0.646292 & 1.21068 \\\\\n",
       "\t5 & 2019-05-10 & 1 & 3.58217 & 2.3462 & 3.94245 & 2.37762 \\\\\n",
       "\t6 & 2019-05-11 & 0 & -0.399971 & -0.425384 & -0.322511 & -0.327565 \\\\\n",
       "\t7 & 2019-05-13 & 0 & -0.274219 & -0.227413 & -0.14434 & -0.0446692 \\\\\n",
       "\t8 & 2019-05-14 & 1 & 1.05316 & 0.542472 & 0.713106 & 0.415036 \\\\\n",
       "\t9 & 2019-05-18 & 0 & -0.372026 & -0.381391 & -0.344782 & -0.362927 \\\\\n",
       "\t10 & 2019-05-19 & 0 & 0.396456 & 0.586466 & 0.379036 & 0.415036 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3   │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-01 │ 1        │ 0.256732  │ 0.476482  │ 0.534936   │\n",
       "│ 2   │ 2019-05-02 │ 0        │ -0.21833  │ -0.18342  │ -0.0552547 │\n",
       "│ 3   │ 2019-05-08 │ 0        │ -0.399971 │ -0.425384 │ -0.344782  │\n",
       "│ 4   │ 2019-05-09 │ 1        │ 0.801656  │ 1.46634   │ 0.646292   │\n",
       "│ 5   │ 2019-05-10 │ 1        │ 3.58217   │ 2.3462    │ 3.94245    │\n",
       "│ 6   │ 2019-05-11 │ 0        │ -0.399971 │ -0.425384 │ -0.322511  │\n",
       "│ 7   │ 2019-05-13 │ 0        │ -0.274219 │ -0.227413 │ -0.14434   │\n",
       "│ 8   │ 2019-05-14 │ 1        │ 1.05316   │ 0.542472  │ 0.713106   │\n",
       "│ 9   │ 2019-05-18 │ 0        │ -0.372026 │ -0.381391 │ -0.344782  │\n",
       "│ 10  │ 2019-05-19 │ 0        │ 0.396456  │ 0.586466  │ 0.379036   │"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3350 = test_set;\n",
    "pred_3350[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_3350[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/oversampled/ouvrage_4240.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45, 0.8051001821493625)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988826815642458"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 297\n",
       "Depth:  24"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = convert(Matrix{Float64}, train_set[:, names_ft]);\n",
    "train_labels = convert(Array{Int64}, train_set[!,:SURVERSE]);\n",
    "\n",
    "dt_model = build_tree(train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 269\n",
       "Depth:  24"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = prune_tree(dt_model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124579124579124"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = convert(Matrix{Float64}, val_set[:, names_ft]);\n",
    "val_labels = convert(Array{Int64}, val_set[!,:SURVERSE]);\n",
    "\n",
    "val_pred_dt = apply_tree(dt_model, val_features);\n",
    "r = roc(val_labels, val_pred_dt);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUICK RANDOM FOREST ESTIMATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532710280373832"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_params = [3, 40, 80, 20];\n",
    "get_rf_direct(train_set, val_set, names_ft, estimated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "# val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.9258312020460358)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9258312020460358"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4240.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "# test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= 0.5] .= 1.0;\n",
    "test_pred[test_pred .< 0.5] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-07</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373593</td><td>-0.388305</td></tr><tr><th>2</th><td>2019-05-09</td><td>0</td><td>0.623037</td><td>1.13181</td><td>0.555808</td><td>0.972262</td></tr><tr><th>3</th><td>2019-05-10</td><td>1</td><td>4.26944</td><td>2.45726</td><td>3.07847</td><td>1.15612</td></tr><tr><th>4</th><td>2019-05-15</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373593</td><td>-0.388305</td></tr><tr><th>5</th><td>2019-05-21</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.337383</td><td>-0.333147</td></tr><tr><th>6</th><td>2019-05-22</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373593</td><td>-0.388305</td></tr><tr><th>7</th><td>2019-05-23</td><td>1</td><td>2.76109</td><td>3.80518</td><td>3.86303</td><td>4.8701</td></tr><tr><th>8</th><td>2019-05-24</td><td>0</td><td>-0.153104</td><td>-0.0588493</td><td>-0.10805</td><td>0.0161877</td></tr><tr><th>9</th><td>2019-05-25</td><td>0</td><td>-0.270258</td><td>-0.283502</td><td>-0.289102</td><td>-0.259603</td></tr><tr><th>10</th><td>2019-06-01</td><td>0</td><td>-0.358123</td><td>-0.373363</td><td>-0.373593</td><td>-0.388305</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-07 & 0 & -0.358123 & -0.373363 & -0.373593 & -0.388305 \\\\\n",
       "\t2 & 2019-05-09 & 0 & 0.623037 & 1.13181 & 0.555808 & 0.972262 \\\\\n",
       "\t3 & 2019-05-10 & 1 & 4.26944 & 2.45726 & 3.07847 & 1.15612 \\\\\n",
       "\t4 & 2019-05-15 & 0 & -0.358123 & -0.373363 & -0.373593 & -0.388305 \\\\\n",
       "\t5 & 2019-05-21 & 0 & -0.358123 & -0.373363 & -0.337383 & -0.333147 \\\\\n",
       "\t6 & 2019-05-22 & 0 & -0.358123 & -0.373363 & -0.373593 & -0.388305 \\\\\n",
       "\t7 & 2019-05-23 & 1 & 2.76109 & 3.80518 & 3.86303 & 4.8701 \\\\\n",
       "\t8 & 2019-05-24 & 0 & -0.153104 & -0.0588493 & -0.10805 & 0.0161877 \\\\\n",
       "\t9 & 2019-05-25 & 0 & -0.270258 & -0.283502 & -0.289102 & -0.259603 \\\\\n",
       "\t10 & 2019-06-01 & 0 & -0.358123 & -0.373363 & -0.373593 & -0.388305 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3    │ SS_sum    │ SS_max3   │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼────────────┼──────────┼───────────┼────────────┼───────────┼───────────┤\n",
       "│ 1   │ 2019-05-07 │ 0        │ -0.358123 │ -0.373363  │ -0.373593 │ -0.388305 │\n",
       "│ 2   │ 2019-05-09 │ 0        │ 0.623037  │ 1.13181    │ 0.555808  │ 0.972262  │\n",
       "│ 3   │ 2019-05-10 │ 1        │ 4.26944   │ 2.45726    │ 3.07847   │ 1.15612   │\n",
       "│ 4   │ 2019-05-15 │ 0        │ -0.358123 │ -0.373363  │ -0.373593 │ -0.388305 │\n",
       "│ 5   │ 2019-05-21 │ 0        │ -0.358123 │ -0.373363  │ -0.337383 │ -0.333147 │\n",
       "│ 6   │ 2019-05-22 │ 0        │ -0.358123 │ -0.373363  │ -0.373593 │ -0.388305 │\n",
       "│ 7   │ 2019-05-23 │ 1        │ 2.76109   │ 3.80518    │ 3.86303   │ 4.8701    │\n",
       "│ 8   │ 2019-05-24 │ 0        │ -0.153104 │ -0.0588493 │ -0.10805  │ 0.0161877 │\n",
       "│ 9   │ 2019-05-25 │ 0        │ -0.270258 │ -0.283502  │ -0.289102 │ -0.259603 │\n",
       "│ 10  │ 2019-06-01 │ 0        │ -0.358123 │ -0.373363  │ -0.373593 │ -0.388305 │"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4240 = test_set;\n",
    "pred_4240[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_4240[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/oversampled/ouvrage_4350.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.8764607679465777)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665480427046264"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 153\n",
       "Depth:  16"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = convert(Matrix{Float64}, train_set[:, names_ft]);\n",
    "train_labels = convert(Array{Int64}, train_set[!,:SURVERSE]);\n",
    "\n",
    "dt_model = build_tree(train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 142\n",
       "Depth:  16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = prune_tree(dt_model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500438212094654"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = convert(Matrix{Float64}, val_set[:, names_ft]);\n",
    "val_labels = convert(Array{Int64}, val_set[!,:SURVERSE]);\n",
    "\n",
    "val_pred_dt = apply_tree(dt_model, val_features);\n",
    "r = roc(val_labels, val_pred_dt);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUICK RANDOM FOREST ESTIMATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734816082121471"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_params = [3, 40, 80, 20];\n",
    "get_rf_direct(train_set, val_set, names_ft, estimated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "# val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.9527027027027027)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9527027027027027"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4350.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "# test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= 0.5] .= 1.0;\n",
    "test_pred[test_pred .< 0.5] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-03</td><td>0</td><td>0.038885</td><td>0.13156</td><td>0.039479</td><td>0.0507577</td></tr><tr><th>2</th><td>2019-05-04</td><td>0</td><td>-0.370694</td><td>-0.376504</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>3</th><td>2019-05-07</td><td>0</td><td>-0.357895</td><td>-0.356181</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>4</th><td>2019-05-08</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>5</th><td>2019-05-10</td><td>1</td><td>4.53146</td><td>2.73285</td><td>0.588891</td><td>0.338935</td></tr><tr><th>6</th><td>2019-05-11</td><td>0</td><td>-0.370694</td><td>-0.376504</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>7</th><td>2019-05-12</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>8</th><td>2019-05-21</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>9</th><td>2019-05-22</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.0493965</td><td>-0.0514987</td></tr><tr><th>10</th><td>2019-05-23</td><td>1</td><td>1.93319</td><td>2.48898</td><td>0.380842</td><td>0.524855</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-03 & 0 & 0.038885 & 0.13156 & 0.039479 & 0.0507577 \\\\\n",
       "\t2 & 2019-05-04 & 0 & -0.370694 & -0.376504 & -0.0493965 & -0.0514987 \\\\\n",
       "\t3 & 2019-05-07 & 0 & -0.357895 & -0.356181 & -0.0493965 & -0.0514987 \\\\\n",
       "\t4 & 2019-05-08 & 0 & -0.396293 & -0.417149 & -0.0493965 & -0.0514987 \\\\\n",
       "\t5 & 2019-05-10 & 1 & 4.53146 & 2.73285 & 0.588891 & 0.338935 \\\\\n",
       "\t6 & 2019-05-11 & 0 & -0.370694 & -0.376504 & -0.0493965 & -0.0514987 \\\\\n",
       "\t7 & 2019-05-12 & 0 & -0.396293 & -0.417149 & -0.0493965 & -0.0514987 \\\\\n",
       "\t8 & 2019-05-21 & 0 & -0.396293 & -0.417149 & -0.0493965 & -0.0514987 \\\\\n",
       "\t9 & 2019-05-22 & 0 & -0.396293 & -0.417149 & -0.0493965 & -0.0514987 \\\\\n",
       "\t10 & 2019-05-23 & 1 & 1.93319 & 2.48898 & 0.380842 & 0.524855 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum    │ FS_max3   │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-03 │ 0        │ 0.038885  │ 0.13156   │ 0.039479   │\n",
       "│ 2   │ 2019-05-04 │ 0        │ -0.370694 │ -0.376504 │ -0.0493965 │\n",
       "│ 3   │ 2019-05-07 │ 0        │ -0.357895 │ -0.356181 │ -0.0493965 │\n",
       "│ 4   │ 2019-05-08 │ 0        │ -0.396293 │ -0.417149 │ -0.0493965 │\n",
       "│ 5   │ 2019-05-10 │ 1        │ 4.53146   │ 2.73285   │ 0.588891   │\n",
       "│ 6   │ 2019-05-11 │ 0        │ -0.370694 │ -0.376504 │ -0.0493965 │\n",
       "│ 7   │ 2019-05-12 │ 0        │ -0.396293 │ -0.417149 │ -0.0493965 │\n",
       "│ 8   │ 2019-05-21 │ 0        │ -0.396293 │ -0.417149 │ -0.0493965 │\n",
       "│ 9   │ 2019-05-22 │ 0        │ -0.396293 │ -0.417149 │ -0.0493965 │\n",
       "│ 10  │ 2019-05-23 │ 1        │ 1.93319   │ 2.48898   │ 0.380842   │"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4350 = test_set;\n",
    "pred_4350[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_4350[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouvrage 4380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = CSV.read(\"data/parsed/oversampled/ouvrage_4380.csv\");\n",
    "train_set, val_set = partitionTrainTest(data_set);\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "size(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.862992125984252)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model = glm(val_form, train_set, Bernoulli(), LogitLink())\n",
    "val_pred_glm = GLM.predict(val_model, val_set);\n",
    "\n",
    "best_threshold_glm, f1_score_glm = find_best_threshold(val_pred_glm, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8465608465608465"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred_glm, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 254\n",
       "Depth:  22"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = convert(Matrix{Float64}, train_set[:, names_ft]);\n",
    "train_labels = convert(Array{Int64}, train_set[!,:SURVERSE]);\n",
    "\n",
    "dt_model = build_tree(train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 233\n",
       "Depth:  22"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = prune_tree(dt_model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995708154506438"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = convert(Matrix{Float64}, val_set[:, names_ft]);\n",
    "val_labels = convert(Array{Int64}, val_set[!,:SURVERSE]);\n",
    "\n",
    "val_pred_dt = apply_tree(dt_model, val_features);\n",
    "r = roc(val_labels, val_pred_dt);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUICK RANDOM FOREST ESTIMATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9367720465890182"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_params = [3, 40, 80, 20];\n",
    "get_rf_direct(train_set, val_set, names_ft, estimated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_rf = get_rf_probas(train_set, val_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params, f1_score_rf = find_best_rf(train_set, val_set, names_ft, params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred_rf = get_rf_probas(train_set, val_set, names_ft, best_params);\n",
    "# val_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55, 0.9148211243611585)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = (val_pred_glm + val_pred_rf[:, 2]) ./ 2;\n",
    "best_threshold, f1_score = find_best_threshold(val_pred, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.914095079232694"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_threshold(val_pred, val_labels, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 9)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/parsed/test_4380.csv\");\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_glm = glm(val_form, data_set, Bernoulli(), LogitLink());\n",
    "test_pred_glm = GLM.predict(test_model_glm, test_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_rf = get_rf_probas(data_set, test_set, names_ft, best_params);\n",
    "# test_pred_rf[:, 2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = get_rf_probas(data_set, test_set, names_ft, estimated_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred_glm + test_pred_rf[:, 2]) ./ 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test_pred .>= 0.5] .= 1.0;\n",
    "test_pred[test_pred .< 0.5] .= 0.0;\n",
    "test_pred = convert(Array{Int}, trunc.(test_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction for ouvrage 4380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>SURVERSE</th><th>FS_sum</th><th>FS_max3</th><th>SS_sum</th><th>SS_max3</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>2019-05-02</td><td>0</td><td>-0.0635098</td><td>0.0299474</td><td>-0.035388</td><td>-0.0117939</td></tr><tr><th>2</th><td>2019-05-04</td><td>0</td><td>-0.370694</td><td>-0.376504</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>3</th><td>2019-05-05</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>4</th><td>2019-05-06</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>5</th><td>2019-05-08</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>6</th><td>2019-05-09</td><td>0</td><td>0.742849</td><td>1.39156</td><td>0.201957</td><td>0.366876</td></tr><tr><th>7</th><td>2019-05-10</td><td>1</td><td>4.53146</td><td>2.73285</td><td>1.38394</td><td>0.796521</td></tr><tr><th>8</th><td>2019-05-17</td><td>0</td><td>-0.332296</td><td>-0.356181</td><td>-0.0923509</td><td>-0.084615</td></tr><tr><th>9</th><td>2019-05-18</td><td>0</td><td>-0.396293</td><td>-0.417149</td><td>-0.116085</td><td>-0.121026</td></tr><tr><th>10</th><td>2019-05-28</td><td>0</td><td>-0.357895</td><td>-0.356181</td><td>-0.0686164</td><td>-0.0482044</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& DATE & SURVERSE & FS\\_sum & FS\\_max3 & SS\\_sum & SS\\_max3\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-05-02 & 0 & -0.0635098 & 0.0299474 & -0.035388 & -0.0117939 \\\\\n",
       "\t2 & 2019-05-04 & 0 & -0.370694 & -0.376504 & -0.116085 & -0.121026 \\\\\n",
       "\t3 & 2019-05-05 & 0 & -0.396293 & -0.417149 & -0.116085 & -0.121026 \\\\\n",
       "\t4 & 2019-05-06 & 0 & -0.396293 & -0.417149 & -0.116085 & -0.121026 \\\\\n",
       "\t5 & 2019-05-08 & 0 & -0.396293 & -0.417149 & -0.116085 & -0.121026 \\\\\n",
       "\t6 & 2019-05-09 & 0 & 0.742849 & 1.39156 & 0.201957 & 0.366876 \\\\\n",
       "\t7 & 2019-05-10 & 1 & 4.53146 & 2.73285 & 1.38394 & 0.796521 \\\\\n",
       "\t8 & 2019-05-17 & 0 & -0.332296 & -0.356181 & -0.0923509 & -0.084615 \\\\\n",
       "\t9 & 2019-05-18 & 0 & -0.396293 & -0.417149 & -0.116085 & -0.121026 \\\\\n",
       "\t10 & 2019-05-28 & 0 & -0.357895 & -0.356181 & -0.0686164 & -0.0482044 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ DATE       │ SURVERSE │ FS_sum     │ FS_max3   │ SS_sum     │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼────────────┼───────────┼────────────┤\n",
       "│ 1   │ 2019-05-02 │ 0        │ -0.0635098 │ 0.0299474 │ -0.035388  │\n",
       "│ 2   │ 2019-05-04 │ 0        │ -0.370694  │ -0.376504 │ -0.116085  │\n",
       "│ 3   │ 2019-05-05 │ 0        │ -0.396293  │ -0.417149 │ -0.116085  │\n",
       "│ 4   │ 2019-05-06 │ 0        │ -0.396293  │ -0.417149 │ -0.116085  │\n",
       "│ 5   │ 2019-05-08 │ 0        │ -0.396293  │ -0.417149 │ -0.116085  │\n",
       "│ 6   │ 2019-05-09 │ 0        │ 0.742849   │ 1.39156   │ 0.201957   │\n",
       "│ 7   │ 2019-05-10 │ 1        │ 4.53146    │ 2.73285   │ 1.38394    │\n",
       "│ 8   │ 2019-05-17 │ 0        │ -0.332296  │ -0.356181 │ -0.0923509 │\n",
       "│ 9   │ 2019-05-18 │ 0        │ -0.396293  │ -0.417149 │ -0.116085  │\n",
       "│ 10  │ 2019-05-28 │ 0        │ -0.357895  │ -0.356181 │ -0.0686164 │"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_4380 = test_set;\n",
    "pred_4380[!, :SURVERSE] = test_pred;\n",
    "vis_ft = [:DATE, :SURVERSE, :FS_sum, :FS_max3, :SS_sum, :SS_max3];\n",
    "first(pred_4380[!, vis_ft], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = CSV.read(\"data/test.csv\");\n",
    "test_set[!, :SURVERSE] = zeros(size(test_set, 1));\n",
    "size(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque ligne de test_set\n",
    "\n",
    "    - On check l'ID de l'ouvrage pour savoir quel prediction load\n",
    "    - On va chercher la prediction à telle date pour cet ouvrage\n",
    "    - On le met à la ligne courante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(test_set, 1)\n",
    "    curr_ouvrage = test_set[i, 1];\n",
    "    pred_to_use = nothing;\n",
    "    if curr_ouvrage == \"3260-01D\"\n",
    "        pred_to_use = pred_3260;\n",
    "    elseif curr_ouvrage == \"3350-07D\"\n",
    "        pred_to_use = pred_3350;\n",
    "    elseif curr_ouvrage == \"4240-01D\"\n",
    "        pred_to_use = pred_4240;\n",
    "    elseif curr_ouvrage == \"4350-01D\"\n",
    "        pred_to_use = pred_4350;\n",
    "    elseif curr_ouvrage == \"4380-01D\"\n",
    "        pred_to_use = pred_4380;\n",
    "    end\n",
    "    \n",
    "    curr_date = test_set[i, :DATE];\n",
    "    pred_res = filter(row -> row.DATE == curr_date, pred_to_use);\n",
    "    \n",
    "    test_set[i, :SURVERSE] = pred_res[1, :SURVERSE];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>NO_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>10 rows × 3 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-05-02</td><td>0</td></tr><tr><th>2</th><td>3260-01D</td><td>2019-05-09</td><td>1</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-05-10</td><td>1</td></tr><tr><th>4</th><td>3260-01D</td><td>2019-05-15</td><td>0</td></tr><tr><th>5</th><td>3260-01D</td><td>2019-05-20</td><td>0</td></tr><tr><th>6</th><td>3260-01D</td><td>2019-05-23</td><td>1</td></tr><tr><th>7</th><td>3260-01D</td><td>2019-05-24</td><td>0</td></tr><tr><th>8</th><td>3260-01D</td><td>2019-05-26</td><td>0</td></tr><tr><th>9</th><td>3260-01D</td><td>2019-05-30</td><td>0</td></tr><tr><th>10</th><td>3350-07D</td><td>2019-05-01</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& NO\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-05-02 & 0 \\\\\n",
       "\t2 & 3260-01D & 2019-05-09 & 1 \\\\\n",
       "\t3 & 3260-01D & 2019-05-10 & 1 \\\\\n",
       "\t4 & 3260-01D & 2019-05-15 & 0 \\\\\n",
       "\t5 & 3260-01D & 2019-05-20 & 0 \\\\\n",
       "\t6 & 3260-01D & 2019-05-23 & 1 \\\\\n",
       "\t7 & 3260-01D & 2019-05-24 & 0 \\\\\n",
       "\t8 & 3260-01D & 2019-05-26 & 0 \\\\\n",
       "\t9 & 3260-01D & 2019-05-30 & 0 \\\\\n",
       "\t10 & 3350-07D & 2019-05-01 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×3 DataFrame\n",
       "│ Row │ NO_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-05-02 │ 0        │\n",
       "│ 2   │ 3260-01D   │ 2019-05-09 │ 1        │\n",
       "│ 3   │ 3260-01D   │ 2019-05-10 │ 1        │\n",
       "│ 4   │ 3260-01D   │ 2019-05-15 │ 0        │\n",
       "│ 5   │ 3260-01D   │ 2019-05-20 │ 0        │\n",
       "│ 6   │ 3260-01D   │ 2019-05-23 │ 1        │\n",
       "│ 7   │ 3260-01D   │ 2019-05-24 │ 0        │\n",
       "│ 8   │ 3260-01D   │ 2019-05-26 │ 0        │\n",
       "│ 9   │ 3260-01D   │ 2019-05-30 │ 0        │\n",
       "│ 10  │ 3350-07D   │ 2019-05-01 │ 1        │"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[!, :SURVERSE] = convert(Array{Int}, test_set[!, :SURVERSE]);\n",
    "first(test_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"submissions/mc-submission-22.csv\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = test_set[:,:NO_OUVRAGE].*\"_\".*string.(test_set[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=test_set[:, :SURVERSE])\n",
    "CSV.write(\"submissions/mc-submission-$(no_soumission).csv\",sampleSubmission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
