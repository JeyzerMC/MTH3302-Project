{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg;\n",
    "# Pkg.add(\"CSV\");\n",
    "# Pkg.add(\"Random\");\n",
    "# Pkg.add(\"DataStructures\");\n",
    "# Pkg.add(\"BenchmarkTools\");\n",
    "# Pkg.add(\"DataFrames\");\n",
    "# Pkg.add(\"Statistics\");\n",
    "# Pkg.add(\"Dates\");\n",
    "# Pkg.add(\"Gadfly\");\n",
    "# Pkg.add(\"MLBase\");\n",
    "# Pkg.add(\"DecisionTree\");\n",
    "# Pkg.add(\"GLM\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, GLM, Statistics, Dates, Gadfly, Random, MLBase, DecisionTree;\n",
    "include(\"utils/precipitation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ouvrages_surverse.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID_ouvrage, Latitude, Longitude, Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages = CSV.read(\"data/ouvrages-surverses.csv\");\n",
    "colnames = [\"N_Env\", \"ID_SOMA\", \"ID_OUVRAGE\", \"NOM\", \"SOMA_SEC\", \"REGION\", \"TP_X\", \"TP_Y\", \"TP_Z\", \"TP_LAT\", \"TP_LNG\", \"EMI_X\", \"EMI_Y\", \"EMI_LNG\", \"EMI_LAT\"];\n",
    "names!(ouvrages, Symbol.(colnames));\n",
    "# select!(ouvrages, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing Z index with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages.TP_Z = coalesce.(ouvrages.TP_Z, mean(ouvrages[completecases(ouvrages), :].TP_Z));\n",
    "first(shuffleDf(ouvrages), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualtion des données chargées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages, x=:TP_Z, Geom.histogram(bincount=50), Guide.xlabel(\"Height of TropPlein\"),Guide.ylabel(\"Frequency\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages,x=:EMI_X, y=:EMI_Y, Geom.point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages,x=:TP_X, y=:TP_Y, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Surverses.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO_ouvrage, Date, Surverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\", missingstring=\"-99999\");\n",
    "\n",
    "first(shuffleDf(surverses),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter non rain surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raison = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "surverses[!,:RAISON] = raison;\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove missing data and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = dropmissing(surverses, disallowmissing=true);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "first(shuffleDf(surverses), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Precipitation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date, Heure, McTavish, Bellevue, Assomption, Trudeau, StHubert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and filter months between May & October included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitations, Symbol(\"St-Hubert\")=>:StHubert);\n",
    "\n",
    "precipitations = filter(row -> month(row.date) > 4, precipitations);\n",
    "precipitations = filter(row -> month(row.date) < 11, precipitations); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(precipitations),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing data by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD WAY\n",
    "\n",
    "#precipitation[!,:McTavish] = coalesce.(precipitation[:,:McTavish], 0);\n",
    "#precipitation[!,:Bellevue] = coalesce.(precipitation[:,:Bellevue], 0);\n",
    "#precipitation[!,:Assomption] = coalesce.(precipitation[:,:Assomption], 0);\n",
    "#precipitation[!,:Trudeau] = coalesce.(precipitation[:,:Trudeau], 0);\n",
    "#precipitation[!,:StHubert] = coalesce.(precipitation[:,:StHubert], 0);\n",
    "\n",
    "#first(shuffleDf(precipitation), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_by_day = by(precipitations, :date,  \n",
    "                            McTavish = :McTavish=>mean_wo_missing, \n",
    "                            Bellevue = :Bellevue=>mean_wo_missing, \n",
    "                            Assomption = :Assomption=>mean_wo_missing,\n",
    "                            Trudeau = :Trudeau=>mean_wo_missing,\n",
    "                            StHubert = :StHubert=>mean_wo_missing)\n",
    "\n",
    "for i=1:size(precipitations,1)\n",
    "    if isequal(precipitations[i, :McTavish], missing)\n",
    "        precipitations[i,:McTavish] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:McTavish][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Bellevue], missing)\n",
    "        precipitations[i,:Bellevue] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Bellevue][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Assomption], missing)\n",
    "        precipitations[i,:Assomption] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Assomption][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Trudeau], missing)\n",
    "        precipitations[i,:Trudeau] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Trudeau][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :StHubert], missing)\n",
    "        precipitations[i,:StHubert] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:StHubert][1]\n",
    "    end\n",
    "end\n",
    "\n",
    "first(shuffleDf(precipitations), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Precipitation aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of precipitation for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>sum, \n",
    "            Bellevue = :Bellevue=>sum,\n",
    "            Assomption = :Assomption=>sum, \n",
    "            Trudeau = :Trudeau=>sum, \n",
    "            StHubert = :StHubert=>sum);\n",
    "first(shuffleDf(pcp_sum), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation visuelle des données enregistrées des différentes stations. \n",
    "(C'est intéractif ! Vous pouvez choisir quelles distributions voir !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_for_plot = pcp_sum\n",
    "df_for_plot = filter(row -> year(row.date) == 2016, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = filter(row -> year(row.date) == 2019, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_plot = 2013;\n",
    "df_for_plot = filter(row -> year(row.date) == date_to_plot, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plt_a = plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable);\n",
    "\n",
    "surv_to_plot = filter(row -> year(row.DATE) == date_to_plot && row.SURVERSE == 1, surverses)\n",
    "select!(surv_to_plot, [:DATE, :SURVERSE])\n",
    "surv_date = by(surv_to_plot, :DATE, :SURVERSE => sum)\n",
    "plt_b = plot(surv_date, x=:DATE, y=:SURVERSE_sum, Geom.line);\n",
    "set_default_plot_size(25cm, 13cm)\n",
    "hstack(plt_a, plt_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first(shuffleDf(surverses), 10);\n",
    "surv_to_plot = filter(row -> year(row.DATE) == 2014 && row.SURVERSE == 1, surverses)\n",
    "select!(surv_to_plot, [:DATE, :SURVERSE])\n",
    "surv_date = by(surv_to_plot, :DATE, :SURVERSE => sum)\n",
    "plot(surv_date, x=:DATE, y=:SURVERSE_sum, Geom.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum precipitation in an hour for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>maximum,\n",
    "            Bellevue = :Bellevue=>maximum, \n",
    "            Assomption = :Assomption=>maximum,\n",
    "            Trudeau = :Trudeau=>maximum,\n",
    "            StHubert = :StHubert=>maximum)\n",
    "first(shuffleDf(pcp_max),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation visuelle des données enregistrées des différentes stations\n",
    "\n",
    "(C'est intéractif ! Vous pouvez choisir quelles distributions voir !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_max\n",
    "df_for_plot = filter(row -> year(row.date) == 2013, pcp_max);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = filter(row -> year(row.date) == 2019, pcp_max);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum precipitation during three consecutive hours in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max3h = by(precipitations, :date,\n",
    "                McTavish = :McTavish=>maximum3,\n",
    "                Bellevue = :Bellevue=>maximum3,\n",
    "                Assomption = :Assomption=>maximum3,\n",
    "                Trudeau = :Trudeau=>maximum3,\n",
    "                StHubert = :StHubert=>maximum3)\n",
    "first(shuffleDf(pcp_max3h),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation visuelle des données enregistrées des différentes stations\n",
    "\n",
    "(C'est intéractif ! Vous pouvez choisir quelles distributions voir !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_max3h\n",
    "df_for_plot = filter(row -> year(row.date) == 2018, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of all three agregations for 1 meteo station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_pt = 2018;\n",
    "loc = :McTavish\n",
    "mct_sum = pcp_sum[:,[1,2]]\n",
    "rename!(mct_sum, loc => :Sum);\n",
    "mct_sum = filter(row -> year(row.date) == date_to_pt, mct_sum);\n",
    "\n",
    "mct_max = pcp_max[:,[1,2]]\n",
    "rename!(mct_max,loc => :Max);\n",
    "mct_max = filter(row -> year(row.date) == date_to_pt, mct_max);\n",
    "\n",
    "mct_max3h = pcp_max3h[:,[1,2]]\n",
    "rename!(mct_max3h,loc => :Max3h);\n",
    "mct_max3h = filter(row -> year(row.date) == date_to_pt, mct_max3h);\n",
    "\n",
    "df_for_plot = join(mct_sum, mct_max3h, on = :date);\n",
    "df_for_plot = join(df_for_plot, mct_max, on = :date);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = CSV.read(\"data/test.csv\");\n",
    "rename!(X_test, :NO_OUVRAGE => :ID_OUVRAGE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = join(ouvrages, X_test, on =:ID_OUVRAGE);\n",
    "features = join(ouvrages, surverses, on =:ID_OUVRAGE);\n",
    "srv = filter(row -> row.SURVERSE == 1, features);\n",
    "first(shuffleDf(srv), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_for_geo_plot = filter(row -> row.DATE == Date(2018,7,25), features)\n",
    "df_for_geo_plot = filter(row -> row.DATE == Date(2015, 5, 30), features)\n",
    "# df_for_geo_plot = filter(row -> row.DATE == Date(2017, 10, 9), features)\n",
    "df_for_geo_plot[:SURVERSE] = convert(Array{Bool,1}, df_for_geo_plot[:SURVERSE])\n",
    "plot(df_for_geo_plot, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:SURVERSE, Guide.title(\"2018-07-25, état des surverses\"))\n",
    "#first(df_for_geo_plot,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add precipitation data to features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stations lat-lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = DataFrame(STATION = String[], LAT = Float64[], LNG = Float64[]);\n",
    "\n",
    "push!(station_df, [\"McTavish\", 45.504742, -73.579167]);\n",
    "push!(station_df, [\"Bellevue\", 45.427222, -73.929167]);\n",
    "push!(station_df, [\"Assomption\", 45.809444, -73.434722]);\n",
    "push!(station_df, [\"Trudeau\", 45.467778, -73.741667]);\n",
    "push!(station_df, [\"StHubert\", 45.5175, -73.416944]);\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add pcp_sum, pcp_max, pcp_max3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function addColsForPrecipationPerDay(df)\n",
    "    df[!, :PCP_SUM] = zeros(size(df, 1));\n",
    "    df[!, :PCP_MAX] = zeros(size(df, 1));\n",
    "    df[!, :PCP_MAX3] = zeros(size(df, 1));\n",
    "    df[!, :METEO] = fill(\"\", size(df, 1));\n",
    "    return df\n",
    "end\n",
    "\n",
    "X_test = addColsForPrecipationPerDay(X_test)\n",
    "permutecols!(X_test, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3]);\n",
    "    \n",
    "features = addColsForPrecipationPerDay(features)\n",
    "permutecols!(features, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3, :SURVERSE]);\n",
    "\n",
    "first(shuffleDf(features), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find closest station to each ouvrage and add pcp_sum and pcp_max to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fillPrecipitationWithClosestMeteoStation(df)\n",
    "    for i=1:size(df, 1)\n",
    "        id_ouvrage = df[i, 1]; \n",
    "        closest_station = \"McTavish\"; # initial value\n",
    "        shortest_dist = -1;\n",
    "\n",
    "        # Find closest station\n",
    "        for j=1:size(station_df, 1)\n",
    "            dist = findDistance(df[i, :TP_LAT], df[i, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "\n",
    "            if shortest_dist == -1 || dist < shortest_dist\n",
    "                shortest_dist = dist;\n",
    "                closest_station = station_df[j, :STATION];\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Augment comb with a weighted p_sum, based on the distance to the station\n",
    "        p_sum = pcp_sum[∈([df[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "    #     comb[i, :PCP_SUM] = p_sum[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_SUM] = p_sum[1]; \n",
    "\n",
    "        # Augment comb with a weighted p_max, based on the distance to the station\n",
    "        p_max = pcp_max[∈([df[i, :DATE]]).(pcp_max.date), Symbol(closest_station)]\n",
    "    #     comb[i, :PCP_MAX] = p_max[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_MAX] = p_max[1];\n",
    "\n",
    "        # Augment comb with a weighted p_max3h, based on the distance to the station\n",
    "        p_max3 = pcp_max3h[∈([df[i, :DATE]]).(pcp_max3h.date), Symbol(closest_station)]\n",
    "    #     comb[i, :PCP_MAX3] = p_max3[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_MAX3] = p_max3[1]; \n",
    "\n",
    "        df[i, :METEO] = closest_station\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = fillPrecipitationWithClosestMeteoStation(X_test)\n",
    "features = fillPrecipitationWithClosestMeteoStation(features)\n",
    "first(shuffleDf(features), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outlier in PCP_SUM and PCP_MAX AND PCP_MAX3 that cause compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "X_test[X_test[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "X_test[X_test[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;\n",
    "\n",
    "features[features[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "features[features[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "features[features[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;\n",
    "\n",
    "# first(shuffleDf(filter(row -> row.SURVERSE == 1, features)), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP location colored by their affiliation to its closest meteo station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_geo_plot = filter(row -> row.DATE == Date(2018,7,25), features)\n",
    "df_for_geo_plot[:SURVERSE] = convert(Array{Bool,1}, df_for_geo_plot[:SURVERSE])\n",
    "plot(df_for_geo_plot, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:METEO, Guide.title(\"2018-07-25, Regroupement par station météo\"))\n",
    "#first(df_for_geo_plot,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouvrage 3350-07D for 2018, when it overflow and quantity based on max3h rain fallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3260-01D dans Rivière-des-Prairies\n",
    "# 3350-07D dans Ahunstic\n",
    "# 4240-01D dans Pointe-aux-Trembles\n",
    "# 4350-01D dans le Vieux-Montréal\n",
    "# 4380-01D dans Verdun\n",
    "\n",
    "id_ouvrage_to_show = \"3350-07D\"\n",
    "df_temp = filter(row -> row.ID_OUVRAGE ∈ [id_ouvrage_to_show], features)\n",
    "df_temp = filter(row -> year(row.DATE) == 2018, df_temp);\n",
    "df_temp = df_temp[!,[:ID_OUVRAGE, :DATE, :PCP_MAX3, :SURVERSE]]\n",
    "df_temp[:SURVERSE] = convert(Array{Bool,1}, df_temp[:SURVERSE])\n",
    "\n",
    "\n",
    "\n",
    "plot(df_temp, x=:DATE, y=:PCP_MAX3, Geom.point, color=:SURVERSE,Guide.title(id_ouvrage_to_show))\n",
    "#first(shuffleDf(df_temp), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dates into months and days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function splitDateByMonthAndDay(df)\n",
    "    df[!,:MONTH] = month.(df.DATE);\n",
    "    df[!,:DAY] = day.(df.DATE);\n",
    "    return df\n",
    "end\n",
    "\n",
    "X_test = splitDateByMonthAndDay(X_test)\n",
    "features = splitDateByMonthAndDay(features)\n",
    "first(shuffleDf(features[!, [:DATE, :MONTH, :DAY]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataframes into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function partitionTrainTest(data, at = 0.8) # https://discourse.julialang.org/t/simple-tool-for-train-test-split/473/2\n",
    "    n = nrow(data)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return data[train_idx,:], data[test_idx,:]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standarizeTrainTestCol(X_train, X_test, col)\n",
    "    mean_train_col = mean(X_train[!, col]);\n",
    "    std_train_col = std(X_train[!, col]);\n",
    "    X_train[!, col] = (X_train[!, col] .- mean_train_col) ./ std_train_col;\n",
    "    X_test[!, col] = (X_test[!, col] .- mean_train_col) ./ std_train_col;\n",
    "    \n",
    "    return X_train, X_test\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Standardize the PCP and Date before splitting into X_train and X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(row -> year(row.DATE) == 2019, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = filter(row-> year(row.DATE) .< 2019, features)\n",
    "X_train = features\n",
    "\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_LAT)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_LNG)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_Z)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_SUM)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_MAX)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_MAX3)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :MONTH)\n",
    "X_train_all, X_test = standarizeTrainTestCol(X_train, X_test, :DAY)\n",
    "\n",
    "X_train, X_val = partitionTrainTest(X_train_all, 0.8)\n",
    "\n",
    "first(shuffleDf(X_train),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(X_test),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(X_val),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Standardize the PCP and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_pcpsum = mean(features.PCP_SUM);\n",
    "# std_pcpsum = std(features.PCP_SUM);\n",
    "# features.PCP_SUM = (features.PCP_SUM .- mean_pcpsum) ./ std_pcpsum;\n",
    "\n",
    "# mean_pcpmax = mean(features.PCP_MAX);\n",
    "# std_pcpmax = std(features.PCP_MAX);\n",
    "# features.PCP_MAX = (features.PCP_MAX .- mean_pcpmax) ./ std_pcpmax;\n",
    "\n",
    "# mean_pcpmax3 = mean(features.PCP_MAX3);\n",
    "# std_pcpmax3 = std(features.PCP_MAX3);\n",
    "# features.PCP_MAX3 = (features.PCP_MAX3 .- mean_pcpmax3) ./ std_pcpmax3;\n",
    "\n",
    "# meanmonth = mean(features.MONTH);\n",
    "# stdmonth = std(features.MONTH);\n",
    "# features.MONTH = (features.MONTH .- meanmonth) ./ stdmonth;\n",
    "\n",
    "# meanday = mean(features.DAY);\n",
    "# stdday = std(features.DAY);\n",
    "# features.DAY = (features.DAY .- meanday) ./ stdday;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(filter(row -> row.SURVERSE == 1, features)), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical!(X_train, :METEO)\n",
    "# levels(X_train[:, :METEO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_glm = [:TP_LAT, :TP_LNG, :TP_Z, :MONTH, :DAY, :PCP_SUM, :METEO, :SURVERSE];\n",
    "names(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_form = @formula(SURVERSE ~ TP_LAT + TP_LNG + TP_Z + MONTH + DAY + PCP_SUM + METEO);\n",
    "val_model = glm(val_form, X_train, Bernoulli(), LogitLink())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = X_val[!, :SURVERSE];\n",
    "val_pred = GLM.predict(val_model, X_val);\n",
    "\n",
    "threshold = 0.07;\n",
    "val_pred[val_pred .>= threshold] .= 1.0;\n",
    "val_pred[val_pred .< threshold] .= 0.0;\n",
    "val_pred = convert(Array{Int}, trunc.(val_pred));\n",
    "\n",
    "r = roc(val_labels, val_pred);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_glm = [:SURVERSE, :TP_LNG, :TP_Z, :MONTH, :PCP_SUM, :METEO];\n",
    "val_form = @formula(SURVERSE ~ TP_LNG + TP_Z + MONTH + PCP_SUM + METEO);\n",
    "names(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 20;\n",
    "batch_score = 0;\n",
    "batch_threshold = 0;\n",
    "\n",
    "for i=1:niter\n",
    "    # Split train and val sets\n",
    "    X_train_glm, X_val_glm = partitionTrainTest(X_train_all, 0.8);\n",
    "    \n",
    "    # Build features and labels\n",
    "    train_features = X_train_glm[:, names_glm];\n",
    "    \n",
    "    # Build model\n",
    "    val_model = glm(val_form, train_features, Bernoulli(), LogitLink())\n",
    "    \n",
    "    # Validate model\n",
    "    val_features = X_val_glm[:, names_glm];\n",
    "    val_labels = X_val_glm[!, :SURVERSE];\n",
    "    \n",
    "    # Get best threshold\n",
    "    start_threshold = 0.090;\n",
    "    max_threshold = 0.095;\n",
    "    step = 0.0002;\n",
    "    \n",
    "    best_threshold = start_threshold;\n",
    "    score = -1;\n",
    "    \n",
    "    # Get best threshold\n",
    "    for j=start_threshold:step:max_threshold\n",
    "        val_pred = GLM.predict(val_model, val_features);\n",
    "        val_pred[val_pred .>= j] .= 1.0;\n",
    "        val_pred[val_pred .< j] .= 0.0;\n",
    "        val_pred = convert(Array{Int}, trunc.(val_pred))\n",
    "        \n",
    "        r = roc(val_labels, val_pred);\n",
    "        new_score = f1score(r);\n",
    "        \n",
    "        if new_score > score\n",
    "            score = new_score\n",
    "            best_threshold = j\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    batch_score += score;\n",
    "    batch_threshold += best_threshold;\n",
    "end\n",
    "\n",
    "batch_threshold = batch_threshold / niter;\n",
    "batch_score = batch_score / niter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_features = X_train_all[:, names_glm];\n",
    "submit_labels = X_train_all[:, :SURVERSE];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = glm(val_form, submit_features, Bernoulli(), LogitLink())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical!(X_test, :METEO)\n",
    "levels(X_test[:, :METEO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = X_test[:, setdiff(names_glm, [:SURVERSE])]\n",
    "test_labels = GLM.predict(val_model, test_features);\n",
    "test_labels[test_labels .>= batch_threshold] .= 1.0;\n",
    "test_labels[test_labels .< batch_threshold] .= 0.0;\n",
    "test_labels = convert(Array{Int}, trunc.(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf = X_train;\n",
    "X_val_rf = X_val;\n",
    "X_test_rf = X_test;\n",
    "X_train_all_rf = X_train_all;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf[:, :METEO] = broadcast(convert_meteo, X_train[:, :METEO]);\n",
    "X_val_rf[:, :METEO] = broadcast(convert_meteo, X_val[:, :METEO]);\n",
    "X_test_rf[:, :METEO] = broadcast(convert_meteo, X_test[:, :METEO]);\n",
    "X_train_all_rf[:, :METEO] = broadcast(convert_meteo, X_train_all[:, :METEO]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ft = [:TP_LAT, :TP_LNG, :TP_Z, :MONTH, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3];\n",
    "nft = 5;\n",
    "ntrees = 120;\n",
    "podata = 0.85;\n",
    "maxd = 28;\n",
    "train_features = convert(Matrix{Float64},X_train_rf[:, names_ft]);\n",
    "train_labels = X_train_rf[:, :SURVERSE];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model = build_forest(train_labels, train_features, nft, ntrees, podata, maxd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model = build_forest(train_labels, train_features, nft, ntrees, podata, maxd)\n",
    "val_features = convert(Matrix{Float64},X_val_rf[:, names_ft]);\n",
    "val_labels = X_val_rf[!, :SURVERSE];\n",
    "val_pred = apply_forest(val_model, val_features);\n",
    "\n",
    "r = roc(val_labels, val_pred);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 10;\n",
    "batch_score = 0;\n",
    "\n",
    "for i=1:niter\n",
    "    # Split train and val sets\n",
    "    X_train_rf, X_val_rf = partitionTrainTest(X_train_all_rf, 0.8);\n",
    "    \n",
    "    # Build features and labels\n",
    "    train_features = convert(Matrix{Float64},X_train_rf[:, names_ft]);\n",
    "    train_labels = X_train_rf[:, :SURVERSE];\n",
    "    \n",
    "    # Build model\n",
    "    val_model = build_forest(train_labels, train_features, nft, ntrees, podata, maxd);\n",
    "    \n",
    "    # Validate model\n",
    "    val_features = convert(Matrix{Float64},X_val_rf[:, names_ft]);\n",
    "    val_labels = X_val_rf[!, :SURVERSE];\n",
    "    val_pred = apply_forest(val_model, val_features);\n",
    "\n",
    "    r = roc(val_labels, val_pred);\n",
    "    batch_score += f1score(r);\n",
    "end\n",
    "\n",
    "batch_score = batch_score / niter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_features =  convert(Matrix{Float64}, X_train_all_rf[:, names_ft]);\n",
    "submit_labels = X_train_all_rf[:, :SURVERSE];\n",
    "model = build_forest(submit_labels, submit_features, nft, ntrees, podata, maxd)\n",
    "\n",
    "test_features = convert(Matrix{Float64},X_test_rf[:, names_ft]);\n",
    "test_labels = apply_forest(model, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = X_test_rf[:,:ID_OUVRAGE].*\"_\".*string.(X_test_rf[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=test_labels)\n",
    "CSV.write(\"submissions/mc-submission-16.csv\",sampleSubmission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
