{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet: Débordement d'égouts\n",
    "## Rapport équipe 9 - A19\n",
    "#### Noboru Yoshida - Mehdi Chaid - Mathieu Giroud-Huppé - Maxime Gosselin\n",
    "#### 05 Décembre 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières\n",
    "\n",
    "1. [Objectif](#objectives)  \n",
    "2. [Méthode choisie](#chosen_method)\n",
    "3. [Traitement des données](#data_processing)  \n",
    "    1. [Chargement des données de l'ensemble d'entraînement](#data_loading) \n",
    "    2. [Nettoyage des données](#data_cleaning)  \n",
    "    3. [Augmentation des données](#data_augmentation)\n",
    "4. [Analyse exploratoire](#data_analysis)  \n",
    "    1. [Distance à la station météorologique](#distance-meteo) \n",
    "    2. [Hauteur du trop plein](#very-full-height)\n",
    "    3. [TODO: Continuer](#continue)\n",
    "5. [Sélection de modèles](#model-selection)\n",
    "    1. [Régression logistique](#logistic-reg)\n",
    "    2. [Classification bayésienne naive](#naive-bayes)\n",
    "    3. [Forêt aléatoire](#random-forest)\n",
    "    4. [Séparateur à vaste marge](#svm)\n",
    "6. [Améliorations possibles](#possible-improvements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"objectives\"></a>\n",
    "\n",
    "## 1. Objectif\n",
    "\n",
    "Ce rapport vise à fournir une prédiction sur les surverses dans plusieurs ouvrages sur l'île de Montréal. TODO: Continuer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chosen_method\"></a>\n",
    "\n",
    "## 2. Méthode choisie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_processing\"></a>\n",
    "\n",
    "## 3. Traitement des données\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, GLM, Statistics, Dates, Gadfly, Random, MLBase;\n",
    "include(\"utils/precipitation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Ouvrages_surverse.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous chargeons les données provenant du fichier <i>ouvrages-surverses.csv</i>. Il y a plusieurs colonnes dans cette table, mais nous sommes intéréssé que par 4 de ces colonnes. ID_ouvrage, Latitude, Longitude, TP_Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages = CSV.read(\"data/ouvrages-surverses.csv\");\n",
    "colnames = [\"N_Env\", \"ID_SOMA\", \"ID_OUVRAGE\", \"NOM\", \"SOMA_SEC\", \"REGION\", \"TP_X\", \"TP_Y\", \"TP_Z\", \"TP_LAT\", \"TP_LNG\", \"EMI_X\", \"EMI_Y\", \"EMI_LNG\", \"EMI_LAT\"];\n",
    "names!(ouvrages, Symbol.(colnames));\n",
    "select!(ouvrages, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputation des hauteurs de Trop-plein manquant par la moyenne des hauteurs des autres trop plein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages.TP_Z = coalesce.(ouvrages.TP_Z, mean(ouvrages[completecases(ouvrages), :].TP_Z));\n",
    "first(shuffleDf(ouvrages), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualtion des données chargées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages, x=:TP_Z, Geom.histogram(bincount=50), Guide.xlabel(\"Height of TropPlein\"),Guide.ylabel(\"Frequency\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages,x=:TP_LNG, y=:TP_LAT, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Surverses.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous chargeons les données du fichier <i>Surverses.csv</i>. Nous utilisons toutes les colonnes de ce taleau. Le fichier est structuré comme ceci : <br>\n",
    "\n",
    "|NO_Ouvrage|Date|Surverse|Raison|\n",
    "|---|---|---|---|\n",
    "|String|Date|Bool|String|\n",
    "\n",
    "NO_ouvrage : <br>\n",
    "Date : <br>\n",
    "Surverse : <br>\n",
    "Raison : <br>\n",
    "\n",
    "Au final, nous gardons que les trois premières colonnes. La colonne NO_Ouvrage sera renommé afin de servir de clé externe pour se joindre à la table des ouvrages créés plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\", missingstring=\"-99999\");\n",
    "first(shuffleDf(surverses),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garder les mois qui nous concerne. (Mai à Octobre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garder les raisons de surverse qui nous intéresse. (Pluie, Inconnue, TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raison = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "surverses[!,:RAISON] = raison;\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retirer les données manquantes ainsi que renommer la colonne NO_OUVRAGE en ID_OUVRAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = dropmissing(surverses, disallowmissing=true);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "first(shuffleDf(surverses), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Precipitation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous chargeons les données du fichier <i> Precipitation.csv </i>. Nous devons effectuer des fonctions d'aggrégation sur ce tableau avant de pouvoir l'intégré dans notre jeu de donnée de nos modèles. En effet, ce tableau contient les données de précipitation par heure pour chacune des cinqs stations météorologiques près de montréal. Cependant, notre jeu de données des features est seulement par jour. Nous allons donc applique 3 fonctions d'aggrégation différente, soit : Somme, Maximum et Maximum3h. \n",
    "\n",
    "\n",
    "Date, Heure, McTavish, Bellevue, Assomption, Trudeau, StHubert\n",
    "\n",
    "Contient toutes les données de précipitation des années 2013 à 2019 (train et test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitations, Symbol(\"St-Hubert\")=>:StHubert);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garder les mois qui nous concerne. (Mai à Octobre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = filter(row -> month(row.date) > 4, precipitations);\n",
    "precipitations = filter(row -> month(row.date) < 11, precipitations);\n",
    "first(shuffleDf(precipitations),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputation des données de précipitation manquante par la moyenne de la journée de la station concernée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_by_day = by(precipitations, :date,  \n",
    "                            McTavish = :McTavish=>mean_wo_missing, \n",
    "                            Bellevue = :Bellevue=>mean_wo_missing, \n",
    "                            Assomption = :Assomption=>mean_wo_missing,\n",
    "                            Trudeau = :Trudeau=>mean_wo_missing,\n",
    "                            StHubert = :StHubert=>mean_wo_missing)\n",
    "\n",
    "for i=1:size(precipitations,1)\n",
    "    if isequal(precipitations[i, :McTavish], missing)\n",
    "        precipitations[i,:McTavish] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:McTavish][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Bellevue], missing)\n",
    "        precipitations[i,:Bellevue] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Bellevue][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Assomption], missing)\n",
    "        precipitations[i,:Assomption] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Assomption][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Trudeau], missing)\n",
    "        precipitations[i,:Trudeau] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Trudeau][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :StHubert], missing)\n",
    "        precipitations[i,:StHubert] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:StHubert][1]\n",
    "    end\n",
    "end\n",
    "\n",
    "first(shuffleDf(precipitations), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Aggrégation des précipitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Somme des précipitations par jour par station météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>sum, \n",
    "            Bellevue = :Bellevue=>sum,\n",
    "            Assomption = :Assomption=>sum, \n",
    "            Trudeau = :Trudeau=>sum, \n",
    "            StHubert = :StHubert=>sum);\n",
    "first(shuffleDf(pcp_sum), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisation des précipitations par station météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_sum\n",
    "df_for_plot = filter(row -> year(row.date) == 2016, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maximum des précipitations par jour par station météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>maximum,\n",
    "            Bellevue = :Bellevue=>maximum, \n",
    "            Assomption = :Assomption=>maximum,\n",
    "            Trudeau = :Trudeau=>maximum,\n",
    "            StHubert = :StHubert=>maximum)\n",
    "first(shuffleDf(pcp_max),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisation des précipitations par station météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_max\n",
    "df_for_plot = filter(row -> year(row.date) == 2013, pcp_max);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maximum de précipitation durant 3 heures consécutives par heure par station météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max3h = by(precipitations, :date,\n",
    "                McTavish = :McTavish=>maximum3,\n",
    "                Bellevue = :Bellevue=>maximum3,\n",
    "                Assomption = :Assomption=>maximum3,\n",
    "                Trudeau = :Trudeau=>maximum3,\n",
    "                StHubert = :StHubert=>maximum3)\n",
    "first(shuffleDf(pcp_max3h),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisation des précipitations par station météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = pcp_max3h\n",
    "df_for_plot = filter(row -> year(row.date) == 2018, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des précipitation aggégrés d'une station pour une année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_pt = 2018;\n",
    "loc = :McTavish\n",
    "mct_sum = pcp_sum[:,[1,2]]\n",
    "rename!(mct_sum, loc => :Sum);\n",
    "mct_sum = filter(row -> year(row.date) == date_to_pt, mct_sum);\n",
    "\n",
    "mct_max = pcp_max[:,[1,2]]\n",
    "rename!(mct_max,loc => :Max);\n",
    "mct_max = filter(row -> year(row.date) == date_to_pt, mct_max);\n",
    "\n",
    "mct_max3h = pcp_max3h[:,[1,2]]\n",
    "rename!(mct_max3h,loc => :Max3h);\n",
    "mct_max3h = filter(row -> year(row.date) == date_to_pt, mct_max3h);\n",
    "\n",
    "df_for_plot = join(mct_sum, mct_max3h, on = :date);\n",
    "df_for_plot = join(df_for_plot, mct_max, on = :date);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jointure des Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement de l'ensemble de test et jointure de ouvrages et surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = CSV.read(\"data/test.csv\"); #NO_OUVRAGE, DATE\n",
    "rename!(X_test, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "\n",
    "X_test = join(ouvrages, X_test, on =:ID_OUVRAGE);\n",
    "features = join(ouvrages, surverses, on =:ID_OUVRAGE);\n",
    "\n",
    "srv = filter(row -> row.SURVERSE == 1, features);\n",
    "first(shuffleDf(srv), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des stations en surverse et en non-surverse à une date donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_for_geo_plot = filter(row -> row.DATE == Date(2018,7,25), features)\n",
    "df_for_geo_plot = filter(row -> row.DATE == Date(2015, 5, 30), features)\n",
    "# df_for_geo_plot = filter(row -> row.DATE == Date(2017, 10, 9), features)\n",
    "df_for_geo_plot[:SURVERSE] = convert(Array{Bool,1}, df_for_geo_plot[:SURVERSE])\n",
    "plot(df_for_geo_plot, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:SURVERSE, Guide.title(\"2018-07-25, état des surverses\"))\n",
    "#first(df_for_geo_plot,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation afin d'assigner les données de précipitations aux ouvrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = DataFrame(STATION = String[], LAT = Float64[], LNG = Float64[]);\n",
    "\n",
    "push!(station_df, [\"McTavish\",   45.504742, -73.579167]);\n",
    "push!(station_df, [\"Bellevue\",   45.427222, -73.929167]);\n",
    "push!(station_df, [\"Assomption\", 45.809444, -73.434722]);\n",
    "push!(station_df, [\"Trudeau\",    45.467778, -73.741667]);\n",
    "push!(station_df, [\"StHubert\",   45.517500, -73.416944]);\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout de colonnes vides dans les jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function addColsForPrecipationPerDay(df)\n",
    "    df[!, :PCP_SUM] = zeros(size(df, 1));\n",
    "    df[!, :PCP_MAX] = zeros(size(df, 1));\n",
    "    df[!, :PCP_MAX3] = zeros(size(df, 1));\n",
    "    df[!, :METEO] = fill(\"\", size(df, 1));\n",
    "    return df\n",
    "end\n",
    "\n",
    "X_test = addColsForPrecipationPerDay(X_test)\n",
    "permutecols!(X_test, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3]);\n",
    "    \n",
    "features = addColsForPrecipationPerDay(features)\n",
    "permutecols!(features, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :METEO, :PCP_SUM, :PCP_MAX, :PCP_MAX3, :SURVERSE]);\n",
    "\n",
    "first(shuffleDf(features), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jointure des précipitations aggrégés aux jeux de données basé sur la station météo la plus près de l'ouvrage concerné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fillPrecipitationWithClosestMeteoStation(df)\n",
    "    for i=1:size(df, 1)\n",
    "        id_ouvrage = df[i, 1]; \n",
    "        closest_station = \"McTavish\"; # initial value\n",
    "        shortest_dist = -1;\n",
    "\n",
    "        # Find closest station\n",
    "        for j=1:size(station_df, 1)\n",
    "            dist = findDistance(df[i, :TP_LAT], df[i, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "\n",
    "            if shortest_dist == -1 || dist < shortest_dist\n",
    "                shortest_dist = dist;\n",
    "                closest_station = station_df[j, :STATION];\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Augment comb with a weighted p_sum, based on the distance to the station\n",
    "        p_sum = pcp_sum[∈([df[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "    #     comb[i, :PCP_SUM] = p_sum[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_SUM] = p_sum[1]; \n",
    "\n",
    "        # Augment comb with a weighted p_max, based on the distance to the station\n",
    "        p_max = pcp_max[∈([df[i, :DATE]]).(pcp_max.date), Symbol(closest_station)]\n",
    "    #     comb[i, :PCP_MAX] = p_max[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_MAX] = p_max[1];\n",
    "\n",
    "        # Augment comb with a weighted p_max3h, based on the distance to the station\n",
    "        p_max3 = pcp_max3h[∈([df[i, :DATE]]).(pcp_max3h.date), Symbol(closest_station)]\n",
    "    #     comb[i, :PCP_MAX3] = p_max3[1] * (1 - shortest_dist);\n",
    "        df[i, :PCP_MAX3] = p_max3[1]; \n",
    "\n",
    "        df[i, :METEO] = closest_station\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = fillPrecipitationWithClosestMeteoStation(X_test)\n",
    "features = fillPrecipitationWithClosestMeteoStation(features)\n",
    "first(shuffleDf(features), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrait des données extrêmes de précipitation. Purement subjectif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "X_test[X_test[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "X_test[X_test[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;\n",
    "\n",
    "features[features[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "features[features[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "features[features[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des stations et leur station météo associée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_geo_plot = filter(row -> row.DATE == Date(2018,7,25), features)\n",
    "df_for_geo_plot[:SURVERSE] = convert(Array{Bool,1}, df_for_geo_plot[:SURVERSE])\n",
    "plot(df_for_geo_plot, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:METEO, Guide.title(\"2018-07-25, Regroupement par station météo\"))\n",
    "#first(df_for_geo_plot,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouvrage 3350-07D pour 2018, quand il surverse, basé sur le critère max3h de pluie tombé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3260-01D dans Rivière-des-Prairies\n",
    "# 3350-07D dans Ahunstic\n",
    "# 4240-01D dans Pointe-aux-Trembles\n",
    "# 4350-01D dans le Vieux-Montréal\n",
    "# 4380-01D dans Verdun\n",
    "\n",
    "id_ouvrage_to_show = \"3350-07D\"\n",
    "df_temp = filter(row -> row.ID_OUVRAGE ∈ [id_ouvrage_to_show], features)\n",
    "df_temp = filter(row -> year(row.DATE) == 2018, df_temp);\n",
    "df_temp = df_temp[!,[:ID_OUVRAGE, :DATE, :PCP_MAX3, :SURVERSE]]\n",
    "df_temp[:SURVERSE] = convert(Array{Bool,1}, df_temp[:SURVERSE])\n",
    "\n",
    "\n",
    "\n",
    "plot(df_temp, x=:DATE, y=:PCP_MAX3, Geom.point, color=:SURVERSE,Guide.title(id_ouvrage_to_show))\n",
    "#first(shuffleDf(df_temp), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout de colonnes Mois (MONTH) et Jour (DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function splitDateByMonthAndDay(df)\n",
    "    df[!,:MONTH] = month.(df.DATE);\n",
    "    df[!,:DAY] = day.(df.DATE);\n",
    "    return df\n",
    "end\n",
    "\n",
    "X_test = splitDateByMonthAndDay(X_test)\n",
    "features = splitDateByMonthAndDay(features)\n",
    "first(shuffleDf(features[!, [:DATE, :MONTH, :DAY]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Déclaration de fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function partitionTrainTest(data, at = 0.8) # https://discourse.julialang.org/t/simple-tool-for-train-test-split/473/2\n",
    "    n = nrow(data)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return data[train_idx,:], data[test_idx,:]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standarizeTrainTestCol(X_train, X_test, col)\n",
    "    mean_train_col = mean(X_train[!, col]);\n",
    "    std_train_col = std(X_train[!, col]);\n",
    "    X_train[!, col] = (X_train[!, col] .- mean_train_col) ./ std_train_col;\n",
    "    X_test[!, col] = (X_test[!, col] .- mean_train_col) ./ std_train_col;\n",
    "    \n",
    "    return X_train, X_test\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function oneHotTrainTestCol(X_train, X_test, col, nb_cat)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization des colonnes et création de l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features\n",
    "\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_LAT)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_LNG)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :TP_Z)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_SUM)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_MAX)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :PCP_MAX3)\n",
    "X_train, X_test = standarizeTrainTestCol(X_train, X_test, :MONTH)\n",
    "X_train_all, X_test = standarizeTrainTestCol(X_train, X_test, :DAY)\n",
    "\n",
    "X_train, X_val = partitionTrainTest(X_train_all, 0.8)\n",
    "\n",
    "first(shuffleDf(X_train),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(X_test),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(X_val),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_analysis\"></a>\n",
    "\n",
    "## 4. Analyse exploratoire\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
