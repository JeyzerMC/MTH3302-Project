{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-selection\"></a>\n",
    "\n",
    "## 4. Sélection de modèles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"logistic-reg\"></a>\n",
    "### 4.1 Régression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.4.1.\"></a>\n",
    "#### 4.4.1. Théorie de la régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle de régression logistique sert à modéliser une variable d'intérêt de type Bernoulli *Y* à l'aide d'une fonction logistique. Dans un tel cas, la variable *Y* représente la probabilité de succès d'un évènement, c'est-à-dire qu'elle prend une valeur entre 0 et 1. Le lien entre la variable *Y* et les *p* variables explicatives ne peut alors pas être exprimé selon une relation linéaire. Cependant, on peut considérer une relation linéaire entre la fonction logit et les *p* variables explicatives. Dans la régression logistique, les coefficients de régression permettent de représenter l'effet de chaque variable expliative sur la variation de la cote (rapport entre la probabilité de succès et la probabilité d'échec) et ceux-ci peuvent être estimé à l'aide de la méthode du maximum de la vraisemblance.\n",
    "\n",
    "Tout comme les autres modèles statistiques, la régression logistique possède des points forts et faibles:\n",
    "\n",
    "Les avantages de la régression logistique sont:\n",
    "- La facilité de l'implémentation\n",
    "- Les variables explicatives n'ont pas à être standardizé\n",
    "\n",
    "Les désavantages de la régression logistique sont:\n",
    "- Une sélection des variables explicatives nécessaire\n",
    "- Pas très performant\n",
    "\n",
    "D'abord, cette méthode est très facile à implémenter, car il n'y a pas beaucoup d'étapes à exécuter et ce n'est pas exigeant en terme de puissance computationnelle. Aussi, les variables explicatives n'ont pas besoin d'être standardizé, donc seulement peu de manipulations pour la transformation de données sont nécessaires pour construire ce modèle. Des désavantages sont également présents. La régression logistique ne peut être performant que si les variables explicatives dont elle utilise sont bien sélectionnées. Des variables qui n'affectent pas du tout la variable de prédiction ou plusieurs varibles qui sont corrélées entre elles peuvent être des bruits pour le modèle et influencer négativement le résultat de la prédiction. De plus, de manière générale, la régression logistique n'est pas un algorithme de classification super performant. D'autres méthodes donnent souvent de meilleurs résultats de prédiction selon le type de problème à résoudre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Entraînement et prédiction du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entraînement et la prédiction du modèle de régression logistique ne sont pas très compliqués. Il suffit de d'abord bien choisir les variables explicatives à évaluer et ensuite à modéliser la variable à prédire selon les variables explicatives choisies à l'aide de la fonction logistique. Il reste par la suite à choisir le seuil qui permet de trier le mieux possible les prédictions réalisées (qui sont des probabilités entre 0 et 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.1 Sélection des variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous définissons les variables explicatives pouvant être utilisées pour notre modèle. Comme mentionné dans la section précédente où l'on décrit la théorie du présent modèle, il est impératif de choisir les bonnes variables explicatives afin de réduire le plus possible les problèmes comme le surapprentissage. On ne prend que les variables qui semblent affecter la présence d'une surverse (c'est-à-dire, la position des ouvrages, la date et la quantité de précipitations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_glm = [:TP_LAT, :TP_LNG, :TP_Z, :MONTH, :DAY, :PCP_SUM, :PCP_MAX, :PCP_MAX3, :SURVERSE];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.2 Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous crééons le modèle de régression logistique en utilisant la fonction glm avec la liste de variables explicatives qui y seront évaluées.\n",
    "La fonction glm permet de construire un modèle de *n* variables explicatives à l'aide de la relation *$log_2(n+1)$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train[:, names_glm];\n",
    "val_form = @formula(SURVERSE ~ TP_LAT + TP_LNG + TP_Z + MONTH + DAY + PCP_SUM + PCP_MAX + PCP_MAX3);\n",
    "\n",
    "val_model = glm(val_form, train_features, Bernoulli(), LogitLink());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.3 Validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons enfin faire la validation de notre modèle. On fait d'abord des prédictions basées sur les données que nous avons utilisé pour construire le modèle. Les prédictions calculées sont des valeurs entre 0 et 1 qui correspondent à la probabilité qu'une surverse ait lieue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: val_set not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: val_set not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": [
    "val_features = val_set[:, names_glm];\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "val_pred = GLM.predict(val_model, val_features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons comme seuil, 0.15 pour trier les prédictions calculées précédemment. C'est-à-dire qu les valeurs qui sont supérieures au seuil seront remplacées par 1 (il y a surverse) et celles qui sont inférieures par 0 (il n'y a pas surverse).\n",
    "Ensuite nous convertissons ces valeurs de prédiction en un tableau de *Int* afin de pouvoir déterminer le F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15;\n",
    "val_pred[val_pred .>= threshold] .= 1.0;\n",
    "val_pred[val_pred .< threshold] .= 0.0;\n",
    "val_pred = convert(Array{Int}, trunc.(val_pred))\n",
    "\n",
    "r = roc(val_labels, val_pred);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite tenter de trouver un seuil qui fonctionne le mieux dans notre contexte en réalisant plusieurs essais, en modifiant légèrement la valeur de seuil à chaque itération. Nous commençons avec un seuil de 0.1 et on cherche la valeur qui donne le meilleur F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 10;\n",
    "batch_score = 0;\n",
    "batch_threshold = 0;\n",
    "\n",
    "for i=1:niter\n",
    "    # Split train and val sets\n",
    "    r_idx = shuffle(1:size(comb, 1));\n",
    "    train_ceil = floor(Int, size(r_idx, 1) * 0.8);\n",
    "    train_set = comb[r_idx[1:train_ceil], :];\n",
    "    val_set = comb[r_idx[train_ceil+1:size(r_idx, 1)], :];\n",
    "    \n",
    "    # Build features and labels\n",
    "    train_features = train_set[:, names_glm];\n",
    "    \n",
    "    # Build model\n",
    "    val_model = glm(val_form, train_features, Bernoulli(), LogitLink())\n",
    "    \n",
    "    # Validate model\n",
    "    val_features = val_set[:, names_glm];\n",
    "    val_labels = val_set[!, :SURVERSE];\n",
    "    \n",
    "    # Get best threshold\n",
    "    start_threshold = 0.1;\n",
    "    max_threshold = 0.15;\n",
    "    step = 0.0002;\n",
    "    \n",
    "    best_threshold = start_threshold;\n",
    "    score = -1;\n",
    "    \n",
    "    # Get best threshold\n",
    "    for j=start_threshold:step:max_threshold\n",
    "        val_pred = GLM.predict(val_model, val_features);\n",
    "        val_pred[val_pred .>= j] .= 1.0;\n",
    "        val_pred[val_pred .< j] .= 0.0;\n",
    "        val_pred = convert(Array{Int}, trunc.(val_pred))\n",
    "        \n",
    "        r = roc(val_labels, val_pred);\n",
    "        new_score = f1score(r);\n",
    "        \n",
    "        if new_score > score\n",
    "            score = new_score\n",
    "            best_threshold = j\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    batch_score += score;\n",
    "    batch_threshold += best_threshold;\n",
    "end\n",
    "\n",
    "batch_threshold = batch_threshold / niter;\n",
    "batch_score = batch_score / niter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.4 Prédiction finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la valeur du threshhold et le F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random-forest\"></a>\n",
    "### 4.3 Forêt Aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svm\"></a>\n",
    "### 4.4 Séparateur à vaste marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"possible-improvements\"></a>\n",
    "### 5. Améliorations possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
