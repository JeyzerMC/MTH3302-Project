{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-selection\"></a>\n",
    "\n",
    "## 4. Sélection de modèles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"logistic-reg\"></a>\n",
    "### 4.1 Régression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.4.1.\"></a>\n",
    "#### 4.4.1. Théorie de la régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle de régression logistique sert à modéliser une variable d'intérêt de type Bernoulli *Y* à l'aide d'une fonction logistique. Dans un tel cas, la variable *Y* représente la probabilité de succès d'un évènement, c'est-à-dire qu'elle prend une valeur entre 0 et 1. Le lien entre la variable *Y* et les *p* variables explicatives ne peut alors pas être exprimé selon une relation linéaire. Cependant, on peut considérer une relation linéaire entre la fonction logit et les *p* variables explicatives. Dans la régression logistique, les coefficients de régression permettent de représenter l'effet de chaque variable expliative sur la variation de la cote (rapport entre la probabilité de succès et la probabilité d'échec) et ceux-ci peuvent être estimé à l'aide de la méthode du maximum de la vraisemblance.\n",
    "\n",
    "Tout comme les autres modèles statistiques, la régression logistique possède des points forts et faibles:\n",
    "\n",
    "Les avantages de la régression logistique sont:\n",
    "- La facilité de l'implémentation\n",
    "- Les variables explicatives n'ont pas à être standardizé\n",
    "\n",
    "Les désavantages de la régression logistique sont:\n",
    "- Une sélection des variables explicatives nécessaire\n",
    "- Pas très performant\n",
    "\n",
    "D'abord, cette méthode est très facile à implémenter, car il n'y a pas beaucoup d'étapes à exécuter et ce n'est pas exigeant en terme de puissance computationnelle. Aussi, les variables explicatives n'ont pas besoin d'être standardizé, donc seulement peu de manipulations pour la transformation de données sont nécessaires pour construire ce modèle. Des désavantages sont également présents. La régression logistique ne peut être performant que si les variables explicatives dont elle utilise sont bien sélectionnées. Des variables qui n'affectent pas du tout la variable de prédiction ou plusieurs varibles qui sont corrélées entre elles peuvent être des bruits pour le modèle et influencer négativement le résultat de la prédiction. De plus, de manière générale, la régression logistique n'est pas un algorithme de classification super performant. D'autres méthodes donnent souvent de meilleurs résultats de prédiction selon le type de problème à résoudre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Entraînement et prédiction du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entraînement et la prédiction du modèle de régression logistique ne sont pas très compliqués. Il suffit de d'abord bien choisir les variables explicatives à évaluer et ensuite à modéliser la variable à prédire selon les variables explicatives choisies à l'aide de la fonction logistique. Il reste par la suite à choisir le seuil qui permet de trier le mieux possible les prédictions réalisées (qui sont des probabilités entre 0 et 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.1 Sélection des variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous définissons les variables explicatives pouvant être utilisées pour notre modèle. Comme mentionné dans la section précédente où l'on décrit la théorie du présent modèle, il est impératif de choisir les bonnes variables explicatives afin de réduire le plus possible les problèmes comme le surapprentissage. On ne prend que les variables qui semblent affecter la présence d'une surverse (c'est-à-dire, la position des ouvrages, la date et la quantité de précipitations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_glm = [:TP_LAT, :TP_LNG, :TP_Z, :MONTH, :DAY, :PCP_SUM, :PCP_MAX, :PCP_MAX3, :SURVERSE];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.2 Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous crééons le modèle de régression logistique en utilisant la fonction glm avec la liste de variables explicatives qui y seront évaluées.\n",
    "La fonction glm permet de construire un modèle de *n* variables explicatives à l'aide de la relation *$log_2(n+1)$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train[:, names_glm];\n",
    "val_form = @formula(SURVERSE ~ TP_LAT + TP_LNG + TP_Z + MONTH + DAY + PCP_SUM + PCP_MAX + PCP_MAX3);\n",
    "\n",
    "val_model = glm(val_form, train_features, Bernoulli(), LogitLink());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.3 Validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons enfin faire la validation de notre modèle. On fait d'abord des prédictions basées sur les données que nous avons utilisé pour construire le modèle. Les prédictions calculées sont des valeurs entre 0 et 1 qui correspondent à la probabilité qu'une surverse ait lieue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: val_set not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: val_set not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": [
    "val_features = val_set[:, names_glm];\n",
    "val_labels = val_set[!, :SURVERSE];\n",
    "val_pred = GLM.predict(val_model, val_features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons comme seuil, 0.15 pour trier les prédictions calculées précédemment. C'est-à-dire qu les valeurs qui sont supérieures au seuil seront remplacées par 1 (il y a surverse) et celles qui sont inférieures par 0 (il n'y a pas surverse).\n",
    "Ensuite nous convertissons ces valeurs de prédiction en un tableau de *Int* afin de pouvoir déterminer le F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15;\n",
    "val_pred[val_pred .>= threshold] .= 1.0;\n",
    "val_pred[val_pred .< threshold] .= 0.0;\n",
    "val_pred = convert(Array{Int}, trunc.(val_pred))\n",
    "\n",
    "r = roc(val_labels, val_pred);\n",
    "f1score(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite tenter de trouver un seuil qui fonctionne le mieux dans notre contexte en réalisant plusieurs essais, en modifiant légèrement la valeur de seuil à chaque itération. Nous commençons avec un seuil de 0.1 et on cherche la valeur qui donne le meilleur F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 10;\n",
    "batch_score = 0;\n",
    "batch_threshold = 0;\n",
    "\n",
    "for i=1:niter\n",
    "    # Split train and val sets\n",
    "    r_idx = shuffle(1:size(comb, 1));\n",
    "    train_ceil = floor(Int, size(r_idx, 1) * 0.8);\n",
    "    train_set = comb[r_idx[1:train_ceil], :];\n",
    "    val_set = comb[r_idx[train_ceil+1:size(r_idx, 1)], :];\n",
    "    \n",
    "    # Build features and labels\n",
    "    train_features = train_set[:, names_glm];\n",
    "    \n",
    "    # Build model\n",
    "    val_model = glm(val_form, train_features, Bernoulli(), LogitLink())\n",
    "    \n",
    "    # Validate model\n",
    "    val_features = val_set[:, names_glm];\n",
    "    val_labels = val_set[!, :SURVERSE];\n",
    "    \n",
    "    # Get best threshold\n",
    "    start_threshold = 0.1;\n",
    "    max_threshold = 0.15;\n",
    "    step = 0.0002;\n",
    "    \n",
    "    best_threshold = start_threshold;\n",
    "    score = -1;\n",
    "    \n",
    "    # Get best threshold\n",
    "    for j=start_threshold:step:max_threshold\n",
    "        val_pred = GLM.predict(val_model, val_features);\n",
    "        val_pred[val_pred .>= j] .= 1.0;\n",
    "        val_pred[val_pred .< j] .= 0.0;\n",
    "        val_pred = convert(Array{Int}, trunc.(val_pred))\n",
    "        \n",
    "        r = roc(val_labels, val_pred);\n",
    "        new_score = f1score(r);\n",
    "        \n",
    "        if new_score > score\n",
    "            score = new_score\n",
    "            best_threshold = j\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    batch_score += score;\n",
    "    batch_threshold += best_threshold;\n",
    "end\n",
    "\n",
    "batch_threshold = batch_threshold / niter;\n",
    "batch_score = batch_score / niter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.4 Prédiction finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la valeur du threshhold et le F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.\"></a>\n",
    "### 4.3. Arbres de décision et forêt aléatoire [TODO: METTRE A JOUR TABLE DES MATIERES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.1.\"></a>\n",
    "#### 4.3.1. Théorie des arbres de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle d'arbres de décision est un algorithme d'apprentissage machine très puissant capable d'effectuer des tâches de classification, mais aussi de régression. Il permet de présenter le résultat d'une série de décisions qui ont été effectuées à l'aide de plusieurs variables explicatives. Dans notre cas, c'est la partie classification qui nous intéresse, car nous cherchons à déterminer si une surverse a eu lieu ou pas, selon certaines variables explicatives.\n",
    "\n",
    "Un arbre de décision est modélisé en prenant d'abord les variables explicatives et en calculant les indices de diversité de Gini de chacune. Ce dernier représente la fréquence que l'issu d'un nouvel élément de l'ensemble soit mal classé si la classification des variables explicatives se fait de manière aléatoire. En effet, on calcule l'indice de diversité de Gini de chaque variable explicative et on remplit l'arbre graduellement à partir de celle qui donne la meilleure valeur (les valeurs se situent entre 0 et 1, 0 étant la meilleure) vers velle qui donne la pire.\n",
    "\n",
    "Les avantages des arbres de décision sont:\n",
    "- La facilité de l'implémentation\n",
    "- L'efficacité pour identifier des variables explicatives significatives \n",
    "\n",
    "Les désavantages des arbres de décision sont:\n",
    "- Une faible précision de prédiction\n",
    "\n",
    "Le modèle d'arbres de décision est très facile à implémenter, des manipulations mathématiques ne sont pas nécessaire afin de réaliser la modélisation. Les données n'ont pas à être standardizé comme c'était le cas pour des modèles comme la régression logistique. De plus, ce modèle est connu pour être efficace en terme d'identification des variables explicatives qui sont significatives et pour repérer les relations entre plusieurs variables explicatives. En effet, la structure de l'arbre créée dépend des indices de diversité de Gini de chacune donc le lien entre les variables explicatives y est encapsulé. Cependant, comme tout autre modèle, les arbres de décision ont également des désavantages. Le principal inconvénient d'utiliser ces derniers est qu'il ne permet pas de donner des prédictions précises. C'est la raison pour laquelle il est rare qu'on utilise un arbre de décision directement sur un ensemble de données; on fait recours à un modèle qui se base sur celui-ci, comme c'est le cas pour le modèle de forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"svm\"></a>\n",
    "### 4.4 Séparateur à vaste marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"possible-improvements\"></a>\n",
    "### 5. Améliorations possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
