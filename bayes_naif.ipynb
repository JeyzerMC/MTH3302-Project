{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      " \u001b[90m [c8e1da08]\u001b[39m\u001b[92m + IterTools v1.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"CSV\");\n",
    "Pkg.add(\"Random\");\n",
    "Pkg.add(\"DataStructures\");\n",
    "Pkg.add(\"BenchmarkTools\");\n",
    "Pkg.add(\"DataFrames\");\n",
    "Pkg.add(\"Statistics\");\n",
    "Pkg.add(\"Dates\");\n",
    "Pkg.add(\"Gadfly\");\n",
    "Pkg.add(\"MLBase\");\n",
    "Pkg.add(\"DecisionTree\");\n",
    "Pkg.add(\"IterTools\");\n",
    "\n",
    "using CSV, DataFrames,Distributions,DataStructures,BenchmarkTools,DecisionTree, Statistics, Dates, Gadfly, Random, MLBase, IterTools;\n",
    "include(\"utils/precipitation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and filter the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latitude, Longitude, Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = CSV.read(\"data/ouvrages-surverses.csv\");\n",
    "colnames = [\"N_Env\", \"ID_SOMA\", \"ID_OUVRAGE\", \"NOM\", \"SOMA_SEC\", \"REGION\", \"TP_X\", \"TP_Y\", \"TP_Z\", \"TP_LAT\", \"TP_LNG\", \"EMI_X\", \"EMI_Y\", \"EMI_LNG\", \"EMI_LAT\"];\n",
    "names!(features, Symbol.(colnames));\n",
    "select!(features, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing Z index with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 4 columns</p><tr><th>1</th><td>4390-01D</td><td>45.4618</td><td>-73.5555</td><td>14.62</td></tr><tr><th>2</th><td>0801-06D</td><td>45.5187</td><td>-73.533</td><td>18.66</td></tr><tr><th>3</th><td>3370-01D</td><td>45.5653</td><td>-73.6631</td><td>18.21</td></tr><tr><th>4</th><td>3400-01D</td><td>45.5435</td><td>-73.6755</td><td>26.04</td></tr><tr><th>5</th><td>4280-01D</td><td>45.6009</td><td>-73.5111</td><td>12.53</td></tr><tr><th>6</th><td>3540-02D</td><td>45.4751</td><td>-73.8727</td><td>26.52</td></tr><tr><th>7</th><td>4620-05D</td><td>45.4254</td><td>-73.8902</td><td>32.55</td></tr><tr><th>8</th><td>4796-01D</td><td>45.45</td><td>-73.5686</td><td>15.747</td></tr><tr><th>9</th><td>3350-08D</td><td>45.5401</td><td>-73.7086</td><td>24.65</td></tr><tr><th>10</th><td>3240-04D</td><td>45.6531</td><td>-73.583</td><td>12.63</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 4390-01D & 45.4618 & -73.5555 & 14.62 \\\\\n",
       "\t2 & 0801-06D & 45.5187 & -73.533 & 18.66 \\\\\n",
       "\t3 & 3370-01D & 45.5653 & -73.6631 & 18.21 \\\\\n",
       "\t4 & 3400-01D & 45.5435 & -73.6755 & 26.04 \\\\\n",
       "\t5 & 4280-01D & 45.6009 & -73.5111 & 12.53 \\\\\n",
       "\t6 & 3540-02D & 45.4751 & -73.8727 & 26.52 \\\\\n",
       "\t7 & 4620-05D & 45.4254 & -73.8902 & 32.55 \\\\\n",
       "\t8 & 4796-01D & 45.45 & -73.5686 & 15.747 \\\\\n",
       "\t9 & 3350-08D & 45.5401 & -73.7086 & 24.65 \\\\\n",
       "\t10 & 3240-04D & 45.6531 & -73.583 & 12.63 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×4 DataFrame\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT  │ TP_LNG   │ TP_Z    │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼────────────┼─────────┼──────────┼─────────┤\n",
       "│ 1   │ 4390-01D   │ 45.4618 │ -73.5555 │ 14.62   │\n",
       "│ 2   │ 0801-06D   │ 45.5187 │ -73.533  │ 18.66   │\n",
       "│ 3   │ 3370-01D   │ 45.5653 │ -73.6631 │ 18.21   │\n",
       "│ 4   │ 3400-01D   │ 45.5435 │ -73.6755 │ 26.04   │\n",
       "│ 5   │ 4280-01D   │ 45.6009 │ -73.5111 │ 12.53   │\n",
       "│ 6   │ 3540-02D   │ 45.4751 │ -73.8727 │ 26.52   │\n",
       "│ 7   │ 4620-05D   │ 45.4254 │ -73.8902 │ 32.55   │\n",
       "│ 8   │ 4796-01D   │ 45.45   │ -73.5686 │ 15.747  │\n",
       "│ 9   │ 3350-08D   │ 45.5401 │ -73.7086 │ 24.65   │\n",
       "│ 10  │ 3240-04D   │ 45.6531 │ -73.583  │ 12.63   │"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.TP_Z = coalesce.(features.TP_Z, mean(features[completecases(features), :].TP_Z));\n",
    "first(shuffleDf(features), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dates and surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\",missingstring=\"-99999\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter non rain surverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "raison = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "surverses[!,:RAISON] = raison;\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove missing data and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>10 rows × 3 columns</p><tr><th>1</th><td>3410-01D</td><td>2016-06-20</td><td>0</td></tr><tr><th>2</th><td>3480-05D</td><td>2017-06-28</td><td>0</td></tr><tr><th>3</th><td>0801-08D</td><td>2013-08-03</td><td>0</td></tr><tr><th>4</th><td>4260-01D</td><td>2017-05-07</td><td>0</td></tr><tr><th>5</th><td>4350-01D</td><td>2013-05-02</td><td>0</td></tr><tr><th>6</th><td>3350-10D</td><td>2013-10-08</td><td>0</td></tr><tr><th>7</th><td>4430-06D</td><td>2013-05-22</td><td>0</td></tr><tr><th>8</th><td>4300-01D</td><td>2017-05-08</td><td>0</td></tr><tr><th>9</th><td>0672-02D</td><td>2013-06-14</td><td>0</td></tr><tr><th>10</th><td>3275-01D</td><td>2017-10-19</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ID\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3410-01D & 2016-06-20 & 0 \\\\\n",
       "\t2 & 3480-05D & 2017-06-28 & 0 \\\\\n",
       "\t3 & 0801-08D & 2013-08-03 & 0 \\\\\n",
       "\t4 & 4260-01D & 2017-05-07 & 0 \\\\\n",
       "\t5 & 4350-01D & 2013-05-02 & 0 \\\\\n",
       "\t6 & 3350-10D & 2013-10-08 & 0 \\\\\n",
       "\t7 & 4430-06D & 2013-05-22 & 0 \\\\\n",
       "\t8 & 4300-01D & 2017-05-08 & 0 \\\\\n",
       "\t9 & 0672-02D & 2013-06-14 & 0 \\\\\n",
       "\t10 & 3275-01D & 2017-10-19 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×3 DataFrame\n",
       "│ Row │ ID_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 3410-01D   │ 2016-06-20 │ 0        │\n",
       "│ 2   │ 3480-05D   │ 2017-06-28 │ 0        │\n",
       "│ 3   │ 0801-08D   │ 2013-08-03 │ 0        │\n",
       "│ 4   │ 4260-01D   │ 2017-05-07 │ 0        │\n",
       "│ 5   │ 4350-01D   │ 2013-05-02 │ 0        │\n",
       "│ 6   │ 3350-10D   │ 2013-10-08 │ 0        │\n",
       "│ 7   │ 4430-06D   │ 2013-05-22 │ 0        │\n",
       "│ 8   │ 4300-01D   │ 2017-05-08 │ 0        │\n",
       "│ 9   │ 0672-02D   │ 2013-06-14 │ 0        │\n",
       "│ 10  │ 3275-01D   │ 2017-10-19 │ 0        │"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surverses = dropmissing(surverses, disallowmissing=true);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "first(shuffleDf(surverses),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment features with dates and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>3350-08D</td><td>45.5401</td><td>-73.7086</td><td>24.65</td><td>2018-06-06</td><td>0</td></tr><tr><th>2</th><td>0642-01D</td><td>45.6727</td><td>-73.5262</td><td>19.3526</td><td>2016-07-25</td><td>0</td></tr><tr><th>3</th><td>4270-01D</td><td>45.6105</td><td>-73.5087</td><td>11.17</td><td>2016-10-20</td><td>0</td></tr><tr><th>4</th><td>3350-08D</td><td>45.5401</td><td>-73.7086</td><td>24.65</td><td>2013-07-18</td><td>0</td></tr><tr><th>5</th><td>3350-09D</td><td>45.5371</td><td>-73.713</td><td>23.72</td><td>2013-06-22</td><td>0</td></tr><tr><th>6</th><td>4360-01D</td><td>45.4907</td><td>-73.5508</td><td>15.15</td><td>2013-05-28</td><td>0</td></tr><tr><th>7</th><td>3350-07D</td><td>45.5461</td><td>-73.6921</td><td>20.75</td><td>2018-07-01</td><td>0</td></tr><tr><th>8</th><td>4240-02D</td><td>45.6498</td><td>-73.4877</td><td>19.29</td><td>2017-06-12</td><td>0</td></tr><tr><th>9</th><td>4610-06D</td><td>45.4305</td><td>-73.8563</td><td>29.05</td><td>2018-06-19</td><td>0</td></tr><tr><th>10</th><td>3350-10D</td><td>45.5372</td><td>-73.7129</td><td>23.73</td><td>2013-09-22</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3350-08D & 45.5401 & -73.7086 & 24.65 & 2018-06-06 & 0 \\\\\n",
       "\t2 & 0642-01D & 45.6727 & -73.5262 & 19.3526 & 2016-07-25 & 0 \\\\\n",
       "\t3 & 4270-01D & 45.6105 & -73.5087 & 11.17 & 2016-10-20 & 0 \\\\\n",
       "\t4 & 3350-08D & 45.5401 & -73.7086 & 24.65 & 2013-07-18 & 0 \\\\\n",
       "\t5 & 3350-09D & 45.5371 & -73.713 & 23.72 & 2013-06-22 & 0 \\\\\n",
       "\t6 & 4360-01D & 45.4907 & -73.5508 & 15.15 & 2013-05-28 & 0 \\\\\n",
       "\t7 & 3350-07D & 45.5461 & -73.6921 & 20.75 & 2018-07-01 & 0 \\\\\n",
       "\t8 & 4240-02D & 45.6498 & -73.4877 & 19.29 & 2017-06-12 & 0 \\\\\n",
       "\t9 & 4610-06D & 45.4305 & -73.8563 & 29.05 & 2018-06-19 & 0 \\\\\n",
       "\t10 & 3350-10D & 45.5372 & -73.7129 & 23.73 & 2013-09-22 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT  │ TP_LNG   │ TP_Z    │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼─────────┼──────────┼─────────┼────────────┼──────────┤\n",
       "│ 1   │ 3350-08D   │ 45.5401 │ -73.7086 │ 24.65   │ 2018-06-06 │ 0        │\n",
       "│ 2   │ 0642-01D   │ 45.6727 │ -73.5262 │ 19.3526 │ 2016-07-25 │ 0        │\n",
       "│ 3   │ 4270-01D   │ 45.6105 │ -73.5087 │ 11.17   │ 2016-10-20 │ 0        │\n",
       "│ 4   │ 3350-08D   │ 45.5401 │ -73.7086 │ 24.65   │ 2013-07-18 │ 0        │\n",
       "│ 5   │ 3350-09D   │ 45.5371 │ -73.713  │ 23.72   │ 2013-06-22 │ 0        │\n",
       "│ 6   │ 4360-01D   │ 45.4907 │ -73.5508 │ 15.15   │ 2013-05-28 │ 0        │\n",
       "│ 7   │ 3350-07D   │ 45.5461 │ -73.6921 │ 20.75   │ 2018-07-01 │ 0        │\n",
       "│ 8   │ 4240-02D   │ 45.6498 │ -73.4877 │ 19.29   │ 2017-06-12 │ 0        │\n",
       "│ 9   │ 4610-06D   │ 45.4305 │ -73.8563 │ 29.05   │ 2018-06-19 │ 0        │\n",
       "│ 10  │ 3350-10D   │ 45.5372 │ -73.7129 │ 23.73   │ 2013-09-22 │ 0        │"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = join(features, surverses, on = :ID_OUVRAGE);\n",
    "first(shuffleDf(comb), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load precipitation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and filter months between May & October included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitation, Symbol(\"St-Hubert\")=>:StHubert);\n",
    "\n",
    "precipitation = filter(row -> month(row.date) > 4, precipitation);\n",
    "precipitation = filter(row -> month(row.date) < 11, precipitation); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing data by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2016-05-14</td><td>12</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2018-10-08</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2014-05-14</td><td>8</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>2015-07-02</td><td>15</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2016-09-02</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2016-05-14 & 12 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 2018-10-08 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 2014-05-14 & 8 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t4 & 2015-07-02 & 15 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t5 & 2016-09-02 & 3 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2016-05-14 │ 12    │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2018-10-08 │ 1     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2014-05-14 │ 8     │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2015-07-02 │ 15    │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2016-09-02 │ 3     │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitation[!,:McTavish] = coalesce.(precipitation[:,:McTavish], 0);\n",
    "precipitation[!,:Bellevue] = coalesce.(precipitation[:,:Bellevue], 0);\n",
    "precipitation[!,:Assomption] = coalesce.(precipitation[:,:Assomption], 0);\n",
    "precipitation[!,:Trudeau] = coalesce.(precipitation[:,:Trudeau], 0);\n",
    "precipitation[!,:StHubert] = coalesce.(precipitation[:,:StHubert], 0);\n",
    "\n",
    "first(shuffleDf(precipitation), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of precipitation for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>2014-09-29</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2013-05-09</td><td>10</td><td>0</td><td>19</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2017-05-13</td><td>0</td><td>38</td><td>0</td><td>9</td><td>15</td></tr><tr><th>4</th><td>2014-07-17</td><td>0</td><td>7</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2017-08-14</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2014-09-29 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 2013-05-09 & 10 & 0 & 19 & 0 & 0 \\\\\n",
       "\t3 & 2017-05-13 & 0 & 38 & 0 & 9 & 15 \\\\\n",
       "\t4 & 2014-07-17 & 0 & 7 & 0 & 0 & 0 \\\\\n",
       "\t5 & 2017-08-14 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2014-09-29 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 2   │ 2013-05-09 │ 10       │ 0        │ 19         │ 0       │ 0        │\n",
       "│ 3   │ 2017-05-13 │ 0        │ 38       │ 0          │ 9       │ 15       │\n",
       "│ 4   │ 2014-07-17 │ 0        │ 7        │ 0          │ 0       │ 0        │\n",
       "│ 5   │ 2017-08-14 │ 0        │ 0        │ 0          │ 0       │ 0        │"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_sum = by(precipitation, :date,  McTavish = :McTavish=>sum, Bellevue = :Bellevue=>sum, \n",
    "   Assomption = :Assomption=>sum, Trudeau = :Trudeau=>sum, StHubert = :StHubert=>sum);\n",
    "first(shuffleDf(pcp_sum), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum precipitation in an hour for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>2019-08-26</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>2</th><td>2019-06-23</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2017-06-23</td><td>31</td><td>28</td><td>20</td><td>24</td><td>25</td></tr><tr><th>4</th><td>2018-07-05</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2017-08-13</td><td>15</td><td>7</td><td>10</td><td>6</td><td>8</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-08-26 & 0 & 0 & 0 & 2 & 0 \\\\\n",
       "\t2 & 2019-06-23 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 2017-06-23 & 31 & 28 & 20 & 24 & 25 \\\\\n",
       "\t4 & 2018-07-05 & 0 & 0 & 4 & 0 & 0 \\\\\n",
       "\t5 & 2017-08-13 & 15 & 7 & 10 & 6 & 8 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2019-08-26 │ 0        │ 0        │ 0          │ 2       │ 0        │\n",
       "│ 2   │ 2019-06-23 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 3   │ 2017-06-23 │ 31       │ 28       │ 20         │ 24      │ 25       │\n",
       "│ 4   │ 2018-07-05 │ 0        │ 0        │ 4          │ 0       │ 0        │\n",
       "│ 5   │ 2017-08-13 │ 15       │ 7        │ 10         │ 6       │ 8        │"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_max = by(precipitation, :date,  McTavish = :McTavish=>maximum, Bellevue = :Bellevue=>maximum, \n",
    "   Assomption = :Assomption=>maximum, Trudeau = :Trudeau=>maximum, StHubert = :StHubert=>maximum)\n",
    "first(shuffleDf(pcp_max),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum precipitation during three consecutive hours in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>2018-08-19</td><td>0</td><td>0</td><td>7</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2019-09-15</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2015-07-03</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>4</th><td>2015-07-14</td><td>0</td><td>7</td><td>30</td><td>0</td><td>12</td></tr><tr><th>5</th><td>2018-05-26</td><td>38</td><td>125</td><td>45</td><td>66</td><td>36</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& date & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2018-08-19 & 0 & 0 & 7 & 0 & 0 \\\\\n",
       "\t2 & 2019-09-15 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 2015-07-03 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t4 & 2015-07-14 & 0 & 7 & 30 & 0 & 12 \\\\\n",
       "\t5 & 2018-05-26 & 38 & 125 & 45 & 66 & 36 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame\n",
       "│ Row │ date       │ McTavish │ Bellevue │ Assomption │ Trudeau │ StHubert │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼──────────┼──────────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ 2018-08-19 │ 0        │ 0        │ 7          │ 0       │ 0        │\n",
       "│ 2   │ 2019-09-15 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 3   │ 2015-07-03 │ 0        │ 0        │ 0          │ 0       │ 0        │\n",
       "│ 4   │ 2015-07-14 │ 0        │ 7        │ 30         │ 0       │ 12       │\n",
       "│ 5   │ 2018-05-26 │ 38       │ 125      │ 45         │ 66      │ 36       │"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp_max3h = by(precipitation, :date,  McTavish = :McTavish=>maximum3, Bellevue = :Bellevue=>maximum3, \n",
    "   Assomption = :Assomption=>maximum3, Trudeau = :Trudeau=>maximum3, StHubert = :StHubert=>maximum3)\n",
    "first(shuffleDf(pcp_max3h),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add precipitation data to features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stations lat-lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>STATION</th><th>LAT</th><th>LNG</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>McTavish</td><td>45.5047</td><td>-73.5792</td></tr><tr><th>2</th><td>Bellevue</td><td>45.4272</td><td>-73.9292</td></tr><tr><th>3</th><td>Assomption</td><td>45.8094</td><td>-73.4347</td></tr><tr><th>4</th><td>Trudeau</td><td>45.4678</td><td>-73.7417</td></tr><tr><th>5</th><td>StHubert</td><td>45.5175</td><td>-73.4169</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& STATION & LAT & LNG\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & McTavish & 45.5047 & -73.5792 \\\\\n",
       "\t2 & Bellevue & 45.4272 & -73.9292 \\\\\n",
       "\t3 & Assomption & 45.8094 & -73.4347 \\\\\n",
       "\t4 & Trudeau & 45.4678 & -73.7417 \\\\\n",
       "\t5 & StHubert & 45.5175 & -73.4169 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ STATION    │ LAT     │ LNG      │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m  │\n",
       "├─────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ McTavish   │ 45.5047 │ -73.5792 │\n",
       "│ 2   │ Bellevue   │ 45.4272 │ -73.9292 │\n",
       "│ 3   │ Assomption │ 45.8094 │ -73.4347 │\n",
       "│ 4   │ Trudeau    │ 45.4678 │ -73.7417 │\n",
       "│ 5   │ StHubert   │ 45.5175 │ -73.4169 │"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df = DataFrame(STATION = String[], LAT = Float64[], LNG = Float64[]);\n",
    "\n",
    "push!(station_df, [\"McTavish\", 45.504742, -73.579167]);\n",
    "push!(station_df, [\"Bellevue\", 45.427222, -73.929167]);\n",
    "push!(station_df, [\"Assomption\", 45.809444, -73.434722]);\n",
    "push!(station_df, [\"Trudeau\", 45.467778, -73.741667]);\n",
    "push!(station_df, [\"StHubert\", 45.5175, -73.416944]);\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize TP and station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanlat = mean(comb.TP_LAT);\n",
    "stdlat = std(comb.TP_LAT);\n",
    "comb.TP_LAT = (comb.TP_LAT .- meanlat) ./ stdlat;\n",
    "station_df.LAT = (station_df.LAT .- meanlat) ./ stdlat;\n",
    "\n",
    "meanlng = mean(comb.TP_LNG);\n",
    "stdlng = std(comb.TP_LNG);\n",
    "comb.TP_LNG = (comb.TP_LNG .- meanlng) ./ stdlng;\n",
    "station_df.LNG = (station_df.LNG .- meanlng) ./ stdlng;\n",
    "\n",
    "meanz = mean(comb.TP_Z);\n",
    "stdz = std(comb.TP_Z);\n",
    "comb.TP_Z = (comb.TP_Z .- meanz) ./ stdz;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>STATION</th><th>LAT</th><th>LNG</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>McTavish</td><td>-0.399934</td><td>0.53979</td></tr><tr><th>2</th><td>Bellevue</td><td>-1.29892</td><td>-2.14237</td></tr><tr><th>3</th><td>Assomption</td><td>3.13364</td><td>1.64672</td></tr><tr><th>4</th><td>Trudeau</td><td>-0.828599</td><td>-0.705498</td></tr><tr><th>5</th><td>StHubert</td><td>-0.251981</td><td>1.78296</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& STATION & LAT & LNG\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & McTavish & -0.399934 & 0.53979 \\\\\n",
       "\t2 & Bellevue & -1.29892 & -2.14237 \\\\\n",
       "\t3 & Assomption & 3.13364 & 1.64672 \\\\\n",
       "\t4 & Trudeau & -0.828599 & -0.705498 \\\\\n",
       "\t5 & StHubert & -0.251981 & 1.78296 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ STATION    │ LAT       │ LNG       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼────────────┼───────────┼───────────┤\n",
       "│ 1   │ McTavish   │ -0.399934 │ 0.53979   │\n",
       "│ 2   │ Bellevue   │ -1.29892  │ -2.14237  │\n",
       "│ 3   │ Assomption │ 3.13364   │ 1.64672   │\n",
       "│ 4   │ Trudeau    │ -0.828599 │ -0.705498 │\n",
       "│ 5   │ StHubert   │ -0.251981 │ 1.78296   │"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add pcp_sum and pcp_max columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.PCP_SUM = zeros(size(comb, 1));\n",
    "comb.PCP_MAX = zeros(size(comb, 1));\n",
    "comb.PCP_MAX3 = zeros(size(comb, 1));\n",
    "permutecols!(comb, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :PCP_SUM, :PCP_MAX, :PCP_MAX3, :SURVERSE]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>PCP_SUM</th><th>PCP_MAX</th><th>PCP_MAX3</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 9 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>4600-01D</td><td>-1.26773</td><td>-1.32401</td><td>0.56828</td><td>2017-10-10</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>3350-06D</td><td>0.183866</td><td>-0.182787</td><td>0.254423</td><td>2017-09-06</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0801-08D</td><td>-0.230069</td><td>0.861407</td><td>-0.850227</td><td>2015-08-26</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>3350-10D</td><td>-0.0239445</td><td>-0.484678</td><td>0.626743</td><td>2013-07-07</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>3350-08D</td><td>0.0104279</td><td>-0.451902</td><td>0.768286</td><td>2013-06-10</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>0801-09D</td><td>-0.271792</td><td>0.873046</td><td>0.865212</td><td>2016-06-09</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>4340-01D</td><td>-0.150978</td><td>0.805845</td><td>-0.0502015</td><td>2013-07-12</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>3480-05D</td><td>-0.471255</td><td>-1.0262</td><td>0.799056</td><td>2015-10-13</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>4620-01D</td><td>-1.43344</td><td>-1.80389</td><td>0.809826</td><td>2014-05-11</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>4230-06D</td><td>1.65681</td><td>1.22251</td><td>-1.6441</td><td>2013-07-09</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & PCP\\_SUM & PCP\\_MAX & PCP\\_MAX3 & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 4600-01D & -1.26773 & -1.32401 & 0.56828 & 2017-10-10 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 3350-06D & 0.183866 & -0.182787 & 0.254423 & 2017-09-06 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0801-08D & -0.230069 & 0.861407 & -0.850227 & 2015-08-26 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 3350-10D & -0.0239445 & -0.484678 & 0.626743 & 2013-07-07 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 3350-08D & 0.0104279 & -0.451902 & 0.768286 & 2013-06-10 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 0801-09D & -0.271792 & 0.873046 & 0.865212 & 2016-06-09 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 4340-01D & -0.150978 & 0.805845 & -0.0502015 & 2013-07-12 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 3480-05D & -0.471255 & -1.0262 & 0.799056 & 2015-10-13 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 4620-01D & -1.43344 & -1.80389 & 0.809826 & 2014-05-11 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 4230-06D & 1.65681 & 1.22251 & -1.6441 & 2013-07-09 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×9 DataFrame. Omitted printing of 4 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT     │ TP_LNG    │ TP_Z       │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼────────────┼───────────┼────────────┼────────────┤\n",
       "│ 1   │ 4600-01D   │ -1.26773   │ -1.32401  │ 0.56828    │ 2017-10-10 │\n",
       "│ 2   │ 3350-06D   │ 0.183866   │ -0.182787 │ 0.254423   │ 2017-09-06 │\n",
       "│ 3   │ 0801-08D   │ -0.230069  │ 0.861407  │ -0.850227  │ 2015-08-26 │\n",
       "│ 4   │ 3350-10D   │ -0.0239445 │ -0.484678 │ 0.626743   │ 2013-07-07 │\n",
       "│ 5   │ 3350-08D   │ 0.0104279  │ -0.451902 │ 0.768286   │ 2013-06-10 │\n",
       "│ 6   │ 0801-09D   │ -0.271792  │ 0.873046  │ 0.865212   │ 2016-06-09 │\n",
       "│ 7   │ 4340-01D   │ -0.150978  │ 0.805845  │ -0.0502015 │ 2013-07-12 │\n",
       "│ 8   │ 3480-05D   │ -0.471255  │ -1.0262   │ 0.799056   │ 2015-10-13 │\n",
       "│ 9   │ 4620-01D   │ -1.43344   │ -1.80389  │ 0.809826   │ 2014-05-11 │\n",
       "│ 10  │ 4230-06D   │ 1.65681    │ 1.22251   │ -1.6441    │ 2013-07-09 │"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(comb), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find closest station to each ouvrage and add pcp_sum and pcp_max to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(comb, 1)\n",
    "    id_ouvrage = comb[i, 1]; \n",
    "    closest_station = \"McTavish\"; # initial value\n",
    "    shortest_dist = -1;\n",
    "    \n",
    "    # Find closest station\n",
    "    for j=1:size(station_df, 1)\n",
    "        dist = findDistance(comb[i, :TP_LAT], comb[i, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "        \n",
    "        if shortest_dist == -1 || dist < shortest_dist\n",
    "            shortest_dist = dist;\n",
    "            closest_station = station_df[j, :STATION];\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Augment comb with a weighted p_sum, based on the distance to the station\n",
    "    p_sum = pcp_sum[∈([comb[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "#     comb[i, :PCP_SUM] = p_sum[1] * (1 - shortest_dist);\n",
    "    comb[i, :PCP_SUM] = p_sum[1]; \n",
    "    \n",
    "    # Augment comb with a weighted p_max, based on the distance to the station\n",
    "    p_max = pcp_max[∈([comb[i, :DATE]]).(pcp_max.date), Symbol(closest_station)]\n",
    "#     comb[i, :PCP_MAX] = p_max[1] * (1 - shortest_dist);\n",
    "    comb[i, :PCP_MAX] = p_max[1];\n",
    "    \n",
    "    # Augment comb with a weighted p_max3h, based on the distance to the station\n",
    "    p_max3 = pcp_max3h[∈([comb[i, :DATE]]).(pcp_max3h.date), Symbol(closest_station)]\n",
    "#     comb[i, :PCP_MAX3] = p_max3[1] * (1 - shortest_dist);\n",
    "    comb[i, :PCP_MAX3] = p_max3[1]; \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outlier in PCP_SUM and PCP_MAX AND PCP_MAX3 that cause compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[192]:1\n",
      "└ @ Core In[192]:1\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[192]:2\n",
      "└ @ Core In[192]:2\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[192]:3\n",
      "└ @ Core In[192]:3\n"
     ]
    }
   ],
   "source": [
    "comb[comb[:PCP_SUM] .> 750, :PCP_SUM] = 750;\n",
    "comb[comb[:PCP_MAX] .> 500, :PCP_MAX] = 500;\n",
    "comb[comb[:PCP_MAX3] .> 750, :PCP_MAX3] = 750;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>PCP_SUM</th><th>PCP_MAX</th><th>PCP_MAX3</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 9 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>4380-01D</td><td>-0.828933</td><td>0.658409</td><td>-0.0467296</td><td>2017-06-05</td><td>434.0</td><td>91.0</td><td>210.0</td></tr><tr><th>2</th><td>4430-05D</td><td>-1.33635</td><td>-0.0587449</td><td>1.69293</td><td>2018-09-03</td><td>39.0</td><td>33.0</td><td>33.0</td></tr><tr><th>3</th><td>4300-01D</td><td>0.3648</td><td>0.987515</td><td>-0.933306</td><td>2015-05-25</td><td>200.0</td><td>56.0</td><td>110.0</td></tr><tr><th>4</th><td>0801-05D</td><td>-0.254625</td><td>0.907701</td><td>-1.07023</td><td>2015-05-18</td><td>318.0</td><td>140.0</td><td>236.0</td></tr><tr><th>5</th><td>4330-01D</td><td>0.0527466</td><td>0.876211</td><td>-0.845611</td><td>2018-10-09</td><td>56.0</td><td>51.0</td><td>51.0</td></tr><tr><th>6</th><td>0672-03D</td><td>1.55381</td><td>0.838395</td><td>-1.48717</td><td>2016-08-21</td><td>230.0</td><td>70.0</td><td>160.0</td></tr><tr><th>7</th><td>4400-02D</td><td>-1.0264</td><td>0.591287</td><td>-0.536371</td><td>2016-06-22</td><td>56.0</td><td>27.0</td><td>38.0</td></tr><tr><th>8</th><td>4370-01D</td><td>-0.787544</td><td>0.689553</td><td>-0.0467296</td><td>2018-07-25</td><td>387.0</td><td>257.0</td><td>307.0</td></tr><tr><th>9</th><td>3270-01D</td><td>1.18312</td><td>0.417032</td><td>0.239038</td><td>2015-06-08</td><td>288.0</td><td>52.0</td><td>114.0</td></tr><tr><th>10</th><td>4370-01D</td><td>-0.787544</td><td>0.689553</td><td>-0.0467296</td><td>2013-08-09</td><td>72.0</td><td>72.0</td><td>72.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & PCP\\_SUM & PCP\\_MAX & PCP\\_MAX3 & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 4380-01D & -0.828933 & 0.658409 & -0.0467296 & 2017-06-05 & 434.0 & 91.0 & 210.0 & $\\dots$ \\\\\n",
       "\t2 & 4430-05D & -1.33635 & -0.0587449 & 1.69293 & 2018-09-03 & 39.0 & 33.0 & 33.0 & $\\dots$ \\\\\n",
       "\t3 & 4300-01D & 0.3648 & 0.987515 & -0.933306 & 2015-05-25 & 200.0 & 56.0 & 110.0 & $\\dots$ \\\\\n",
       "\t4 & 0801-05D & -0.254625 & 0.907701 & -1.07023 & 2015-05-18 & 318.0 & 140.0 & 236.0 & $\\dots$ \\\\\n",
       "\t5 & 4330-01D & 0.0527466 & 0.876211 & -0.845611 & 2018-10-09 & 56.0 & 51.0 & 51.0 & $\\dots$ \\\\\n",
       "\t6 & 0672-03D & 1.55381 & 0.838395 & -1.48717 & 2016-08-21 & 230.0 & 70.0 & 160.0 & $\\dots$ \\\\\n",
       "\t7 & 4400-02D & -1.0264 & 0.591287 & -0.536371 & 2016-06-22 & 56.0 & 27.0 & 38.0 & $\\dots$ \\\\\n",
       "\t8 & 4370-01D & -0.787544 & 0.689553 & -0.0467296 & 2018-07-25 & 387.0 & 257.0 & 307.0 & $\\dots$ \\\\\n",
       "\t9 & 3270-01D & 1.18312 & 0.417032 & 0.239038 & 2015-06-08 & 288.0 & 52.0 & 114.0 & $\\dots$ \\\\\n",
       "\t10 & 4370-01D & -0.787544 & 0.689553 & -0.0467296 & 2013-08-09 & 72.0 & 72.0 & 72.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×9 DataFrame. Omitted printing of 4 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT    │ TP_LNG     │ TP_Z       │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼───────────┼────────────┼────────────┼────────────┤\n",
       "│ 1   │ 4380-01D   │ -0.828933 │ 0.658409   │ -0.0467296 │ 2017-06-05 │\n",
       "│ 2   │ 4430-05D   │ -1.33635  │ -0.0587449 │ 1.69293    │ 2018-09-03 │\n",
       "│ 3   │ 4300-01D   │ 0.3648    │ 0.987515   │ -0.933306  │ 2015-05-25 │\n",
       "│ 4   │ 0801-05D   │ -0.254625 │ 0.907701   │ -1.07023   │ 2015-05-18 │\n",
       "│ 5   │ 4330-01D   │ 0.0527466 │ 0.876211   │ -0.845611  │ 2018-10-09 │\n",
       "│ 6   │ 0672-03D   │ 1.55381   │ 0.838395   │ -1.48717   │ 2016-08-21 │\n",
       "│ 7   │ 4400-02D   │ -1.0264   │ 0.591287   │ -0.536371  │ 2016-06-22 │\n",
       "│ 8   │ 4370-01D   │ -0.787544 │ 0.689553   │ -0.0467296 │ 2018-07-25 │\n",
       "│ 9   │ 3270-01D   │ 1.18312   │ 0.417032   │ 0.239038   │ 2015-06-08 │\n",
       "│ 10  │ 4370-01D   │ -0.787544 │ 0.689553   │ -0.0467296 │ 2013-08-09 │"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(filter(row -> row.SURVERSE == 1, comb)), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dates into months and days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>MONTH</th><th>DAY</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>2014-08-02</td><td>8</td><td>2</td></tr><tr><th>2</th><td>2018-09-24</td><td>9</td><td>24</td></tr><tr><th>3</th><td>2017-06-05</td><td>6</td><td>5</td></tr><tr><th>4</th><td>2015-09-23</td><td>9</td><td>23</td></tr><tr><th>5</th><td>2015-06-24</td><td>6</td><td>24</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& DATE & MONTH & DAY\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2014-08-02 & 8 & 2 \\\\\n",
       "\t2 & 2018-09-24 & 9 & 24 \\\\\n",
       "\t3 & 2017-06-05 & 6 & 5 \\\\\n",
       "\t4 & 2015-09-23 & 9 & 23 \\\\\n",
       "\t5 & 2015-06-24 & 6 & 24 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ DATE       │ MONTH │ DAY   │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼────────────┼───────┼───────┤\n",
       "│ 1   │ 2014-08-02 │ 8     │ 2     │\n",
       "│ 2   │ 2018-09-24 │ 9     │ 24    │\n",
       "│ 3   │ 2017-06-05 │ 6     │ 5     │\n",
       "│ 4   │ 2015-09-23 │ 9     │ 23    │\n",
       "│ 5   │ 2015-06-24 │ 6     │ 24    │"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.MONTH = month.(comb.DATE);\n",
    "comb.DAY = day.(comb.DATE);\n",
    "first(shuffleDf(comb[!, [:DATE, :MONTH, :DAY]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the PCP and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pcpsum = mean(comb.PCP_SUM);\n",
    "std_pcpsum = std(comb.PCP_SUM);\n",
    "comb.PCP_SUM = (comb.PCP_SUM .- mean_pcpsum) ./ std_pcpsum;\n",
    "\n",
    "mean_pcpmax = mean(comb.PCP_MAX);\n",
    "std_pcpmax = std(comb.PCP_MAX);\n",
    "comb.PCP_MAX = (comb.PCP_MAX .- mean_pcpmax) ./ std_pcpmax;\n",
    "\n",
    "mean_pcpmax3 = mean(comb.PCP_MAX3);\n",
    "std_pcpmax3 = std(comb.PCP_MAX3);\n",
    "comb.PCP_MAX3 = (comb.PCP_MAX3 .- mean_pcpmax3) ./ std_pcpmax3;\n",
    "\n",
    "meanmonth = mean(comb.MONTH);\n",
    "stdmonth = std(comb.MONTH);\n",
    "comb.MONTH = (comb.MONTH .- meanmonth) ./ stdmonth;\n",
    "\n",
    "meanday = mean(comb.DAY);\n",
    "stdday = std(comb.DAY);\n",
    "comb.DAY = (comb.DAY .- meanday) ./ stdday;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>PCP_SUM</th><th>PCP_MAX</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 11 columns (omitted printing of 4 columns)</p><tr><th>1</th><td>0801-05D</td><td>-0.254625</td><td>0.907701</td><td>-1.07023</td><td>2013-07-16</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>2</th><td>4430-04D</td><td>-1.38578</td><td>0.00660048</td><td>1.82832</td><td>2018-09-02</td><td>0.903974</td><td>1.72099</td></tr><tr><th>3</th><td>3380-01D</td><td>0.163171</td><td>-0.158884</td><td>0.395966</td><td>2016-10-27</td><td>1.20282</td><td>0.551968</td></tr><tr><th>4</th><td>3310-01D</td><td>0.865632</td><td>0.140067</td><td>-0.0117388</td><td>2016-10-21</td><td>6.17456</td><td>1.53641</td></tr><tr><th>5</th><td>3350-05D</td><td>0.362175</td><td>-0.0977361</td><td>0.248269</td><td>2014-07-27</td><td>1.66468</td><td>1.19801</td></tr><tr><th>6</th><td>0801-05D</td><td>-0.254625</td><td>0.907701</td><td>-1.07023</td><td>2018-08-04</td><td>-0.345752</td><td>-0.278652</td></tr><tr><th>7</th><td>4290-01D</td><td>0.5267</td><td>1.08435</td><td>-1.19485</td><td>2014-09-13</td><td>1.28433</td><td>1.07495</td></tr><tr><th>8</th><td>3270-01D</td><td>1.18312</td><td>0.417032</td><td>0.239038</td><td>2015-06-13</td><td>-0.37292</td><td>-0.34018</td></tr><tr><th>9</th><td>4720-01D</td><td>1.86614</td><td>1.22986</td><td>-1.39332</td><td>2015-05-18</td><td>3.53926</td><td>3.90522</td></tr><tr><th>10</th><td>4370-02D</td><td>-0.787414</td><td>0.689638</td><td>-0.0467296</td><td>2017-06-20</td><td>1.96352</td><td>2.18245</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & PCP\\_SUM & PCP\\_MAX & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0801-05D & -0.254625 & 0.907701 & -1.07023 & 2013-07-16 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t2 & 4430-04D & -1.38578 & 0.00660048 & 1.82832 & 2018-09-02 & 0.903974 & 1.72099 & $\\dots$ \\\\\n",
       "\t3 & 3380-01D & 0.163171 & -0.158884 & 0.395966 & 2016-10-27 & 1.20282 & 0.551968 & $\\dots$ \\\\\n",
       "\t4 & 3310-01D & 0.865632 & 0.140067 & -0.0117388 & 2016-10-21 & 6.17456 & 1.53641 & $\\dots$ \\\\\n",
       "\t5 & 3350-05D & 0.362175 & -0.0977361 & 0.248269 & 2014-07-27 & 1.66468 & 1.19801 & $\\dots$ \\\\\n",
       "\t6 & 0801-05D & -0.254625 & 0.907701 & -1.07023 & 2018-08-04 & -0.345752 & -0.278652 & $\\dots$ \\\\\n",
       "\t7 & 4290-01D & 0.5267 & 1.08435 & -1.19485 & 2014-09-13 & 1.28433 & 1.07495 & $\\dots$ \\\\\n",
       "\t8 & 3270-01D & 1.18312 & 0.417032 & 0.239038 & 2015-06-13 & -0.37292 & -0.34018 & $\\dots$ \\\\\n",
       "\t9 & 4720-01D & 1.86614 & 1.22986 & -1.39332 & 2015-05-18 & 3.53926 & 3.90522 & $\\dots$ \\\\\n",
       "\t10 & 4370-02D & -0.787414 & 0.689638 & -0.0467296 & 2017-06-20 & 1.96352 & 2.18245 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×11 DataFrame. Omitted printing of 6 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT    │ TP_LNG     │ TP_Z       │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼───────────┼────────────┼────────────┼────────────┤\n",
       "│ 1   │ 0801-05D   │ -0.254625 │ 0.907701   │ -1.07023   │ 2013-07-16 │\n",
       "│ 2   │ 4430-04D   │ -1.38578  │ 0.00660048 │ 1.82832    │ 2018-09-02 │\n",
       "│ 3   │ 3380-01D   │ 0.163171  │ -0.158884  │ 0.395966   │ 2016-10-27 │\n",
       "│ 4   │ 3310-01D   │ 0.865632  │ 0.140067   │ -0.0117388 │ 2016-10-21 │\n",
       "│ 5   │ 3350-05D   │ 0.362175  │ -0.0977361 │ 0.248269   │ 2014-07-27 │\n",
       "│ 6   │ 0801-05D   │ -0.254625 │ 0.907701   │ -1.07023   │ 2018-08-04 │\n",
       "│ 7   │ 4290-01D   │ 0.5267    │ 1.08435    │ -1.19485   │ 2014-09-13 │\n",
       "│ 8   │ 3270-01D   │ 1.18312   │ 0.417032   │ 0.239038   │ 2015-06-13 │\n",
       "│ 9   │ 4720-01D   │ 1.86614   │ 1.22986    │ -1.39332   │ 2015-05-18 │\n",
       "│ 10  │ 4370-02D   │ -0.787414 │ 0.689638   │ -0.0467296 │ 2017-06-20 │"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(filter(row -> row.SURVERSE == 1, comb)), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idx = shuffle(1:size(comb, 1));\n",
    "train_ceil = floor(Int, size(r_idx, 1) * 0.8);\n",
    "train_set = comb[r_idx[1:train_ceil], :];\n",
    "val_set = comb[r_idx[train_ceil+1:size(r_idx, 1)], :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitBestDistribution (generic function with 1 method)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#= fonction qui trouve la distribution qui représente le mieux chaque variable explicative=#\n",
    "\n",
    "function fitBestDistribution(data::Array, verbose::Bool)\n",
    "    # Distributions à essayer\n",
    "    distr = [Beta, Binomial, \n",
    "              Categorical, DiscreteUniform, Exponential, \n",
    "              Normal, Gamma, Geometric, Laplace, Pareto, \n",
    "              Poisson, Uniform, Multinomial, MvNormal, Dirichlet, Weibull];\n",
    "    \n",
    "    distrNames = [\"Beta\", \"Binomial\", \n",
    "                  \"Categorical\", \"DiscreteUniform\", \"Exponential\", \n",
    "                  \"Normal\", \"Gamma\", \"Geometric\", \"Laplace\", \"Pareto\", \n",
    "                  \"Poisson\", \"Uniform\", \"Multinomial\", \"MvNormal\", \"Dirichlet\", \"Weibull\"];\n",
    "    \n",
    "    # Déclaration des variables\n",
    "    maxLikelihood = -Inf;\n",
    "    distrName = nothing;\n",
    "    finalfd = nothing;\n",
    "    fitDist = nothing;\n",
    "    \n",
    "    for i = 1:length(distr) # Pour chaque type de modèle\n",
    "        if (verbose)\n",
    "            println(\"Trying model of type: \", distrNames[i]);\n",
    "        end\n",
    "        try # On essaie de faire fit le modèle sur les données\n",
    "            fitDist = fit(distr[i], data);\n",
    "        catch\n",
    "            if (verbose)\n",
    "                println(\"Invalid\");\n",
    "            end\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "#         k = sizeof(fieldnames(distr[i]))[1]; # le nombre de paramètres dans le modèle\n",
    "#         nData = sizeof(data)[1]; # le nombre de données dans l'ensemble\n",
    "        newLikelihood = loglikelihood(fitDist, data)\n",
    "#         newBIC = BIC(fitDist, data, k, nData); # calcul du BIC\n",
    "        \n",
    "        # Si on trouve un meilleur BIC que celui qu'on a déjà, le modèle courant est le meilleur\n",
    "        if (newLikelihood > maxLikelihood) \n",
    "            maxLikelihood = newLikelihood;\n",
    "            distrName = distrNames[i];\n",
    "            finalfd = fitDist;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Décommenter cette ligne pour voir quel est le modèle trouvé\n",
    "    println(\"The best distribution is of type \", distrName, \" with a likelihood of \", maxLikelihood)\n",
    "    return finalfd;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getBestLikelihoodDistributions (generic function with 1 method)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#= Cette fonction retourne un tableau des meilleurs distribution selon les variables données \n",
    "(1 distribution lorsqu'il n'y a pas de surverse et une distribution lorsqu'il y a surverse=#\n",
    "\n",
    "function getBestLikelihoodDistributions(train::DataFrame, variable::Symbol)\n",
    "    x_m = [];\n",
    "    for i=0:1\n",
    "        ind = train[:,:SURVERSE] .== i;\n",
    "        x=train[ind,variable];\n",
    "        push!(x_m,fitBestDistribution(x, false));\n",
    "    end\n",
    "    \n",
    "    return x_m;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getPrioris (generic function with 1 method)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getPrioris(trainSet::DataFrame)\n",
    "    dAlpha = trainSet[:,:SURVERSE];\n",
    "    n_mode = Float64[];\n",
    "    for i=0:1\n",
    "        push!(n_mode, count(dAlpha .== i));\n",
    "    end\n",
    "    α = n_mode/size(trainSet,1);\n",
    "    M = Categorical(α); #Categorical en 2 dim ? Bernoulli ? \n",
    "    mode(M);\n",
    "    \n",
    "    return α;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictNaiveBayes (generic function with 2 methods)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predictNaiveBayes(data::DataFrame, likelihoodDistrs::Array, prioris::Array, variables::Array)\n",
    "    n_data = size(data,1);\n",
    "    nb_exp_var = size(variables,1);\n",
    "    y_m = Array{Int64}(undef,n_data);\n",
    "    \n",
    "    \n",
    "\n",
    "    for i=1:n_data\n",
    "        p = [];\n",
    "        for j=1:2\n",
    "#             prob =1; # à priori non informatif (Uniform(0,1))\n",
    "            prob = prioris[j]\n",
    "            for k=1:nb_exp_var\n",
    "                prob *= pdf.(likelihoodDistrs[k][j], data[i,variables[k]]);\n",
    "            end\n",
    "            push!(p,prob);\n",
    "        end\n",
    "        _, ind = findmax(p);\n",
    "        y_m[i] =ind -1;\n",
    "    end\n",
    "    \n",
    "    return y_m;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIC (generic function with 5 methods)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function BIC(distributions::Dict, data::DataFrame)\n",
    "    n = size(data)[1]\n",
    "    k = length(keys(distributions))\n",
    "    totalLogLikelihood = 0\n",
    "    for variable in keys(distributions)\n",
    "        for j=0:1\n",
    "            ind = data[:,:SURVERSE] .== j;\n",
    "            x=data[ind,variable];\n",
    "#             @show distributions\n",
    "            totalLogLikelihood += loglikelihood(distributions[variable][j+1], x)\n",
    "        end\n",
    "    end\n",
    "    return (totalLogLikelihood - k*log(n)/2);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findBestVariablesCombinationBIC (generic function with 2 methods)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findBestVariablesCombinationBIC(train::DataFrame, likelihoodDistrs::Dict, variables::Array{Symbol})\n",
    "    bics = []\n",
    "    bicsDict = Dict()\n",
    "    combinations = []\n",
    "    for combination in subsets(variables)\n",
    "        push!(combinations, combination)\n",
    "        modelVariables = []\n",
    "        modelLikelihoodDistrs = Dict()\n",
    "        for variable in combination\n",
    "            modelLikelihoodDistrs[variable] = likelihoodDistrs[variable]\n",
    "        end\n",
    "#         @show modelLikelihoodDistrs\n",
    "        bic = BIC(modelLikelihoodDistrs, train)\n",
    "        if bic == 0.0\n",
    "            continue\n",
    "        end\n",
    "        push!(bics, bic)\n",
    "#         bicsDict[combination] = bic\n",
    "    end\n",
    "#     @show bicsDict\n",
    "    @show _, indexMax = findmax(bics)\n",
    "#     sortedBics = sort(collect(keys(bicsDict)))\n",
    "    println(\"Best combination: \", combinations[indexMax], \" with bic: \", bics[indexMax])\n",
    "    return (combinations[indexMax], bics[indexMax])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findBestVariablesCombinationF1Validation (generic function with 1 method)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findBestVariablesCombinationF1Validation(train::DataFrame, validation::DataFrame, likelihoodDistrs::Dict, variables::Array{Symbol})\n",
    "    f1scores = []\n",
    "    combinations = []\n",
    "    for combination in subsets(variables)\n",
    "        push!(combinations, combination)\n",
    "        modelVariables = []\n",
    "        modelLikelihoodDistrs = []\n",
    "        for variable in combination\n",
    "            push!(modelLikelihoodDistrs, likelihoodDistrs[variable])\n",
    "            push!(modelVariables, variable)\n",
    "        end\n",
    "        prioris = getPrioris(train)\n",
    "#         @show modelVariables\n",
    "        y = predictNaiveBayes(validation, modelLikelihoodDistrs, prioris, modelVariables);\n",
    "        r = roc(val_set[:SURVERSE], y);\n",
    "        push!(f1scores, f1score(r))\n",
    "#         println(f1score(r))\n",
    "    end\n",
    "    _, indexMax = findmax(f1scores)\n",
    "    println(\"Best combination: \", combinations[indexMax], \" with f1score: \", f1scores[indexMax])\n",
    "    return (combinations[indexMax], f1scores[indexMax])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitModel (generic function with 1 method)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fitModel(train::DataFrame, variables::Array{Symbol} )\n",
    "    likelihoodDistrs = Dict();\n",
    "    \n",
    "    for variable in variables\n",
    "        likelihoodDistrs[variable] = getBestLikelihoodDistributions(train, variable);\n",
    "    end\n",
    "    return likelihoodDistrs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainNaiveBayes (generic function with 1 method)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trainNaiveBayes(train::DataFrame, validation::DataFrame, variables::Array{Symbol} )\n",
    "    likelihoodDistrs = fitModel(train, variables)\n",
    "    modelVariables, f1score = findBestVariablesCombinationF1Validation(train, validation, likelihoodDistrs, variables)\n",
    "    return (likelihoodDistrs, modelVariables, f1score)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainOnValidationAndPredictNaiveBayes (generic function with 1 method)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trainOnValidationAndPredictNaiveBayes(train::DataFrame,validation::DataFrame, test::DataFrame, variables::Array{Symbol} )\n",
    "    likelihoodDistrs, modelVariables, f1score = trainNaiveBayes(train, validation, variables)\n",
    "    prioris = getPrioris(train)\n",
    "    \n",
    "    modelLikelihoodDistrs = []\n",
    "    for variable in modelVariables\n",
    "        push!(modelLikelihoodDistrs, likelihoodDistrs[variable]);\n",
    "    end\n",
    "    y = predictNaiveBayes(test, modelLikelihoodDistrs, prioris, modelVariables);\n",
    "    return y;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainAndPredictNaiveBayes (generic function with 1 method)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creer un vecteur y avec un modèle des variables `variables` entraîné sur `train` et appliqué sur `test`\n",
    "function trainAndPredictNaiveBayes(train::DataFrame, test::DataFrame, variables::Array{Symbol} )\n",
    "    n_variables = size(variables,1);\n",
    "    likelihoodDistrs = fitModel(train, variables)\n",
    "    \n",
    "#     modelVariables, bic = findBestVariablesCombinationBIC(train, likelihoodDistrs, variables)\n",
    "#     modelVariables, f1score = findBestVariablesCombinationF1Validation(train, test, likelihoodDistrs, variables)\n",
    "    \n",
    "    prioris = getPrioris(train)\n",
    "    \n",
    "    println(prioris)\n",
    "    modelLikelihoodDistrs = []\n",
    "    for variable in variables\n",
    "        push!(modelLikelihoodDistrs, likelihoodDistrs[variable]);\n",
    "    end\n",
    "#     @show modelLikelihoodDistrs\n",
    "    y = predictNaiveBayes(test, modelLikelihoodDistrs, prioris, variables);\n",
    "    return y;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compareArr (generic function with 1 method)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compareArr(a, b, verbose)\n",
    "    pourcent = count(a .== b)/size(a,1) * 100;\n",
    "    if(verbose)\n",
    "        println(size(a,1))\n",
    "        println(size(b,1))\n",
    "        \n",
    "        println(\"Le modéle est précis à $pourcent %\");\n",
    "    end\n",
    "    return pourcent;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive bayes Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ft = [:TP_LAT, :TP_LNG, :TP_Z, :MONTH, :DAY, :PCP_SUM, :PCP_MAX, :PCP_MAX3];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is of type Uniform with a BIC of -152541.51364510704\n",
      "The best model is of type Uniform with a BIC of -5436.80430390067\n",
      "The best model is of type Uniform with a BIC of -159558.3867488944\n",
      "The best model is of type Normal with a BIC of -4467.086529136986\n",
      "The best model is of type Normal with a BIC of -175192.39090162498\n",
      "The best model is of type Normal with a BIC of -5572.954294527319\n",
      "The best model is of type Uniform with a BIC of -132033.1741631602\n",
      "The best model is of type Uniform with a BIC of -4705.856867383811\n",
      "The best model is of type Uniform with a BIC of -150285.9631051927\n",
      "The best model is of type Uniform with a BIC of -5356.413159286683\n",
      "The best model is of type Normal with a BIC of -158350.57058899855\n",
      "The best model is of type Normal with a BIC of -9306.943331354872\n",
      "The best model is of type Normal with a BIC of -161360.19792138768\n",
      "The best model is of type Laplace with a BIC of -8822.699148219668\n",
      "The best model is of type Normal with a BIC of -159480.01370342379\n",
      "The best model is of type Laplace with a BIC of -9111.469228562066\n",
      "[0.9655851234872905, 0.034414876512709504]\n",
      "modelLikelihoodDistrs = Any[Any[Uniform{Float64}(a=-1.5860752106262548, b=1.8661412518268747), Uniform{Float64}(a=-1.5860752106262548, b=1.8661412518268747)], Any[Uniform{Float64}(a=-2.354535723026788, b=1.3001530514362682), Normal{Float64}(μ=0.3535958209511426, σ=0.6697068716012341)], Any[Normal{Float64}(μ=0.0075269270752838366, σ=1.004067653420828), Normal{Float64}(μ=-0.19442955639683132, σ=0.8616602266888533)], Any[Uniform{Float64}(a=-1.4598301428614477, b=1.4626650066145712), Uniform{Float64}(a=-1.4598301428614477, b=1.4626650066145712)], Any[Uniform{Float64}(a=-1.6771435827411096, b=1.7124017676434973), Uniform{Float64}(a=-1.6771435827411096, b=1.7124017676434973)], Any[Normal{Float64}(μ=-0.06552135980890475, σ=0.8756944367090419), Normal{Float64}(μ=1.881211940950687, σ=2.0179061266527687)], Any[Normal{Float64}(μ=-0.05906568276262402, σ=0.8973651628917506), Laplace{Float64}(μ=1.1980067192237167, θ=1.4595321550533658)], Any[Normal{Float64}(μ=-0.06384418384132308, σ=0.8837649208888326), Laplace{Float64}(μ=1.5342124916824222, θ=1.756472081253565)]]\n",
      "31876\n",
      "31876\n",
      "Le modéle est précis à 93.96097377337182 %\n",
      "0.5053285968028419\n",
      "0.29375322663913267\n",
      "0.3715311785830885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[357]:2\n",
      "└ @ Core In[357]:2\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[357]:5\n",
      "└ @ Core In[357]:5\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[357]:9\n",
      "└ @ Core In[357]:9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 29382  1368\n",
       "   557   569"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = trainAndPredictNaiveBayes(train_set, val_set, names_ft);\n",
    "# print(y)\n",
    "# Comparer nos résultats\n",
    "compareArr(y, val_set[:SURVERSE], true);\n",
    "r = roc(val_set[:SURVERSE], y);\n",
    "println(recall(r))\n",
    "println(precision(r))\n",
    "println(f1score(r))\n",
    "\n",
    "no_0_gt = val_set[:SURVERSE] .+ 1\n",
    "no_0_pred = y.+1\n",
    "confusmat(2, no_0_gt, no_0_pred )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is of type Uniform with a BIC of -152541.51364510704\n",
      "The best model is of type Uniform with a BIC of -5436.80430390067\n",
      "The best model is of type Uniform with a BIC of -159558.3867488944\n",
      "The best model is of type Normal with a BIC of -4467.086529136986\n",
      "The best model is of type Normal with a BIC of -175192.39090162498\n",
      "The best model is of type Normal with a BIC of -5572.954294527319\n",
      "The best model is of type Uniform with a BIC of -132033.1741631602\n",
      "The best model is of type Uniform with a BIC of -4705.856867383811\n",
      "The best model is of type Uniform with a BIC of -150285.9631051927\n",
      "The best model is of type Uniform with a BIC of -5356.413159286683\n",
      "The best model is of type Normal with a BIC of -158350.57058899855\n",
      "The best model is of type Normal with a BIC of -9306.943331354872\n",
      "The best model is of type Normal with a BIC of -161360.19792138768\n",
      "The best model is of type Laplace with a BIC of -8822.699148219668\n",
      "The best model is of type Normal with a BIC of -159480.01370342379\n",
      "The best model is of type Laplace with a BIC of -9111.469228562066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = findBestVariablesCombinationF1Validation(::DataFrame, ::DataFrame, ::Dict{Any,Any}, ::Array{Symbol,1}) at In[366]:15\n",
      "└ @ Main ./In[366]:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination: Symbol[:TP_LNG, :TP_Z, :PCP_SUM, :PCP_MAX] with f1score: 0.3772087991345114\n",
      "31876\n",
      "31876\n",
      "Le modéle est précis à 94.58213075668215 %\n",
      "0.4644760213143872\n",
      "0.3175470552519733\n",
      "0.3772087991345114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[369]:2\n",
      "└ @ Core In[369]:2\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[369]:5\n",
      "└ @ Core In[369]:5\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[369]:9\n",
      "└ @ Core In[369]:9\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching *(::Array{Int64,2}, ::typeof(trainOnValidationAndPredictNaiveBayes))\nClosest candidates are:\n  *(::Any, ::Any, !Matched::Any, !Matched::Any...) at operators.jl:529\n  *(::Union{DenseArray{T,2}, Base.ReinterpretArray{T,2,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, SubArray{T,2,A,I,L} where L where I<:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, DenseArray}} where T, !Matched::LinearAlgebra.AbstractQ) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/qr.jl:668\n  *(::Union{DenseArray{T,2}, Base.ReinterpretArray{T,2,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, SubArray{T,2,A,I,L} where L where I<:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, DenseArray}} where T, !Matched::LinearAlgebra.Adjoint{#s617,#s616} where #s616<:LinearAlgebra.AbstractQ where #s617) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/qr.jl:708\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching *(::Array{Int64,2}, ::typeof(trainOnValidationAndPredictNaiveBayes))\nClosest candidates are:\n  *(::Any, ::Any, !Matched::Any, !Matched::Any...) at operators.jl:529\n  *(::Union{DenseArray{T,2}, Base.ReinterpretArray{T,2,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, SubArray{T,2,A,I,L} where L where I<:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, DenseArray}} where T, !Matched::LinearAlgebra.AbstractQ) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/qr.jl:668\n  *(::Union{DenseArray{T,2}, Base.ReinterpretArray{T,2,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray}, SubArray{T,2,A,I,L} where L where I<:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{Base.ReinterpretArray{T,N,S,A} where S where A<:Union{SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I<:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A<:DenseArray where N where T, DenseArray} where N where T, DenseArray}} where T, !Matched::LinearAlgebra.Adjoint{#s617,#s616} where #s616<:LinearAlgebra.AbstractQ where #s617) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.2/LinearAlgebra/src/qr.jl:708\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[369]:12"
     ]
    }
   ],
   "source": [
    "y = trainOnValidationAndPredictNaiveBayes(train_set, val_set, val_set, names_ft);\n",
    "# print(y)\n",
    "# Comparer nos résultats\n",
    "compareArr(y, val_set[:SURVERSE], true);\n",
    "r = roc(val_set[:SURVERSE], y);\n",
    "println(recall(r))\n",
    "println(precision(r))\n",
    "println(f1score(r))\n",
    "\n",
    "no_0_gt = val_set[:SURVERSE] .+ 1\n",
    "no_0_pred = y.+1\n",
    "confusmat(2, no_0_gt, no_0_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_features = convert(Matrix{Float64},comb[:, names_ft]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_labels = comb[:, :SURVERSE];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>DATE</th></tr><tr><th></th><th>String</th><th>Date</th></tr></thead><tbody><p>10 rows × 2 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-05-02</td></tr><tr><th>2</th><td>3260-01D</td><td>2019-05-09</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-05-10</td></tr><tr><th>4</th><td>3260-01D</td><td>2019-05-15</td></tr><tr><th>5</th><td>3260-01D</td><td>2019-05-20</td></tr><tr><th>6</th><td>3260-01D</td><td>2019-05-23</td></tr><tr><th>7</th><td>3260-01D</td><td>2019-05-24</td></tr><tr><th>8</th><td>3260-01D</td><td>2019-05-26</td></tr><tr><th>9</th><td>3260-01D</td><td>2019-05-30</td></tr><tr><th>10</th><td>3350-07D</td><td>2019-05-01</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& ID\\_OUVRAGE & DATE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-05-02 \\\\\n",
       "\t2 & 3260-01D & 2019-05-09 \\\\\n",
       "\t3 & 3260-01D & 2019-05-10 \\\\\n",
       "\t4 & 3260-01D & 2019-05-15 \\\\\n",
       "\t5 & 3260-01D & 2019-05-20 \\\\\n",
       "\t6 & 3260-01D & 2019-05-23 \\\\\n",
       "\t7 & 3260-01D & 2019-05-24 \\\\\n",
       "\t8 & 3260-01D & 2019-05-26 \\\\\n",
       "\t9 & 3260-01D & 2019-05-30 \\\\\n",
       "\t10 & 3350-07D & 2019-05-01 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×2 DataFrame\n",
       "│ Row │ ID_OUVRAGE │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼────────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-05-02 │\n",
       "│ 2   │ 3260-01D   │ 2019-05-09 │\n",
       "│ 3   │ 3260-01D   │ 2019-05-10 │\n",
       "│ 4   │ 3260-01D   │ 2019-05-15 │\n",
       "│ 5   │ 3260-01D   │ 2019-05-20 │\n",
       "│ 6   │ 3260-01D   │ 2019-05-23 │\n",
       "│ 7   │ 3260-01D   │ 2019-05-24 │\n",
       "│ 8   │ 3260-01D   │ 2019-05-26 │\n",
       "│ 9   │ 3260-01D   │ 2019-05-30 │\n",
       "│ 10  │ 3350-07D   │ 2019-05-01 │"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = CSV.read(\"data/test.csv\");\n",
    "rename!(test, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "first(test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_merge = unique(comb[!, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z]], :ID_OUVRAGE);\n",
    "test_comb = join(test, to_merge, on= [:ID_OUVRAGE]);\n",
    "nrow(test_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>DATE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th></tr><tr><th></th><th>String</th><th>Date</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 5 columns</p><tr><th>1</th><td>3260-01D</td><td>2019-08-28</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td></tr><tr><th>2</th><td>4240-01D</td><td>2019-07-25</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td></tr><tr><th>3</th><td>3260-01D</td><td>2019-06-09</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td></tr><tr><th>4</th><td>4350-01D</td><td>2019-08-24</td><td>-0.465715</td><td>0.725081</td><td>-0.0467296</td></tr><tr><th>5</th><td>3350-07D</td><td>2019-06-26</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td></tr><tr><th>6</th><td>4240-01D</td><td>2019-06-30</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td></tr><tr><th>7</th><td>3260-01D</td><td>2019-06-11</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td></tr><tr><th>8</th><td>3260-01D</td><td>2019-07-08</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td></tr><tr><th>9</th><td>4350-01D</td><td>2019-08-19</td><td>-0.465715</td><td>0.725081</td><td>-0.0467296</td></tr><tr><th>10</th><td>4380-01D</td><td>2019-09-30</td><td>-0.828933</td><td>0.658409</td><td>-0.0467296</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& ID\\_OUVRAGE & DATE & TP\\_LAT & TP\\_LNG & TP\\_Z\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2019-08-28 & 1.29293 & 0.531312 & 0.0790333 \\\\\n",
       "\t2 & 4240-01D & 2019-07-25 & 1.28137 & 1.24035 & -1.19178 \\\\\n",
       "\t3 & 3260-01D & 2019-06-09 & 1.29293 & 0.531312 & 0.0790333 \\\\\n",
       "\t4 & 4350-01D & 2019-08-24 & -0.465715 & 0.725081 & -0.0467296 \\\\\n",
       "\t5 & 3350-07D & 2019-06-26 & 0.0802391 & -0.325532 & 0.168267 \\\\\n",
       "\t6 & 4240-01D & 2019-06-30 & 1.28137 & 1.24035 & -1.19178 \\\\\n",
       "\t7 & 3260-01D & 2019-06-11 & 1.29293 & 0.531312 & 0.0790333 \\\\\n",
       "\t8 & 3260-01D & 2019-07-08 & 1.29293 & 0.531312 & 0.0790333 \\\\\n",
       "\t9 & 4350-01D & 2019-08-19 & -0.465715 & 0.725081 & -0.0467296 \\\\\n",
       "\t10 & 4380-01D & 2019-09-30 & -0.828933 & 0.658409 & -0.0467296 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×5 DataFrame\n",
       "│ Row │ ID_OUVRAGE │ DATE       │ TP_LAT    │ TP_LNG    │ TP_Z       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 3260-01D   │ 2019-08-28 │ 1.29293   │ 0.531312  │ 0.0790333  │\n",
       "│ 2   │ 4240-01D   │ 2019-07-25 │ 1.28137   │ 1.24035   │ -1.19178   │\n",
       "│ 3   │ 3260-01D   │ 2019-06-09 │ 1.29293   │ 0.531312  │ 0.0790333  │\n",
       "│ 4   │ 4350-01D   │ 2019-08-24 │ -0.465715 │ 0.725081  │ -0.0467296 │\n",
       "│ 5   │ 3350-07D   │ 2019-06-26 │ 0.0802391 │ -0.325532 │ 0.168267   │\n",
       "│ 6   │ 4240-01D   │ 2019-06-30 │ 1.28137   │ 1.24035   │ -1.19178   │\n",
       "│ 7   │ 3260-01D   │ 2019-06-11 │ 1.29293   │ 0.531312  │ 0.0790333  │\n",
       "│ 8   │ 3260-01D   │ 2019-07-08 │ 1.29293   │ 0.531312  │ 0.0790333  │\n",
       "│ 9   │ 4350-01D   │ 2019-08-19 │ -0.465715 │ 0.725081  │ -0.0467296 │\n",
       "│ 10  │ 4380-01D   │ 2019-09-30 │ -0.828933 │ 0.658409  │ -0.0467296 │"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(test_comb), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add PCP_SUM and PCP_MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize default pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comb.PCP_SUM = zeros(size(test_comb, 1));\n",
    "test_comb.PCP_MAX = zeros(size(test_comb, 1));\n",
    "test_comb.PCP_MAX3 = zeros(size(test_comb, 1));\n",
    "permutecols!(test_comb, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :DATE, :PCP_SUM, :PCP_MAX, :PCP_MAX3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>PCP_SUM</th><th>PCP_MAX</th><th>PCP_MAX3</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 8 columns</p><tr><th>1</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-06-09</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>4240-01D</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td><td>2019-07-25</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>4350-01D</td><td>-0.465715</td><td>0.725081</td><td>-0.0467296</td><td>2019-05-04</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-09</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>4240-01D</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td><td>2019-08-02</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-06-02</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-19</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-02</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>4380-01D</td><td>-0.828933</td><td>0.658409</td><td>-0.0467296</td><td>2019-08-27</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>4350-01D</td><td>-0.465715</td><td>0.725081</td><td>-0.0467296</td><td>2019-08-12</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & PCP\\_SUM & PCP\\_MAX & PCP\\_MAX3\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-06-09 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t2 & 4240-01D & 1.28137 & 1.24035 & -1.19178 & 2019-07-25 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t3 & 4350-01D & -0.465715 & 0.725081 & -0.0467296 & 2019-05-04 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-09 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 4240-01D & 1.28137 & 1.24035 & -1.19178 & 2019-08-02 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t6 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-06-02 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-19 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t8 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-02 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t9 & 4380-01D & -0.828933 & 0.658409 & -0.0467296 & 2019-08-27 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t10 & 4350-01D & -0.465715 & 0.725081 & -0.0467296 & 2019-08-12 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT    │ TP_LNG    │ TP_Z       │ DATE       │ PCP_SUM │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mDate\u001b[39m       │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼────────────┼───────────┼───────────┼────────────┼────────────┼─────────┤\n",
       "│ 1   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333  │ 2019-06-09 │ 0.0     │\n",
       "│ 2   │ 4240-01D   │ 1.28137   │ 1.24035   │ -1.19178   │ 2019-07-25 │ 0.0     │\n",
       "│ 3   │ 4350-01D   │ -0.465715 │ 0.725081  │ -0.0467296 │ 2019-05-04 │ 0.0     │\n",
       "│ 4   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-05-09 │ 0.0     │\n",
       "│ 5   │ 4240-01D   │ 1.28137   │ 1.24035   │ -1.19178   │ 2019-08-02 │ 0.0     │\n",
       "│ 6   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333  │ 2019-06-02 │ 0.0     │\n",
       "│ 7   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-05-19 │ 0.0     │\n",
       "│ 8   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-05-02 │ 0.0     │\n",
       "│ 9   │ 4380-01D   │ -0.828933 │ 0.658409  │ -0.0467296 │ 2019-08-27 │ 0.0     │\n",
       "│ 10  │ 4350-01D   │ -0.465715 │ 0.725081  │ -0.0467296 │ 2019-08-12 │ 0.0     │"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(test_comb), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(test_comb, 1)\n",
    "    id_ouvrage = test_comb[i, 1]; \n",
    "    closest_station = \"McTavish\"; # initial value\n",
    "    shortest_dist = -1;\n",
    "    \n",
    "    # Find closest station\n",
    "    for j=1:size(station_df, 1)\n",
    "        dist = findDistance(test_comb[i, :TP_LAT], test_comb[i, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "        \n",
    "        if shortest_dist == -1 || dist < shortest_dist\n",
    "            shortest_dist = dist;\n",
    "            closest_station = station_df[j, :STATION];\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Augment comb with a weighted p_sum, based on the distance to the station\n",
    "    p_sum = pcp_sum[∈([test_comb[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "#     test_comb[i, :PCP_SUM] = p_sum[1] * (1 - shortest_dist); \n",
    "    test_comb[i, :PCP_SUM] = p_sum[1]; \n",
    "    # Augment comb with a weighted p_max, based on the distance to the station\n",
    "    p_max = pcp_max[∈([test_comb[i, :DATE]]).(pcp_max.date), Symbol(closest_station)]\n",
    "#     test_comb[i, :PCP_MAX] = p_max[1] * (1 - shortest_dist);\n",
    "    test_comb[i, :PCP_MAX] = p_max[1];\n",
    "    # Augment comb with a weighted p_max3, based on the distance to the station\n",
    "    p_max3 = pcp_max3h[∈([test_comb[i, :DATE]]).(pcp_max3h.date), Symbol(closest_station)]\n",
    "#     test_comb[i, :PCP_MAX3] = p_max3[1] * (1 - shortest_dist);\n",
    "    test_comb[i, :PCP_MAX3] = p_max3[1];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>PCP_SUM</th><th>PCP_MAX</th><th>PCP_MAX3</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 8 columns</p><tr><th>1</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-07-28</td><td>15.0</td><td>15.0</td><td>15.0</td></tr><tr><th>2</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-08-01</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-08-22</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>4240-01D</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td><td>2019-09-28</td><td>39.0</td><td>15.0</td><td>25.0</td></tr><tr><th>5</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-08-14</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-07-13</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>4380-01D</td><td>-0.828933</td><td>0.658409</td><td>-0.0467296</td><td>2019-05-09</td><td>89.0</td><td>45.0</td><td>89.0</td></tr><tr><th>8</th><td>4240-01D</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td><td>2019-06-08</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-31</td><td>5.0</td><td>5.0</td><td>5.0</td></tr><tr><th>10</th><td>4350-01D</td><td>-0.465715</td><td>0.725081</td><td>-0.0467296</td><td>2019-07-04</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & PCP\\_SUM & PCP\\_MAX & PCP\\_MAX3\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-07-28 & 15.0 & 15.0 & 15.0 \\\\\n",
       "\t2 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-08-01 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t3 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-08-22 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t4 & 4240-01D & 1.28137 & 1.24035 & -1.19178 & 2019-09-28 & 39.0 & 15.0 & 25.0 \\\\\n",
       "\t5 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-08-14 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t6 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-07-13 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 4380-01D & -0.828933 & 0.658409 & -0.0467296 & 2019-05-09 & 89.0 & 45.0 & 89.0 \\\\\n",
       "\t8 & 4240-01D & 1.28137 & 1.24035 & -1.19178 & 2019-06-08 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\t9 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-31 & 5.0 & 5.0 & 5.0 \\\\\n",
       "\t10 & 4350-01D & -0.465715 & 0.725081 & -0.0467296 & 2019-07-04 & 0.0 & 0.0 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT    │ TP_LNG    │ TP_Z       │ DATE       │ PCP_SUM │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mDate\u001b[39m       │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼────────────┼───────────┼───────────┼────────────┼────────────┼─────────┤\n",
       "│ 1   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-07-28 │ 15.0    │\n",
       "│ 2   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333  │ 2019-08-01 │ 0.0     │\n",
       "│ 3   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333  │ 2019-08-22 │ 0.0     │\n",
       "│ 4   │ 4240-01D   │ 1.28137   │ 1.24035   │ -1.19178   │ 2019-09-28 │ 39.0    │\n",
       "│ 5   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-08-14 │ 0.0     │\n",
       "│ 6   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-07-13 │ 0.0     │\n",
       "│ 7   │ 4380-01D   │ -0.828933 │ 0.658409  │ -0.0467296 │ 2019-05-09 │ 89.0    │\n",
       "│ 8   │ 4240-01D   │ 1.28137   │ 1.24035   │ -1.19178   │ 2019-06-08 │ 0.0     │\n",
       "│ 9   │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267   │ 2019-05-31 │ 5.0     │\n",
       "│ 10  │ 4350-01D   │ -0.465715 │ 0.725081  │ -0.0467296 │ 2019-07-04 │ 0.0     │"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(test_comb), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize PCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comb.PCP_SUM = (test_comb.PCP_SUM .- mean_pcpsum) ./ std_pcpsum;\n",
    "test_comb.PCP_MAX = (test_comb.PCP_MAX .- mean_pcpmax) ./ std_pcpmax;\n",
    "test_comb.PCP_MAX3 = (test_comb.PCP_MAX3 .- mean_pcpmax3) ./ std_pcpmax3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>DATE</th><th>PCP_SUM</th><th>PCP_MAX</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Date</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>20 rows × 8 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-02</td><td>-0.0469042</td><td>-0.0325426</td></tr><tr><th>2</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-09</td><td>0.808886</td><td>0.982661</td></tr><tr><th>3</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-10</td><td>4.82974</td><td>1.6287</td></tr><tr><th>4</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-15</td><td>-0.37292</td><td>-0.34018</td></tr><tr><th>5</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-20</td><td>0.224775</td><td>0.828842</td></tr><tr><th>6</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-23</td><td>1.97711</td><td>1.53641</td></tr><tr><th>7</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-24</td><td>-0.223496</td><td>-0.124834</td></tr><tr><th>8</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-26</td><td>-0.359336</td><td>-0.309416</td></tr><tr><th>9</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>2019-05-30</td><td>-0.305</td><td>-0.186361</td></tr><tr><th>10</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-01</td><td>0.238359</td><td>0.244331</td></tr><tr><th>11</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-02</td><td>-0.223496</td><td>-0.155598</td></tr><tr><th>12</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-08</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>13</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-09</td><td>0.768134</td><td>0.921133</td></tr><tr><th>14</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-10</td><td>3.47134</td><td>1.07495</td></tr><tr><th>15</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-11</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>16</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-13</td><td>-0.277832</td><td>-0.124834</td></tr><tr><th>17</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-14</td><td>1.01265</td><td>0.15204</td></tr><tr><th>18</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-18</td><td>-0.37292</td><td>-0.34018</td></tr><tr><th>19</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-19</td><td>0.374199</td><td>0.428913</td></tr><tr><th>20</th><td>3350-07D</td><td>0.0802391</td><td>-0.325532</td><td>0.168267</td><td>2019-05-20</td><td>0.319863</td><td>1.16724</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & DATE & PCP\\_SUM & PCP\\_MAX & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Date & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-02 & -0.0469042 & -0.0325426 & $\\dots$ \\\\\n",
       "\t2 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-09 & 0.808886 & 0.982661 & $\\dots$ \\\\\n",
       "\t3 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-10 & 4.82974 & 1.6287 & $\\dots$ \\\\\n",
       "\t4 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-15 & -0.37292 & -0.34018 & $\\dots$ \\\\\n",
       "\t5 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-20 & 0.224775 & 0.828842 & $\\dots$ \\\\\n",
       "\t6 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-23 & 1.97711 & 1.53641 & $\\dots$ \\\\\n",
       "\t7 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-24 & -0.223496 & -0.124834 & $\\dots$ \\\\\n",
       "\t8 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-26 & -0.359336 & -0.309416 & $\\dots$ \\\\\n",
       "\t9 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 2019-05-30 & -0.305 & -0.186361 & $\\dots$ \\\\\n",
       "\t10 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-01 & 0.238359 & 0.244331 & $\\dots$ \\\\\n",
       "\t11 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-02 & -0.223496 & -0.155598 & $\\dots$ \\\\\n",
       "\t12 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-08 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t13 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-09 & 0.768134 & 0.921133 & $\\dots$ \\\\\n",
       "\t14 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-10 & 3.47134 & 1.07495 & $\\dots$ \\\\\n",
       "\t15 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-11 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t16 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-13 & -0.277832 & -0.124834 & $\\dots$ \\\\\n",
       "\t17 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-14 & 1.01265 & 0.15204 & $\\dots$ \\\\\n",
       "\t18 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-18 & -0.37292 & -0.34018 & $\\dots$ \\\\\n",
       "\t19 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-19 & 0.374199 & 0.428913 & $\\dots$ \\\\\n",
       "\t20 & 3350-07D & 0.0802391 & -0.325532 & 0.168267 & 2019-05-20 & 0.319863 & 1.16724 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "20×8 DataFrame. Omitted printing of 3 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT    │ TP_LNG    │ TP_Z      │ DATE       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mDate\u001b[39m       │\n",
       "├─────┼────────────┼───────────┼───────────┼───────────┼────────────┤\n",
       "│ 1   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-02 │\n",
       "│ 2   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-09 │\n",
       "│ 3   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-10 │\n",
       "│ 4   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-15 │\n",
       "│ 5   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-20 │\n",
       "│ 6   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-23 │\n",
       "│ 7   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-24 │\n",
       "│ 8   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-26 │\n",
       "│ 9   │ 3260-01D   │ 1.29293   │ 0.531312  │ 0.0790333 │ 2019-05-30 │\n",
       "│ 10  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-01 │\n",
       "│ 11  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-02 │\n",
       "│ 12  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-08 │\n",
       "│ 13  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-09 │\n",
       "│ 14  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-10 │\n",
       "│ 15  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-11 │\n",
       "│ 16  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-13 │\n",
       "│ 17  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-14 │\n",
       "│ 18  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-18 │\n",
       "│ 19  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-19 │\n",
       "│ 20  │ 3350-07D   │ 0.0802391 │ -0.325532 │ 0.168267  │ 2019-05-20 │"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(test_comb, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dates into month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>DATE</th><th>MONTH</th><th>DAY</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>2019-09-13</td><td>9</td><td>13</td></tr><tr><th>2</th><td>2019-05-02</td><td>5</td><td>2</td></tr><tr><th>3</th><td>2019-08-06</td><td>8</td><td>6</td></tr><tr><th>4</th><td>2019-09-26</td><td>9</td><td>26</td></tr><tr><th>5</th><td>2019-06-30</td><td>6</td><td>30</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& DATE & MONTH & DAY\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-09-13 & 9 & 13 \\\\\n",
       "\t2 & 2019-05-02 & 5 & 2 \\\\\n",
       "\t3 & 2019-08-06 & 8 & 6 \\\\\n",
       "\t4 & 2019-09-26 & 9 & 26 \\\\\n",
       "\t5 & 2019-06-30 & 6 & 30 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ DATE       │ MONTH │ DAY   │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼────────────┼───────┼───────┤\n",
       "│ 1   │ 2019-09-13 │ 9     │ 13    │\n",
       "│ 2   │ 2019-05-02 │ 5     │ 2     │\n",
       "│ 3   │ 2019-08-06 │ 8     │ 6     │\n",
       "│ 4   │ 2019-09-26 │ 9     │ 26    │\n",
       "│ 5   │ 2019-06-30 │ 6     │ 30    │"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comb.MONTH = month.(test_comb.DATE);\n",
    "test_comb.DAY = day.(test_comb.DATE);\n",
    "\n",
    "first(shuffleDf(test_comb[!, [:DATE, :MONTH, :DAY]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize months and days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comb.MONTH = (test_comb.MONTH .- meanmonth) ./ stdmonth;\n",
    "test_comb.DAY = (test_comb.DAY .- meanday) ./ stdday;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>TP_LAT</th><th>TP_LNG</th><th>TP_Z</th><th>MONTH</th><th>DAY</th><th>PCP_SUM</th><th>PCP_MAX</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 9 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>4240-01D</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td><td>-0.875331</td><td>-0.88625</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>2</th><td>4240-01D</td><td>1.28137</td><td>1.24035</td><td>-1.19178</td><td>-1.45983</td><td>-0.999235</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>3</th><td>4380-01D</td><td>-0.828933</td><td>0.658409</td><td>-0.0467296</td><td>-0.875331</td><td>1.37345</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>4</th><td>4350-01D</td><td>-0.465715</td><td>0.725081</td><td>-0.0467296</td><td>0.293667</td><td>0.356584</td><td>-0.400087</td><td>-0.401707</td></tr><tr><th>5</th><td>3260-01D</td><td>1.29293</td><td>0.531312</td><td>0.0790333</td><td>0.878166</td><td>-1.2252</td><td>-0.400087</td><td>-0.401707</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& ID\\_OUVRAGE & TP\\_LAT & TP\\_LNG & TP\\_Z & MONTH & DAY & PCP\\_SUM & PCP\\_MAX & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 4240-01D & 1.28137 & 1.24035 & -1.19178 & -0.875331 & -0.88625 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t2 & 4240-01D & 1.28137 & 1.24035 & -1.19178 & -1.45983 & -0.999235 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t3 & 4380-01D & -0.828933 & 0.658409 & -0.0467296 & -0.875331 & 1.37345 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t4 & 4350-01D & -0.465715 & 0.725081 & -0.0467296 & 0.293667 & 0.356584 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\t5 & 3260-01D & 1.29293 & 0.531312 & 0.0790333 & 0.878166 & -1.2252 & -0.400087 & -0.401707 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×9 DataFrame. Omitted printing of 3 columns\n",
       "│ Row │ ID_OUVRAGE │ TP_LAT    │ TP_LNG   │ TP_Z       │ MONTH     │ DAY       │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼────────────┼───────────┼──────────┼────────────┼───────────┼───────────┤\n",
       "│ 1   │ 4240-01D   │ 1.28137   │ 1.24035  │ -1.19178   │ -0.875331 │ -0.88625  │\n",
       "│ 2   │ 4240-01D   │ 1.28137   │ 1.24035  │ -1.19178   │ -1.45983  │ -0.999235 │\n",
       "│ 3   │ 4380-01D   │ -0.828933 │ 0.658409 │ -0.0467296 │ -0.875331 │ 1.37345   │\n",
       "│ 4   │ 4350-01D   │ -0.465715 │ 0.725081 │ -0.0467296 │ 0.293667  │ 0.356584  │\n",
       "│ 5   │ 3260-01D   │ 1.29293   │ 0.531312 │ 0.0790333  │ 0.878166  │ -1.2252   │"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(shuffleDf(test_comb[!, [:ID_OUVRAGE, :TP_LAT, :TP_LNG, :TP_Z, :MONTH, :DAY, :PCP_SUM, :PCP_MAX, :PCP_MAX3]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is of type Uniform with a BIC of -152541.51364510704\n",
      "The best model is of type Uniform with a BIC of -5436.80430390067\n",
      "The best model is of type Uniform with a BIC of -159558.3867488944\n",
      "The best model is of type Normal with a BIC of -4467.086529136986\n",
      "The best model is of type Normal with a BIC of -175192.39090162498\n",
      "The best model is of type Normal with a BIC of -5572.954294527319\n",
      "The best model is of type Uniform with a BIC of -132033.1741631602\n",
      "The best model is of type Uniform with a BIC of -4705.856867383811\n",
      "The best model is of type Uniform with a BIC of -150285.9631051927\n",
      "The best model is of type Uniform with a BIC of -5356.413159286683\n",
      "The best model is of type Normal with a BIC of -158350.57058899855\n",
      "The best model is of type Normal with a BIC of -9306.943331354872\n",
      "The best model is of type Normal with a BIC of -161360.19792138768\n",
      "The best model is of type Laplace with a BIC of -8822.699148219668\n",
      "The best model is of type Normal with a BIC of -159480.01370342379\n",
      "The best model is of type Laplace with a BIC of -9111.469228562066\n",
      "Best combination: Symbol[:TP_LNG, :TP_Z, :PCP_SUM, :PCP_MAX] with f1score: 0.3772087991345114\n",
      "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
     ]
    }
   ],
   "source": [
    "test_labels = trainOnValidationAndPredictNaiveBayes(train_set,val_set, test_comb, names_ft);\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"submissions/mgh-submission-2.csv\""
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = test_comb[:,:ID_OUVRAGE].*\"_\".*string.(test_comb[:,:DATE])\n",
    "sampleSubmission = DataFrame(ID = ID, Surverse=test_labels)\n",
    "CSV.write(\"submissions/mgh-submission-2.csv\",sampleSubmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "283\n",
      "Le modéle est précis à 89.04593639575971 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.04593639575971"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine = CSV.read(\"submissions/mgh-submission-2.csv\");\n",
    "mc =CSV.read(\"submissions/mc-submission-10.csv\");\n",
    "compareArr(mine[:, :Surverse], mc[:, :Surverse], true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
