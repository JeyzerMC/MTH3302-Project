{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Random;\n",
    "include(\"utils/precipitation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde les ouvrages d'intérêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages = CSV.read(\"data/ouvrages-surverses.csv\");\n",
    "colnames = [\"N_Env\", \"ID_SOMA\", \"ID_OUVRAGE\", \"NOM\", \"SOMA_SEC\", \"REGION\", \"TP_X\", \"TP_Y\", \"TP_Z\", \"TP_LAT\", \"TP_LNG\", \"EMI_X\", \"EMI_Y\", \"EMI_LNG\", \"EMI_LAT\"];\n",
    "names!(ouvrages, Symbol.(colnames));\n",
    "select!(ouvrages, [:ID_OUVRAGE, :TP_LAT, :TP_LNG]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(ouvrages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_ouvrages = [\"3260-01D\", \"3350-07D\", \"4240-01D\", \"4350-01D\", \"4380-01D\"];\n",
    "ouvrages = filter(row -> row.ID_OUVRAGE ∈ important_ouvrages, ouvrages);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(ouvrages, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\", missingstring=\"-99999\");\n",
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);\n",
    "surverses[!,:RAISON] = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = filter(row -> row.ID_OUVRAGE ∈ important_ouvrages, surverses);\n",
    "dropmissing!(surverses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(surverses[!, :SURVERSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = filter(row -> row.ID_OUVRAGE == important_ouvrages[3], surverses);\n",
    "describe(curr[!, :SURVERSE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le mean correspond au taux de surverses ici -> Beaucoup plus de non surverses que de surverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beaucoup plus de 0 que de 1 -> Class imbalance problem\n",
    "On le solve avec du over sampling de 1 et du under sampling de 0, plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitations, Symbol(\"St-Hubert\")=>:StHubert);\n",
    "\n",
    "precipitations = filter(row -> month(row.date) > 4, precipitations);\n",
    "precipitations = filter(row -> month(row.date) < 11, precipitations); \n",
    "names(precipitations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(precipitations[!, :StHubert])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données abérantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_outliers = precipitations[!, :McTavish] .> 2000;\n",
    "idx_outliers[isequal.(idx_outliers, missing)] .= false;\n",
    "idx_outliers = convert(Array{Bool, 1}, idx_outliers);\n",
    "\n",
    "date_outlier = precipitations[idx_outliers, :date];\n",
    "precipitations[idx_outliers, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations[idx_outliers, :McTavish] .= 0;\n",
    "precipitations[idx_outliers, :StHubert] .= 0;\n",
    "precipitations[idx_outliers, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations[precipitations.date .== Date(2017, 7, 20), :Bellevue] .= 0;\n",
    "precipitations[precipitations.date .== Date(2017, 7, 20), :Trudeau] .= 0; # VOIR SI GARDER LUI\n",
    "\n",
    "precipitations[precipitations.date .== Date(2013, 6, 24), :Assomption] .= 0;\n",
    "precipitations[precipitations.date .== Date(2014, 8, 5), :Assomption] .= 0;\n",
    "precipitations[precipitations.date .== Date(2015, 6, 10), :Assomption] .= 0;\n",
    "precipitations[precipitations.date .== Date(2018, 7, 26), :Trudeau] .= 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_by_day = by(precipitations, :date,  \n",
    "                            McTavish = :McTavish=>mean_wo_missing, \n",
    "                            Bellevue = :Bellevue=>mean_wo_missing, \n",
    "                            Assomption = :Assomption=>mean_wo_missing,\n",
    "                            Trudeau = :Trudeau=>mean_wo_missing,\n",
    "                            StHubert = :StHubert=>mean_wo_missing)\n",
    "\n",
    "for i=1:size(precipitations,1)\n",
    "    if isequal(precipitations[i, :McTavish], missing)\n",
    "        precipitations[i,:McTavish] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:McTavish][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Bellevue], missing)\n",
    "        precipitations[i,:Bellevue] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Bellevue][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Assomption], missing)\n",
    "        precipitations[i,:Assomption] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Assomption][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Trudeau], missing)\n",
    "        precipitations[i,:Trudeau] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Trudeau][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :StHubert], missing)\n",
    "        precipitations[i,:StHubert] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:StHubert][1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(precipitations[!, :StHubert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(precipitations), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>sum, \n",
    "            Bellevue = :Bellevue=>sum,\n",
    "            Assomption = :Assomption=>sum, \n",
    "            Trudeau = :Trudeau=>sum, \n",
    "            StHubert = :StHubert=>sum);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(pcp_sum), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = melt(pcp_sum, :date)\n",
    "set_default_plot_size(25cm, 13cm)\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.point, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réduit le gros outlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>maximum,\n",
    "            Bellevue = :Bellevue=>maximum, \n",
    "            Assomption = :Assomption=>maximum,\n",
    "            Trudeau = :Trudeau=>maximum,\n",
    "            StHubert = :StHubert=>maximum);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = melt(pcp_max, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.point, color=:variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(pcp_max), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max3 = by(precipitations, :date,\n",
    "                McTavish = :McTavish=>maximum3,\n",
    "                Bellevue = :Bellevue=>maximum3,\n",
    "                Assomption = :Assomption=>maximum3,\n",
    "                Trudeau = :Trudeau=>maximum3,\n",
    "                StHubert = :StHubert=>maximum3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_for_plot = melt(pcp_max3, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.point, color=:variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(pcp_max3), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardiser les données de précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standardize_col(col)\n",
    "    mean_col = mean(col);\n",
    "    std_col = std(col);\n",
    "    \n",
    "    res = (col .- mean_col) ./ std_col;\n",
    "    \n",
    "    return res;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum[!, :McTavish] = standardize_col(pcp_sum[!, :McTavish]);\n",
    "pcp_sum[!, :Bellevue] = standardize_col(pcp_sum[!, :Bellevue]);\n",
    "pcp_sum[!, :Assomption] = standardize_col(pcp_sum[!, :Assomption]);\n",
    "pcp_sum[!, :Trudeau] = standardize_col(pcp_sum[!, :Trudeau]);\n",
    "pcp_sum[!, :StHubert] = standardize_col(pcp_sum[!, :StHubert]);\n",
    "\n",
    "pcp_max[!, :McTavish] = standardize_col(pcp_max[!, :McTavish]);\n",
    "pcp_max[!, :Bellevue] = standardize_col(pcp_max[!, :Bellevue]);\n",
    "pcp_max[!, :Assomption] = standardize_col(pcp_max[!, :Assomption]);\n",
    "pcp_max[!, :Trudeau] = standardize_col(pcp_max[!, :Trudeau]);\n",
    "pcp_max[!, :StHubert] = standardize_col(pcp_max[!, :StHubert]);\n",
    "\n",
    "pcp_max3[!, :McTavish] = standardize_col(pcp_max3[!, :McTavish]);\n",
    "pcp_max3[!, :Bellevue] = standardize_col(pcp_max3[!, :Bellevue]);\n",
    "pcp_max3[!, :Assomption] = standardize_col(pcp_max3[!, :Assomption]);\n",
    "pcp_max3[!, :Trudeau] = standardize_col(pcp_max3[!, :Trudeau]);\n",
    "pcp_max3[!, :StHubert] = standardize_col(pcp_max3[!, :StHubert]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(pcp_sum), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = DataFrame(STATION = String[], LAT = Float64[], LNG = Float64[]);\n",
    "\n",
    "push!(station_df, [\"McTavish\", 45.504742, -73.579167]);\n",
    "push!(station_df, [\"Bellevue\", 45.427222, -73.929167]);\n",
    "push!(station_df, [\"Assomption\", 45.809444, -73.434722]);\n",
    "push!(station_df, [\"Trudeau\", 45.467778, -73.741667]);\n",
    "push!(station_df, [\"StHubert\", 45.5175, -73.416944]);\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On ajoute les colonnes de précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = surverses;\n",
    "\n",
    "train_data[!, :FS_dist] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_dist] = zeros(size(train_data, 1));\n",
    "train_data[!, :FS_sum] = zeros(size(train_data, 1));\n",
    "train_data[!, :FS_max] = zeros(size(train_data, 1));\n",
    "train_data[!, :FS_max3] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_sum] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_max] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_max3] = zeros(size(train_data, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(shuffleDf(train_data), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train_data[!, :SURVERSE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate les fields de chaque data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(train_data, 1)\n",
    "    curr_ouvrage = train_data[i, 1];\n",
    "    ouvrage_data = filter(row -> row.ID_OUVRAGE == curr_ouvrage, ouvrages);\n",
    "    \n",
    "    closest_station = nothing;\n",
    "    closest_distance = 9999;\n",
    "    \n",
    "    second_closest_station = nothing;\n",
    "    second_closest_distance = 9999;\n",
    "    \n",
    "    # Pour chaque station\n",
    "    for j=1:5\n",
    "       current_station = station_df[j, :STATION];\n",
    "       dist = findDistance(ouvrage_data[1, :TP_LAT], ouvrage_data[1, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "       \n",
    "        if dist < closest_distance\n",
    "            second_closest_distance = closest_distance;\n",
    "            second_closest_station = closest_station;\n",
    "            closest_distance = dist;\n",
    "            closest_station = current_station;\n",
    "        elseif dist < second_closest_distance\n",
    "            second_closest_distance = dist;\n",
    "            second_closest_station = current_station;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    train_data[i, :FS_dist] = closest_distance;\n",
    "    train_data[i, :SS_dist] = second_closest_distance;\n",
    "    \n",
    "    # Add data for first station\n",
    "    sum_p = pcp_sum[∈([train_data[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "    train_data[i, :FS_sum] = sum_p[1];\n",
    "    max_p = pcp_max[∈([train_data[i, :DATE]]).(pcp_max.date), Symbol(closest_station)];\n",
    "    train_data[i, :FS_max] = max_p[1];\n",
    "    max3_p = pcp_max3[∈([train_data[i, :DATE]]).(pcp_max3.date), Symbol(closest_station)];\n",
    "    train_data[i, :FS_max3] = max3_p[1];\n",
    "    \n",
    "    # Find multiplier for second station\n",
    "    ratio = second_closest_distance / closest_distance;\n",
    "    logratio = log(sqrt(ratio));\n",
    "    multiplier = 1 - logratio;\n",
    "    \n",
    "    # Add data for second station\n",
    "    s_sum_p = pcp_sum[∈([train_data[i, :DATE]]).(pcp_sum.date), Symbol(second_closest_station)];\n",
    "    train_data[i, :SS_sum] = s_sum_p[1] * multiplier;\n",
    "    s_max_p = pcp_max[∈([train_data[i, :DATE]]).(pcp_max.date), Symbol(second_closest_station)];\n",
    "    train_data[i, :SS_max] = s_max_p[1] * multiplier;\n",
    "    s_max3_p = pcp_max3[∈([train_data[i, :DATE]]).(pcp_max3.date), Symbol(second_closest_station)];\n",
    "    train_data[i, :SS_max3] = s_max3_p[1] * multiplier;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [:ID_OUVRAGE, :SURVERSE, :FS_dist, :SS_dist, :FS_sum, :SS_sum, :FS_max, :SS_max];\n",
    "first(shuffleDf(train_data[!, cols]), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes in files per ouvrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_3260 = filter(row -> row.ID_OUVRAGE == \"3260-01D\", train_data);\n",
    "select!(ouvrage_3260, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/ouvrage_3260.csv\",ouvrage_3260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_3350 = filter(row -> row.ID_OUVRAGE == \"3350-07D\", train_data)\n",
    "select!(ouvrage_3350, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/ouvrage_3350.csv\",ouvrage_3350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_4240 = filter(row -> row.ID_OUVRAGE == \"4240-01D\", train_data)\n",
    "select!(ouvrage_4240, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/ouvrage_4240.csv\",ouvrage_4240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_4350 = filter(row -> row.ID_OUVRAGE == \"4350-01D\", train_data)\n",
    "select!(ouvrage_4350, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/ouvrage_4350.csv\",ouvrage_4350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_4380 = filter(row -> row.ID_OUVRAGE == \"4380-01D\", train_data)\n",
    "select!(ouvrage_4380, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/ouvrage_4380.csv\",ouvrage_4380)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CSV.read(\"data/test.csv\");\n",
    "rename!(test_data, :NO_OUVRAGE => :ID_OUVRAGE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(test_data[:,:ID_OUVRAGE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[!, :FS_dist] = zeros(size(test_data, 1));\n",
    "test_data[!, :SS_dist] = zeros(size(test_data, 1));\n",
    "test_data[!, :FS_sum] = zeros(size(test_data, 1));\n",
    "test_data[!, :FS_max] = zeros(size(test_data, 1));\n",
    "test_data[!, :FS_max3] = zeros(size(test_data, 1));\n",
    "test_data[!, :SS_sum] = zeros(size(test_data, 1));\n",
    "test_data[!, :SS_max] = zeros(size(test_data, 1));\n",
    "test_data[!, :SS_max3] = zeros(size(test_data, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(test_data, 1)\n",
    "    curr_ouvrage = test_data[i, 1];\n",
    "    ouvrage_data = filter(row -> row.ID_OUVRAGE == curr_ouvrage, ouvrages);\n",
    "    \n",
    "    closest_station = nothing;\n",
    "    closest_distance = 9999;\n",
    "    \n",
    "    second_closest_station = nothing;\n",
    "    second_closest_distance = 9999;\n",
    "    \n",
    "    # Pour chaque station\n",
    "    for j=1:5\n",
    "       current_station = station_df[j, :STATION];\n",
    "       dist = findDistance(ouvrage_data[1, :TP_LAT], ouvrage_data[1, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "       \n",
    "        if dist < closest_distance\n",
    "            second_closest_distance = closest_distance;\n",
    "            second_closest_station = closest_station;\n",
    "            closest_distance = dist;\n",
    "            closest_station = current_station;\n",
    "        elseif dist < second_closest_distance\n",
    "            second_closest_distance = dist;\n",
    "            second_closest_station = current_station;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    test_data[i, :FS_dist] = closest_distance;\n",
    "    test_data[i, :SS_dist] = second_closest_distance;\n",
    "    \n",
    "    # Add data for first station\n",
    "    sum_p = pcp_sum[∈([test_data[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "    test_data[i, :FS_sum] = sum_p[1];\n",
    "    max_p = pcp_max[∈([test_data[i, :DATE]]).(pcp_max.date), Symbol(closest_station)];\n",
    "    test_data[i, :FS_max] = max_p[1];\n",
    "    max3_p = pcp_max3[∈([test_data[i, :DATE]]).(pcp_max3.date), Symbol(closest_station)];\n",
    "    test_data[i, :FS_max3] = max3_p[1];\n",
    "    \n",
    "    # Find multiplier for second station\n",
    "    ratio = second_closest_distance / closest_distance;\n",
    "    logratio = log(sqrt(ratio));\n",
    "    multiplier = 1 - logratio;\n",
    "    \n",
    "    # Add data for second station\n",
    "    s_sum_p = pcp_sum[∈([test_data[i, :DATE]]).(pcp_sum.date), Symbol(second_closest_station)];\n",
    "    test_data[i, :SS_sum] = s_sum_p[1] * multiplier;\n",
    "    s_max_p = pcp_max[∈([test_data[i, :DATE]]).(pcp_max.date), Symbol(second_closest_station)];\n",
    "    test_data[i, :SS_max] = s_max_p[1] * multiplier;\n",
    "    s_max3_p = pcp_max3[∈([test_data[i, :DATE]]).(pcp_max3.date), Symbol(second_closest_station)];\n",
    "    test_data[i, :SS_max3] = s_max3_p[1] * multiplier;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [:ID_OUVRAGE, :FS_dist, :SS_dist, :FS_sum, :SS_sum, :FS_max, :SS_max];\n",
    "first(shuffleDf(test_data[!, cols]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3260 = filter(row -> row.ID_OUVRAGE == \"3260-01D\", test_data);\n",
    "select!(test_3260, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/test_3260.csv\",test_3260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3350 = filter(row -> row.ID_OUVRAGE == \"3350-07D\", test_data);\n",
    "select!(test_3350, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/test_3350.csv\",test_3350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4240 = filter(row -> row.ID_OUVRAGE == \"4240-01D\", test_data);\n",
    "select!(test_4240, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/test_4240.csv\",test_4240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4350 = filter(row -> row.ID_OUVRAGE == \"4350-01D\", test_data);\n",
    "select!(test_4350, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/test_4350.csv\",test_4350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4380 = filter(row -> row.ID_OUVRAGE == \"4380-01D\", test_data);\n",
    "select!(test_4380, Not(:ID_OUVRAGE));\n",
    "CSV.write(\"data/parsed/test_4380.csv\",test_4380)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
