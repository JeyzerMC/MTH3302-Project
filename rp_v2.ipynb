{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport de projet final: Débordement d'égouts\n",
    "## Équipe 9 - A19\n",
    "#### _Noboru Yoshida - Mehdi Chaid - Mathieu Giroux-Huppé - Maxime Gosselin_\n",
    "<br>\n",
    "20 Décembre 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières\n",
    "\n",
    "+ [1. Introduction](#1.)\n",
    "    + [1.1. Objectifs](#1.1.)  \n",
    "    + [1.2. Méthode de travail](#1.2.)  \n",
    "<br>\n",
    "+ [2. Analyse exploratoire](#2.)\n",
    "    + [2.1. Motivation](#2.1.)  \n",
    "    + [2.2. Importation des données](#2.2.)  \n",
    "    + [2.3. Fonctions utilisées](#2.3.)\n",
    "    + [2.4. Analyse des données d'ouvrages](#2.4.)  \n",
    "        + [2.4.1. Données discrètes](#2.4.1.)\n",
    "        + [2.4.2. Données de Trop-Plein](#2.4.2.)\n",
    "        + [2.4.3. Données d'Emissaire](#2.4.3.)\n",
    "    + [2.5. Analyse des données de précipitations](#2.5.)  \n",
    "        + [2.5.1. Données de précipitations](#2.5.1.)\n",
    "        + [2.5.2. Somme des précipitations journalières](#2.5.2.)\n",
    "        + [2.5.3. Taux horaire maximal de précipitations journalières](#2.5.3.)\n",
    "        + [2.5.4. Taux sur trois heures maximal des précipitations journalières](#2.5.4.)\n",
    "    + [2.6. Analyse des données de surverses](#2.6.)\n",
    "        + [2.6.1. Chargement des surverses pour analyse](#2.6.1.)\n",
    "        + [2.6.2. Lien entre ouvrages et surverses](#2.6.2.)\n",
    "        + [2.6.3. Lien entre précipitations de surverses](#2.6.3.)\n",
    "    + [2.7. Isolation des ouvrages d'intérêts](#2.7.)\n",
    "        + [2.7.1. Motivation](#2.7.1.)\n",
    "        + [2.7.2. Chargement des données traitées](#2.7.2.)\n",
    "        + [2.7.3. Station la plus proche](#2.7.3.)\n",
    "        + [2.7.4. Deuxième station la plus proche](#2.7.4.)\n",
    "    + [2.8. Retour sur l'analyse](#2.8.)\n",
    "<br>\n",
    "\n",
    "\n",
    "+ [3. Traitement des données](#3.)\n",
    "    + [3.1. Motivation](#3.1.)  \n",
    "    + [3.2. Processus de traitement](#3.2.)\n",
    "    + [3.3. Fonctions utilisées](#3.3.)\n",
    "    + [3.4. Considérations et étapes retenues](#3.4.)\n",
    "    + [3.5. Isolation des ouvrages](#3.6.)\n",
    "    + [3.6. Rafinements isolés](#3.7.)\n",
    "<br>\n",
    "\n",
    "\n",
    "+ [4. Sélection de modèles](#4.)\n",
    "    + [4.1. Motivation](#4.1)\n",
    "    + [4.2. Choix des modèles](#4.2.)\n",
    "    + [4.3. Arbres de décision et forêt aléatoire](#4.3.)  \n",
    "    + [4.4. Régression logistique](#4.4.)  \n",
    "    + [4.5. Machine à vecteurs de support](#4.5.)  \n",
    "    + [4.6. Classification bayésienne naive](#4.6.)  \n",
    "    + [4.7. Ensemble de modèles](#4.7.)  \n",
    "<br>\n",
    "+ [5. Retour et conclusion](#5.)\n",
    "    + [5.1. Retour sur les résultats](#5.1.)  \n",
    "    + [5.2. Améliorations possibles](#5.2.)\n",
    "    + [5.3. Difficultés rencontrées](#5.3.)\n",
    "        + [5.3.1. Interpretation des données](#5.3.1.)\n",
    "    + [5.4. Conclusion](#5.5.)  \n",
    "<br>\n",
    "\n",
    "+ [6. Références](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.\"></a>\n",
    "\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1.\"></a>\n",
    "### 1.1. Objectifs\n",
    "\n",
    "Ce rapport vise à fournir une prédiction sur les surverses dans plusieurs ouvrages sur l'île de Montréal. Il en existe 170 répartis sur tout le bord de l'île. Dans ce travail, nous nous attarderons sur la prédiction de seulement 5 d'entre-eux, soit les suivants :\n",
    "- 3260-01D dans Rivière-des-Prairies\n",
    "- 3350-07D dans Ahunstic\n",
    "- 4240-01D dans Pointe-aux-Trembles\n",
    "- 4350-01D dans le Vieux-Montréal\n",
    "- 4380-01D dans Verdun\n",
    "\n",
    "Nous avons à notre disposition 3 jeux de données qui nous aiderons à trouver une relation entre la quantité de pluie tombé et les surverses de certain ouvrages. Nous devrons alors entraîner un modèle sur les données de 2013 à 2018, puis prédire sur certaines dates de 2019. Il n'y pas de restrictions au niveau des techniques à utilisés pour le type de modèle à utiliser. Nous avons exploré quelques techniques différentes que nous allons détaillé plus en détail dans la [section 5](#model-selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2.\"></a>\n",
    "### 1.2. Déroulement de travail\n",
    "\n",
    "Le projet s'est déroulé de la sorte: \n",
    "\n",
    " 1. Tout d'abord, nous avons effectué une analyse superficielle des données afin de comprendre leur sens et de pouvoir commencer la tâche.\n",
    "\n",
    " 2. Puis, nous avons procédé à une exploration initiale des modèles selon les données que nous avons et en pesant les avantages et inconvénients de chaque modèle afin de déterminer les plus appropriés.\n",
    "\n",
    " 3. Par la suite, nous avons effectué un traitement initiale des données afin de les intégrer aux modèles.\n",
    "\n",
    " 4. À cette étape, nous avons appliqué les multiples modèles choisis à nos données traitées afin de les analyser et d'isoler les plus performants.\n",
    "\n",
    " 5. Nous avons ensuite procédé à une analyse plus poussée afin de trouver des manière d'améliorer nos données.\n",
    "\n",
    " 6. Nous avons alors traité plus en profondeur les données pour les adapter à la situation et rendre nos modèles plus robustes.\n",
    "\n",
    " 7. Finalement, nous avons rafiné les modèles selon ces nouvelles données, menant à nos prédictions finales.\n",
    "\n",
    "Nous aborderons dans ce rapport chacune de ces parties, séparées en 3 groupes: l'analyse exploratoire, le traitement de données et la sélection de modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.\"></a>\n",
    "## 2. Analyse exploratoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.1.\"></a>\n",
    "### 2.1. Motivation\n",
    "\n",
    "L'analyse exploratoire est une très importante pour tout exercice en sciences de données. Elle permet de déterminer, entres autres:\n",
    "\n",
    "- Quelles variables vont jouer un rôle important pour la prédiction.\n",
    "- À quel point les variables sont corrélées entre elles.\n",
    "- Si une régularisation est nécessaire pour certaines variables.\n",
    "- Comment améliorer le temps d'entrainement et les prédictions.\n",
    "\n",
    "Pour ce faire, nous allons analyser chacune des variables explicatives en utilisant des graphes et des statistiques afin d'appuyer nos résultats et de guider notre prise de décision.\n",
    "\n",
    "Cette section du rapport, qui est assez longue, peut être ignorée si le lecteur est déjà familier avec les jeux de données utilisés. Elle permet néanmoins de mieux comprendre comment nous avons choisi les variables d'intérêts et comment nous sommes arrivés aux conclusions que nous avons tiré lors de la préparation de modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.2.\"></a>\n",
    "### 2.2. Importation des données\n",
    "\n",
    "Installons d'abord les libraires utilisées pour l'analyse exploratoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"CSV\");\n",
    "Pkg.add(\"Random\");\n",
    "Pkg.add(\"DataStructures\");\n",
    "Pkg.add(\"BenchmarkTools\");\n",
    "Pkg.add(\"DataFrames\");\n",
    "Pkg.add(\"Statistics\");\n",
    "Pkg.add(\"Dates\");\n",
    "Pkg.add(\"Gadfly\");\n",
    "Pkg.add(\"IterTools\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importons maintenant ces librairies dans le rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading DataFrames support into Gadfly.jl\n",
      "└ @ Gadfly /home/chaime/.julia/packages/Gadfly/09PWZ/src/mapping.jl:228\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, DataStructures, BenchmarkTools, Statistics, Dates, Gadfly, Random, IterTools;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration de l'outil de visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(25cm, 13cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3.\"></a>\n",
    "### 2.3. Fonctions utilisées [TODO: COMPLETER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons ici les fonctions utilisées pour l'analyse exploratoire de données. Ces fonctions sont implémentées dans le fichier suivant afin de ne pas polluer le rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"utils/precipitation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3.1.\"></a>\n",
    "#### 2.3.1. random_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette function est un remplacement à la fonction first qui nous permet d'obtenir un échantillon aléatoire de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_first (generic function with 2 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function random_first(df::DataFrame, nb::Int64, fts::Array=[])\n",
    "    if length(fts) == 0\n",
    "        first(df[shuffle(1:size(df, 1)),:], nb)\n",
    "    else\n",
    "        first(df[shuffle(1:size(df, 1)),fts], nb)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3.2.\"></a>\n",
    "#### 2.3.2. maximum_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4.\"></a>\n",
    "### 2.4. Analyse des données d'ouvrages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par importer le fichier de données d'ouvrages et renommons les colonnes pour qu'elles soient plus facile à traiter. Le fichier concerné est _ouvrages-surverses.csv_. Pour plus d'informations sur ce jeu de données: http://donnees.ville.montreal.qc.ca/dataset/ouvrage-surverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `names!(df::AbstractDataFrame, vals::Vector{Symbol}; makeunique::Bool=false)` is deprecated, use `rename!(df, vals, makeunique=makeunique)` instead.\n",
      "│   caller = top-level scope at In[267]:3\n",
      "└ @ Core In[267]:3\n"
     ]
    }
   ],
   "source": [
    "ouvrages = CSV.read(\"data/ouvrages-surverses.csv\");\n",
    "colnames = [\"N_ENV\", \"ID_SOMA\", \"ID_OUVRAGE\", \"NOM\", \"SOMA_SEC\", \"REGION\", \"TP_X\", \"TP_Y\", \"TP_Z\", \"TP_LAT\", \"TP_LNG\", \"EMI_X\", \"EMI_Y\", \"EMI_LNG\", \"EMI_LAT\"];\n",
    "names!(ouvrages, Symbol.(colnames));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4.1.\"></a>\n",
    "#### 2.4.1. Données discrètes\n",
    "\n",
    "Tout d'abord, procédons à une analyse des données discrètes des ouvrages. Les données discrètes de ce jeu de données sont:\n",
    "\n",
    "- N_ENV: Identifiant de l'ouvrage Environnement Canada.\n",
    "- ID_SOMA: Identifiant de l'ouvrage selon SOMAEU (Gouvernement du Québec).\n",
    "- ID_OUVRAGE: Identifiant de l'ouvrage selon la ville.\n",
    "- NOM: Nom de l'ouvrage.\n",
    "- SOMA_SEC: Nom du secteur SOMAEU où se trouve l'ouvrage.\n",
    "- REGION: Nom de la région (arrondissement ou municipalité) où se trouve l'ouvrage.\n",
    "\n",
    "Analysons brièvement chacune de ces variables afin de déterminer si elles pourraient jouer le rôle de variable explicative dans notre situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*N_ENV, ID_SOMA, ID_OUVRAGE, NOM:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_first(ouvrages, 10, [:N_ENV, :ID_SOMA, :ID_OUVRAGE, :NOM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, chaque ouvrage possède une valeur unique pour ces colonnes. Celà fait du sens, compte tenu qu'il s'agit d'un identifiant unique à l'ouvrage, exprimé sous plusieurs normes.\n",
    "<br>\n",
    "\n",
    "En raison du faible pouvoir prédictif d'une telle propriété, dûe à l'unicité de chaque valeur, et de la haute corrélation entre les variables, nous avons décidé de ne pas inclure ces variables dans notre modèle. Nous conservons évidemment l'identifiant de l'ouvrage (_ID_OUVRAGE_) qui va permettre d'identifier chaque ouvrage et de joindre plusieurs jeux de données ensemble, mais les autres ne semblent pas posséder de pouvoir prédictif significatif.\n",
    "<br>\n",
    "\n",
    "Il est à noter que le numéro contenu dans _N_ENV_ et _ID_SOMA_, ainsi que les 3 lettres dans _ID_SOMA_ pourraient tous deux permettrent de grouper certains ouvrages ensembles ou de les localiser dans une carte, mais d'autres variables explicatives abordées à la section [2.4.1. Données discrètes](#2.4.1.) et [2.4.2. Données de Trop-Plein](#2.4.2.) s'occupent déjà de cette localisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SOMA_SEC, REGION_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons maintenant les effets de ces deux variables discrètes. Tout d'abord, le secteur selon la norme SOMAEU. Visualisons la carte de Montréal selon les positions de Trop-Pleins, identifiant le secteur SOMAEU par couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages,x=:TP_LNG, y=:TP_LAT, Geom.point, color= :SOMA_SEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, la majorité des ouvrages sont groupés sous le secteur _OMAEU de Montreal (Station Jean-R.-Marcotte_). Ce problème d'imbalancement de classes pourrait s'avérer problématique. Effectuons maintenant la même tâche pour la séparation de secteurs selon leur arrondissement ou municipalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages,x=:TP_LNG, y=:TP_LAT, Geom.point, color= :REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les secteurs sont beaucoups mieux balancés. Cette variable explicative permet de grouper ensemble un certain nombres d'ouvrages, ce qui pourrait s'avérer utile pour la prédiction.\n",
    "\n",
    "On remarque cependant que certaines régions ne contiennent que très peu d'ouvrages. Il pourrait être intéressant de grouper ensemble des régions contigues afin d'obtenir un nombre d'ouvrage par région plus balancé encore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4.2.\"></a>\n",
    "#### 2.4.2. Données de trop-plein\n",
    "\n",
    "Passons maintenant à l'analyse des données de trop-plein. Nous avons ici 5 variables explicatives pour le trop-plein.\n",
    "\n",
    "- TP_X: Coordonnée en X selon la norme NAD83 MTM8.\n",
    "- TP_Y: Coordonnée en Y selon la norme NAD83 MTM8\n",
    "- TP_Z: Coordonnée en Z selon la norme NAD83 MTM8.\n",
    "- TP_LNG: Longitude selon la norme WGS84.\n",
    "- TP_LAT: Latitude selon la norme WGS84.\n",
    "\n",
    "Pour ce qui est de l'interprétation des trops-pleins, bien que nous ayons eu certaines difficultés à correctement interpréter le sens de ce terme en comparaison avec les émissaires, comme discuté dans la section [5.3. Difficultés rencontrées](#5.3.), des recherches plus poussées en ligne nous ont guidé vers le sens du trop-plein dans ce contexte: Il s'agit ici de l'ouvrage qui permet aux eaux non dirigées vers la station d'épuration d'être évacuées vers le milieu récepteur naturel<sup>[[1]](#refs)</sup>. \n",
    "\n",
    "Les couples de coordonnées [X, Y] et [LNG, LAT] semblent redondantes, testons cette hypothèse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TP_X, TP_Y, TP_LNG, TP_LAT:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_x_y = plot(ouvrages, x=:TP_X, y=:TP_Y, Geom.point);\n",
    "plt_lng_lat = plot(ouvrages, x=:TP_LNG, y=:TP_LAT, Geom.point);\n",
    "hstack(plt_x_y, plt_lng_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir sur les graphiques, ces données sont en effet plutôt similaires et mappent toutes les deux le contour de l'Ile de Montréal, où sont situés les Trop-Pleins. Nous avons choisi de ne garder pour l'instant que les latitudes et longitudes, ce format étant consistent avec les données présentes dans un autre jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TP_Z:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons maintenant la répartition des hauteurs de trop-plein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrages, x=:TP_Z, Geom.histogram(bincount=50), Guide.xlabel(\"Hauteur de trop-plein\"),Guide.ylabel(\"Fréquence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une analyse sur les données de hauteur nous informent que cette information est manquante pour une partie des ouvrages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(ouvrages[!, :TP_Z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, environ 10% des données sont manquantes. Une solution à ce problème est proposée dans la section [3. Traitement des données](#3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4.3.\"></a>\n",
    "#### 2.4.3. Données d'emissaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluons l'analyse des données d'ouvrages avec les variables concernant l'émissaire. Selon la description des données accompagnant le jeu de données sur le site de Montréal, le positionnement géographique des ouvrages de débordement est associé aux émissaires dans cet ensemble de données<sup>[[2]](#refs)</sup>. \n",
    "\n",
    "Encore une fois, ces coordonnées sont présentes selon les deux normes, avec le couple [X,Y] ou le couple [LNG, LAT]. Nous choisissons le second afin de rester consistent avec nos autres choix jusqu'à présent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces données contiennent des valeurs manquantes, comme l'indique la description des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(ouvrages[!, :EMI_LNG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(ouvrages[!, :EMI_LAT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela correspond aux indications présentes sur le site web. Le traitement des données manquantes sera abordé dans la section [3. Traitement des données](#3.). Pour l'instant, nous allons ignorer les données manquantes afin d'observer le graphique des émissaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emi_lng_no_missing = collect(skipmissing(ouvrages[!, :EMI_LNG]));\n",
    "emi_lat_no_missing = collect(skipmissing(ouvrages[!, :EMI_LAT]));\n",
    "plot(x=emi_lng_no_missing, y=emi_lat_no_missing, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, la forme ressemble fortement à celle obtenue avec les données de trop-pleins. Stackons les deux pour voir la différence et comparons verticalement le résultat lorsque chacun est par dessus l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_first_emi = plot(layer(ouvrages, x=:TP_LNG, y=:TP_LAT, Geom.point, order=1, Theme(default_color=colorant=\"orange\")),\n",
    "     layer(x=emi_lng_no_missing, y=emi_lat_no_missing, Geom.point, order=2, Theme(default_color=colorant=\"blue\")),\n",
    "     Guide.title(\"Émissaire par dessus\"), Guide.xlabel(nothing),Guide.ylabel(nothing));\n",
    "\n",
    "emi_first_tp = plot(layer(ouvrages, x=:TP_LNG, y=:TP_LAT, Geom.point, order=2, Theme(default_color=colorant=\"orange\")),\n",
    "     layer(x=emi_lng_no_missing, y=emi_lat_no_missing, Geom.point, order=1, Theme(default_color=colorant=\"blue\")),\n",
    "     Guide.title(\"Trop-plein par dessus\"), Guide.xlabel(nothing),Guide.ylabel(nothing));\n",
    "\n",
    "hstack(tp_first_emi, emi_first_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, ces coordonnées sont assez semblables. Utiliser les deux dans notre modèle pourrait donc entrainer des problèmes de corrélation. Nous avons, pour la majorité du temps de travail, utilisé les coordonnées de trop-pleins afin d'effectuer nos prédictions, n'utilisant donc pas les données d'émissaires dans notre modèle. Ce choix provient du fait que les données d'émissaires sont parfois manquantes (10% du temps).\n",
    "<br>\n",
    "\n",
    "Une autre approche utilisée récemment nous permet de ne pas avoir à choisir entre les deux et de ne pas utiliser de données géographiques. Cette approche sera discutée dans la section [2.7. Isolation des ouvrages d'intérêts](#2.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5.\"></a>\n",
    "### 2.5. Analyse des données de précipitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5.1.\"></a>\n",
    "#### 2.5.1. Données de précipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons à l'analyse des données de précipitations à certaines stations pluviométrique. Nous devons effectuer des fonctions d'aggrégation sur ce tableau avant de pouvoir l'intégré dans notre jeu de donnée de nos modèles. En effet, ce tableau contient les données de précipitation par heure pour chacune des cinqs stations météorologiques près de montréal. Cependant, notre jeu de données des features est seulement par jour. Nous allons donc applique 3 fonctions d'aggrégation différente, soit : Somme, Maximum et Maximum3h. \n",
    "\n",
    "Ce jeu de données a été préparé par notre professeur à partir des données météos d'environnement Canada<sup>[[3]](#refs)</sup> et contient la date sous le format yyyy-mm-jj, l'heure, ainsi que la quantité de pluie au dixième de millimètre pour chacune des cinqs stations pluviométriques suivante :\n",
    "- McTavish (7024745)\n",
    "- Ste-Anne-de-Bellevue (702FHL8)\n",
    "- Montreal/Pierre Elliott Trudeau Intl (702S006)\n",
    "- Montreal/St-Hubert (7027329)\n",
    "- L’Assomption (7014160)\n",
    "\n",
    "Les dates contenues dans ce dataset comprennent les années 2013 à 2019. Par contre, nous devons entraîner notre modèle sur les années avant 2019, et prédire sur toute l'année 2019 (de mai à octobre). Il est donc important de noter que cette table contient des données de l'ensemble d'entraînement et de test.\n",
    "\n",
    "Commençons par importer les données de précipitations et renommer la colonne St-Hubert afin qu'elle soit plus facile à traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitations, Symbol(\"St-Hubert\")=>:StHubert);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne sommes intéressés que par les mois de Mai à Octobre, inclusivement. Analysons les valeurs associés à ce lapse de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>5 rows × 7 columns</p><tr><th>1</th><td>2018-05-01</td><td>21</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>2014-06-04</td><td>23</td><td>missing</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>2013-07-12</td><td>23</td><td>0</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr><tr><th>4</th><td>2016-06-08</td><td>18</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>2019-10-28</td><td>3</td><td>2</td><td>missing</td><td>missing</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2018-05-01 & 21 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t2 & 2014-06-04 & 23 &  & 0 & 0 & 0 & 0 \\\\\n",
       "\t3 & 2013-07-12 & 23 & 0 & 0 & 0 & 0 &  \\\\\n",
       "\t4 & 2016-06-08 & 18 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\t5 & 2019-10-28 & 3 & 2 &  &  & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2018-05-01 │ 21    │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 2   │ 2014-06-04 │ 23    │ \u001b[90mmissing\u001b[39m  │ 0        │ 0          │ 0       │\n",
       "│ 3   │ 2013-07-12 │ 23    │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 4   │ 2016-06-08 │ 18    │ 0        │ 0        │ 0          │ 0       │\n",
       "│ 5   │ 2019-10-28 │ 3     │ 2        │ \u001b[90mmissing\u001b[39m  │ \u001b[90mmissing\u001b[39m    │ 0       │"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitations = filter(row -> month(row.date) > 4, precipitations);\n",
    "precipitations = filter(row -> month(row.date) < 11, precipitations);\n",
    "random_first(precipitations, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut l'observer ci-dessous, plusieurs de ces données sont manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Union…</th><th>Type</th></tr></thead><tbody><p>7 rows × 8 columns</p><tr><th>1</th><td>date</td><td></td><td>2013-05-01</td><td></td><td>2019-10-31</td><td>1288</td><td></td><td>Date</td></tr><tr><th>2</th><td>heure</td><td>11.5</td><td>0</td><td>11.5</td><td>23</td><td></td><td></td><td>Int64</td></tr><tr><th>3</th><td>McTavish</td><td>1.42821</td><td>0</td><td>0.0</td><td>2082</td><td></td><td>1585</td><td>Union{Missing, Int64}</td></tr><tr><th>4</th><td>Bellevue</td><td>1.16081</td><td>0</td><td>0.0</td><td>295</td><td></td><td>4010</td><td>Union{Missing, Int64}</td></tr><tr><th>5</th><td>Assomption</td><td>1.40768</td><td>0</td><td>0.0</td><td>326</td><td></td><td>1789</td><td>Union{Missing, Int64}</td></tr><tr><th>6</th><td>Trudeau</td><td>1.21048</td><td>0</td><td>0.0</td><td>366</td><td></td><td>182</td><td>Union{Missing, Int64}</td></tr><tr><th>7</th><td>StHubert</td><td>1.22368</td><td>0</td><td>0.0</td><td>307</td><td></td><td>5206</td><td>Union{Missing, Int64}</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Union… & Union… & Type\\\\\n",
       "\t\\hline\n",
       "\t1 & date &  & 2013-05-01 &  & 2019-10-31 & 1288 &  & Date \\\\\n",
       "\t2 & heure & 11.5 & 0 & 11.5 & 23 &  &  & Int64 \\\\\n",
       "\t3 & McTavish & 1.42821 & 0 & 0.0 & 2082 &  & 1585 & Union\\{Missing, Int64\\} \\\\\n",
       "\t4 & Bellevue & 1.16081 & 0 & 0.0 & 295 &  & 4010 & Union\\{Missing, Int64\\} \\\\\n",
       "\t5 & Assomption & 1.40768 & 0 & 0.0 & 326 &  & 1789 & Union\\{Missing, Int64\\} \\\\\n",
       "\t6 & Trudeau & 1.21048 & 0 & 0.0 & 366 &  & 182 & Union\\{Missing, Int64\\} \\\\\n",
       "\t7 & StHubert & 1.22368 & 0 & 0.0 & 307 &  & 5206 & Union\\{Missing, Int64\\} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "7×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ variable   │ mean    │ min        │ median │ max        │ nunique │\n",
       "│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mAny\u001b[39m        │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m        │ \u001b[90mUnion…\u001b[39m  │\n",
       "├─────┼────────────┼─────────┼────────────┼────────┼────────────┼─────────┤\n",
       "│ 1   │ date       │         │ 2013-05-01 │        │ 2019-10-31 │ 1288    │\n",
       "│ 2   │ heure      │ 11.5    │ 0          │ 11.5   │ 23         │         │\n",
       "│ 3   │ McTavish   │ 1.42821 │ 0          │ 0.0    │ 2082       │         │\n",
       "│ 4   │ Bellevue   │ 1.16081 │ 0          │ 0.0    │ 295        │         │\n",
       "│ 5   │ Assomption │ 1.40768 │ 0          │ 0.0    │ 326        │         │\n",
       "│ 6   │ Trudeau    │ 1.21048 │ 0          │ 0.0    │ 366        │         │\n",
       "│ 7   │ StHubert   │ 1.22368 │ 0          │ 0.0    │ 307        │         │"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(precipitations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(precipitations[!, :McTavish])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La stratégie de résolution des données manquantes est discutée dans la section [3. Traitement des données](#3.). Pour l'instant, gardons seulement les données complêtes à des fins d'observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropmissing!(precipitations);\n",
    "size(precipitations, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5.2.\"></a>\n",
    "#### 2.5.2. Somme des précipitations journalières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par obtenir la somme des précipitations dans une journée, par station pluviométrique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>sum, \n",
    "            Bellevue = :Bellevue=>sum,\n",
    "            Assomption = :Assomption=>sum, \n",
    "            Trudeau = :Trudeau=>sum, \n",
    "            StHubert = :StHubert=>sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a beaucoup d'éléments sur ce graphique. Une particularité de Gadfly est qu'il nous permet de choisir les séries à afficher. On peut cliquer donc cliquer sur la station d'intérêt afin de filtrer les résultats. On peut remarquer sur ce graphique que les stations ont des tendances similaires, mais pas totalement identiques. Si nous prennons McTavish et Assomption pour l'année 2016, nous pouvons voir que la majorité des pics se superposent, avec quelques exceptions où des pics plus bas apparaissent seulement pour une station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = filter(row -> year(row.date) == 2016, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable, Guide.title(\"Somme des précipitations des stations météo pour 2016\"), Guide.xlabel(\"Date (j)\"), Guide.ylabel(\"Précipitation (mm 10^-1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait donc, jusqu'à présent, que McTavish reçoive plus de précipitations en moyenne que les autres stations. Voyons si cette tendance se maintient pour les autres années."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = melt(pcp_sum, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.point, color=:variable, Guide.title(\"Somme des précipitations des stations météo de 2013 à 2018\"), Guide.xlabel(\"Date (j)\"),  Guide.ylabel(\"Précipitation (mm 10^-1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tendance semble se conserver, mais l'année 2019 est très différente, beaucoup d'informations sont manquantes. Analysons séparément l'année 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = filter(row -> year(row.date) == 2019, pcp_sum);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable, Guide.title(\"Somme des précipitations des stations météo pour 2019\"), Guide.xlabel(\"Date (j)\"), Guide.ylabel(\"Précipitation (mm 10^-1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, nous ne possédons des données de précipitations que pour la majorité du mois de Mai. En réalité, une analyse de la table de précipitation nous informe que nous possédons les informations couvrant la majorité de l'année pour certaines stations, mais d'autres, comme Bellevue, ne sont couvertes que jusqu'en Mai. Une solution à ce problème sera abordé à la section [3. Traitement des données](#3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5.3.\"></a>\n",
    "#### 2.5.3. Taux horaire maximal des précipitations journalières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons au taux horaire maximal par jour des précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>maximum,\n",
    "            Bellevue = :Bellevue=>maximum, \n",
    "            Assomption = :Assomption=>maximum,\n",
    "            Trudeau = :Trudeau=>maximum,\n",
    "            StHubert = :StHubert=>maximum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation de ces informations pour l'année 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot = filter(row -> year(row.date) == 2016, pcp_max);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable, Guide.title(\"Taux horaire maximal des précipitations pour 2016\"), Guide.xlabel(\"Date (j)\"), Guide.ylabel(\"Précipitation (mm 10^-1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique semble suggérer une tendance similaire à celle que la somme des précipitations journalières nous procure. Le reste des informations étant assez similaires entre la somme et le taux horaire maximal, nous ne montrerons pas de graphes additionels dans cette sous-section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.5.4.\"></a>\n",
    "#### 2.5.4. Taux sur trois heures maximal des précipitations journalières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, voyons le taux sur trois heures maximal des précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max3 = by(precipitations, :date,\n",
    "                McTavish = :McTavish=>maximum3,\n",
    "                Bellevue = :Bellevue=>maximum3,\n",
    "                Assomption = :Assomption=>maximum3,\n",
    "                Trudeau = :Trudeau=>maximum3,\n",
    "                StHubert = :StHubert=>maximum3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation de ces informations pour l'année 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_for_plot = filter(row -> year(row.date) == 2016, pcp_max3);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable, Guide.title(\"Taux maximal sur 3 heures pour 2016\"), Guide.xlabel(\"Date (j)\"), Guide.ylabel(\"Précipitation (mm 10^-1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, nous pouvons voir des positions de pics similaires entre les trois graphiques, avec des hauteurs de pics différentes compte tenu des types de valeurs variables.\n",
    "\n",
    "En effet, la somme des précipitations pour une journée sera toujours supérieure ou égale au taux maximal sur 3h qui lui même sera toujours supérieur ou égal au taux horaire maximal. Démontrons cette hypothèse avec les données pour McTavish en 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_pt = 2018;\n",
    "loc = :McTavish\n",
    "mct_sum = pcp_sum[:,[1,2]]\n",
    "rename!(mct_sum, loc => :Sum);\n",
    "mct_sum = filter(row -> year(row.date) == date_to_pt, mct_sum);\n",
    "\n",
    "mct_max = pcp_max[:,[1,2]]\n",
    "rename!(mct_max,loc => :Max);\n",
    "mct_max = filter(row -> year(row.date) == date_to_pt, mct_max);\n",
    "\n",
    "mct_max3 = pcp_max3[:,[1,2]]\n",
    "rename!(mct_max3,loc => :Max3);\n",
    "mct_max3 = filter(row -> year(row.date) == date_to_pt, mct_max3);\n",
    "\n",
    "df_for_plot = join(mct_sum, mct_max3, on = :date);\n",
    "df_for_plot = join(df_for_plot, mct_max, on = :date);\n",
    "df_for_plot = melt(df_for_plot, :date)\n",
    "\n",
    "\n",
    "plot(df_for_plot, x=:date, y=:value, Geom.line, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.6.\"></a>\n",
    "### 2.6. Analyse des données de surverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.6.1\"></a>\n",
    "#### 2.6.1. Chargement des surverses pour analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous chargeons les données du fichier <i>Surverses.csv</i>. Ce jeu de donnée provient des données ouvertes de Montréal : http://donnees.ville.montreal.qc.ca/dataset/debordement. Le fichier ne correspond pas tout à fait aux données en ligne. Il y a eu des transformations (jointures) apportées par notre professeur. Le fichier est structuré de la sorte:\n",
    "<br>\n",
    "\n",
    "**NO_Ouvrage** : (String) L'idendifiant unique de chacun des ouvrages <br>\n",
    "**Date** : (Date) La date sous le format yyyy-mm-jj de l'observation <br>\n",
    "**Surverse** : (Bool) Si l'ouvrage a surversé à cette date <br>\n",
    "**Raison** : (String) Abréviation de la raison de la surverse. Les options sont variables, Ex:\n",
    "- \"U\" : Urgence;\n",
    "- \"Inconnue\" : La raison est inconnue;\n",
    "- \"TS\" : Déversement par temps sec;\n",
    "- \"P\" : Débordement du à la pluie; \n",
    "- \"N\" : Rejet à la rivière des Prairies;\n",
    "- \"S\" : Rejet au fleuve St-Laurent;\n",
    "\n",
    "Au final, nous ne garderons que les trois premières colonnes. La colonne NO_Ouvrage sera renommé afin d'être consistente avec l'identifiant de l'ouvrage des autres jeux de données. De plus, nous ne garderons que les surverses dûes à la pluie, à un débordement par temps sec ou à une raison inconnue que nous considérerons comme étant dûe à la pluie.\n",
    "\n",
    "Chargeons les données de surverses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\", missingstring=\"-99999\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne gardons que les mois de Mai à Octobre inclusivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservons les surverses dûes à la pluie, au temps sec ou de raison inconnue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "raison = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "surverses[!,:RAISON] = raison;\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données de surverses manquantes sont retirées: On ne peut rien analyser avec celles ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = dropmissing(surverses, disallowmissing=true);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.6.2.\"></a>\n",
    "#### 2.6.2. Lien entre ouvrages et surverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe t'il des ouvrages qui sont plus susceptibles à des surverses que d'autres? C'est ce que nous allons chercher à déterminer dans cette sous-section. Commençons par joindre ces deux jeux de données ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrages_surverses = join(ouvrages, surverses, on =:ID_OUVRAGE);\n",
    "select!(ouvrages_surverses, [:ID_OUVRAGE, :SURVERSE, :TP_LNG, :TP_LAT, :TP_Z]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons si la position des ouvrages influence le nombre de surverses reçues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_surverses_by_ouvrage = by(ouvrages_surverses, :ID_OUVRAGE, \n",
    "    SURVERSE = :SURVERSE => sum,\n",
    "    TP_LNG = :TP_LNG => mean, \n",
    "    TP_LAT = :TP_LAT => mean,\n",
    "    TP_Z = :TP_Z => mean);\n",
    "plot(n_surverses_by_ouvrage, x=:TP_LNG, y=:TP_LAT, Geom.point, color=:SURVERSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À première vue, il seble que la moitié droite de l'Île de Montréal soit plus touchée par des surverses que la moitié gauche. On observe aussi le plus de surverses au croisement milieu de l'Île. La position semble donc influencer la quantité de surverses qu'un ouvrage subit durant l'année. On se rend compte en revanche que c'est principalement la longitude qui joue en rôle dans la quantité de surverses plutôt que la longitude.\n",
    "\n",
    "Ceci n'est évidemment qu'une observation qui semble indiquer une corrélation, mais ne constitue pas une preuve de corrélation. Nous tiendrons néanmoins compte de ce résultat dans notre traitement de données puis dans notre sélection de modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand est il de la hauteur du trop plein? Observons son influence sur la quantité de surverses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropmissing!(n_surverses_by_ouvrage, disallowmissing=true);\n",
    "plot(n_surverses_by_ouvrage, x=:TP_Z, y=:SURVERSE, Geom.hair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrairement à notre intuition, la hauteur ne semble pas jouer un rôle si important sur la quantité de surverses d'un trop-plein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.6.3.\"></a>\n",
    "#### 2.6.3. Lien entre précipitations et surverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouvons maintenant le lien entre le taux de surverses et la quantité de précipitation reçus par les ouvrages. Le facteur commun direct entre les deux est la date, groupons donc ces données par dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par renommer la colonne :date des précipitations afin de pouvoir effectuer la jointure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename!(pcp_sum, :date => :DATE)\n",
    "rename!(pcp_max, :date => :DATE)\n",
    "rename!(pcp_max3, :date => :DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue la jointure et on groupe par date afin de visualiser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum_surverses = join(pcp_sum, surverses, on=:DATE)\n",
    "select!(pcp_sum_surverses, Not([:ID_OUVRAGE]))\n",
    "n_surverses_by_date = by(pcp_sum_surverses, :DATE, \n",
    "                            McTavish = :McTavish => first,\n",
    "                            Bellevue = :Bellevue => first,\n",
    "                            Assomption = :Assomption => first,\n",
    "                            Trudeau = :Trudeau => first,\n",
    "                            StHubert = :StHubert => first,\n",
    "                            SURVERSE = :SURVERSE => sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons l'effet de la quantité de pluie reçus dans une journée à McTavish sur le taux de précipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(n_surverses_by_date, x=:McTavish, y=:SURVERSE, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le remarquer, il existe une relation bien définie entre la quantité de pluie reçue et le nombre de surverses dans une journée.\n",
    "\n",
    "Voyons si ce phénomène est présent pour les autres stations pluviométriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bellevue_plot = plot(n_surverses_by_date, x=:Bellevue, y=:SURVERSE, Geom.point);\n",
    "assomption_plot = plot(n_surverses_by_date, x=:Assomption, y=:SURVERSE, Geom.point);\n",
    "trudeau_plot = plot(n_surverses_by_date, x=:Trudeau, y=:SURVERSE, Geom.point);\n",
    "st_hubert_plot = plot(n_surverses_by_date, x=:StHubert, y=:SURVERSE, Geom.point);\n",
    "gridstack([bellevue_plot assomption_plot; trudeau_plot st_hubert_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que la relation ne soit pas aussi clairement définie partout, il existe toutefois un lien entre la quantité reçue par une station et le nombre de surverses sur l'Île de Montréal. Nous tiendrons compte de cette information lors du traitement des données et de l'entrainement des modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce même évènement devrait se produire pour pcp_max et pcp_max3, étant donné qu'ils sont très corrélés avec pcp_sum. Assurons nous que ce soit le cas avec pcp_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max_surverses = join(pcp_max, surverses, on=:DATE)\n",
    "select!(pcp_max_surverses, Not([:ID_OUVRAGE]))\n",
    "n_surverses_by_date = by(pcp_max_surverses, :DATE, \n",
    "                            McTavish = :McTavish => first,\n",
    "                            Bellevue = :Bellevue => first,\n",
    "                            Assomption = :Assomption => first,\n",
    "                            Trudeau = :Trudeau => first,\n",
    "                            StHubert = :StHubert => first,\n",
    "                            SURVERSE = :SURVERSE => sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprenons la station McTavish pour analyser le phénomène."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(n_surverses_by_date, x=:McTavish, y=:SURVERSE, Geom.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait l'imaginer, le graphe est très similaire à celui du pcp_sum. \n",
    "Afin de garder le rapport concis, nous ne démontrerons pas ce résultat pour les autres stations et pour pcp_max3 ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.7.\"></a>\n",
    "### 2.7. Isolation des ouvrages d'intérêts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.7.1.\"></a>\n",
    "#### 2.7.1. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une approche qui a été prise plus tard dans le processus de développement de notre modèle a été d'isoler nos ouvrages. En effet, nous savons déjà quels ouvrages seront utilisés pour la prédiction finale. Il conviendrait alors de ne se concentrer que sur ces ouvrages dans la création de nos modèles. \n",
    "\n",
    "Ce sujet a été abordé par l'équipe dès la première journée du projet, et rapidement disciminé en faveur d'un entrainement sur toutes les données. Il a finalement été revu et mis en oeuvre dans les derniers jours de rafinement du modèle afin d'améliorer encore plus les résultats. \n",
    "\n",
    "Voici les arguments en faveur de cette approche:\n",
    "- Diminution du nombre de données d'entrées, donc permet un entrainement de modèle plus rapide.\n",
    "- Beaucoup de données d'entrées sont invariables aux ouvrages, ils n'influencent pas les chances de surverses au niveau de l'ouvrage en tel quel. \n",
    "- Permet d'avoir un modèle spécialisé par ouvrage, qui sera probablement plus précis qu'un modèle général.\n",
    "\n",
    "Voici les arguments contre cette approche:\n",
    "- Diminution du nombre de données d'entrées, donc moins d'informations pour rendre notre modèle plus robuste.\n",
    "- Ne serait pas capable de prédire les surverses pour un ouvrage autre que ceux entrainés.\n",
    "\n",
    "À la lumière de ces arguments, nous avons finalement choisi d'isoler nos ouvrages et d'entrainer un modèle par ouvrage. En effet, nous savons quels ouvrages vont être utilisés et ne cherchons pas à prédire les surverses pour d'autres ouvrages dans le cadre de ce devoir. \n",
    "\n",
    "De plus, nous éliminons ainsi un bon nombre de variables explicatives qui ne joue pas un rôle direct dans la prédiction du taux de surverses par ouvrage. Par exemple, la position d'un ouvrage ne change pas et donc cette variable n'explique plus la fluctuation des surverses pour cet ouvrage. Nous pouvons alors nous concentrer sur les seuls éléments qui changent: les données de précipitations.\n",
    "\n",
    "Ce faisant, nous éliminons donc une grande partie de l'effort que nous avons mis dans la conception d'un modèle général, y compris le traitement de certaines qui ne seront alors plus utilisés. Nous expliquerons ce que nous ferons à ce sujet dans la section [3. Traitement des données](#3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.7.2.\"></a>\n",
    "#### 2.7.2. Chargement des données traitées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le but de pouvoir analyser les données de chaque ouvrage d'intérêt séparément, ils sont passés par un processus rafinement qui sera couvert dans la section [3. Traitement des données](#3.). Afin de ne pas polluer la partie analyse du rapport, nous allons directement charger les données qui ont été générées plus tard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons l'ouvrage 3260-01D pour commencer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_3260 = CSV.read(\"data/parsed/ouvrage_3260.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce jeu de données contient les données de précipitation pour les deux stations les plus proches de l'ouvrage, dont la somme et le maximum sur 3h des précipitations, pour chaque jour. \n",
    "\n",
    "De plus, il contient aussi l'information de surverse pour chaque date enregistrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_first(ouvrage_3260, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, FS correspond à _First Station_ et SS correspond à _Second Station_. Les colonnes _dist_ correspond à la distance entre l'ouvrage et la station correspondante. Pour ce qui des données de _sum_ , _max_ et _max3_ , elles sont standardisées avec les données complètes et traitées de toutes les stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.7.3.\"></a>\n",
    "#### 2.7.3. Station la plus proche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant s'il y'a une relation entre les données de précipitation de la station la plus proche et le taux de surverses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_plot = plot(ouvrage_3260, x=:SURVERSE, y=:FS_sum, Geom.boxplot);\n",
    "max_plot = plot(ouvrage_3260, x=:SURVERSE, y=:FS_max, Geom.boxplot);\n",
    "max3_plot = plot(ouvrage_3260, x=:SURVERSE, y=:FS_max3, Geom.boxplot);\n",
    "hstack([sum_plot, max_plot, max3_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait d'après ce graphe en boites que la somme des précipitations est le indice de surverses. Observons le lien entre la somme et le taux maximum pour cet ouvrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ouvrage_3260, x=:FS_sum, y=:FS_max, Geom.point, color=:SURVERSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait l'imaginer, ces deux variables sont très corrélées. Certains modèles ne sont pas affectés par une telle correlation mais d'autres, tel que la régression logistique, peut avoir des difficultés avec une telle corrélation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.7.4.\"></a>\n",
    "#### 2.7.4. Deuxième station la plus proche [TODO: Add image to illustrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La question à se poser maintenant est la suivante: Existe t'il un lien entre la deuxième station la plus proche et le taux de précipitations?\n",
    "\n",
    "En effet, nous avons tout d'abord assumé que seule la station la plus proche d'un ouvrage influençait son taux de précipitation. Cette idée est fausse, car si un ouvrage se trouve à l'intersection de deux stations, et que des précipitations ne touchent qu'une des deux stations, ou en touche une plus que l'autre, l'ouvrage pourrait être affecté.\n",
    "\n",
    "En réalité, un ouvrage pourrait être à l'intersection de plus que deux stations, mais les chances sont très faibles et l'impact sur la prédiction, limité. Nous avons donc décidé de nous limiter aux deux stations les plus proches.\n",
    "\n",
    "Maintenant, il faut tenir compte du fait que ces deux stations n'ont pas le même effet sur l'ouvrage. La station la plus proche est, dans la majorité des cas, celle qui va expliquer le mieux surverses d'un ouvrage. Ainsi, nous diminuons l'impact de la deuxième station par un facteur qui dépends de distance avec l'ouvrage. Plus de détails sur cette modification à la section [3. Traitement des données](#3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons l'impact de la deuxième station par rapport à la première station pour les précipitations de cet ouvrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(ouvrage_3260, x=:FS_sum, y=:SS_sum, Geom.point, color=:SURVERSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique montre une majorité de surverses à l'intersection de ces deux stations, mais aussi lorsque la deuxième station reçoit plus de précipitations que la station la plus proche. Ceci valide notre hypothèse concernant l'influance des autres stations sur le taux de surverses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir la distance entre l'ouvrage et les stations ainsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvrage_3260[1, [:FS_dist, :SS_dist]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième station est donc $ \\frac{0.210769}{0.145981} = 1.44$, soit 44% plus loin de l'ouvrage que la station la plus proche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, afin de ne pas rendre cette section trop longue, nous ne présenterons pas les autres ouvrages ici. Les détails spécifiques à chaque ouvrage seront présentés à la section [3. Traitement des données](#3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.8.\"></a>\n",
    "### 2.8. Retour sur l'analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusion, cette analyse nous a permis de repérer les informations pertinentes à notre projet et d'isoler les variables d'intérêt. Elle nous a aussi permis de détecter les possibles causes d'erreurs et a joué un rôle important pour la tâche subséquente, soit le traitement de ces données. Elle a enfin permis de renforcer ou discréditer certaines hypothèses _a priori_ que nous avions sur les données afin de les incorporer ou les retirer de nos modèles. \n",
    "\n",
    "Cette étape a ainsi constitué la partie la plus longue et fastidieuse de notre projet, mais a grandement servi à l'amélioration de nos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.\"></a>\n",
    "## 3. Traitement des données [TODO: UPDATE TABLE DES MATIERES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1.\"></a>\n",
    "### 3.1. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette section aborde une étape cruciale lors de la mise en oeuvre de notre solution. C'est en effet ici que les données sont modifiées après l'analyse de l'étape précédente afin de servir de base à nos modèles.\n",
    "\n",
    "Le choix adéquat des variables explicatives ainsi que leur rafinement jouent un rôle tout aussi important que le choix du modèle, et va grandement influencer les performances de celui ci. C'est pourquoi nous avons consacré une grande partie de notre temps à traiter et peaufiner les données pour ce projet.\n",
    "\n",
    "De plus, certains modèles ne fonctionnent bien qu'en présence de données traitées d'une certaine manière. Un tel modèle serait, par exemple, la régression logistique, qui fonctionne de manière bien plus efficace lorsque toutes les variables explicatives sont à la même échelle. La régression logisitique, ainsi que la classification bayésienne naive, marchent aussi mieux lorsque les données ne sont pas trop corrélées entre elles. C'est pourquoi il est important de s'assurer ici de bien choisir et structurer nos données avant de les offrir à nos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2.\"></a>\n",
    "### 3.2. Processus de traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons présenter dans cette section les étapes et choix faits pour la préparation et traitements des données d'entrées à nos modèles. Le processus de traitement de données a été le suivant:\n",
    "\n",
    "1. Sélection des données à utiliser\n",
    "2. Modification des données afin d'entrainer les modèles\n",
    "3. Entrainement des modèles et validation\n",
    "4. Détection des problèmes liés aux données\n",
    "5. Correction et amélioration des données\n",
    "\n",
    "Ces étapes ont été répétés en boucle tout au long du projet, en raison du nombre important de variations des modèles sélectionnés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.3.\"></a>\n",
    "### 3.3. Préchargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Remove maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.\"></a>\n",
    "### 3.4. Considérations et étapes retenues [TODO: UPDATE TABLE DES MATIERES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette sous-section, nous présenterons chacune des considérations de traitements de données ainsi que leurs motivations. Pour les considérations qui ont été retenues, nous irons en détails sur leur implémentation pour le modèle final. \n",
    "\n",
    "En effet, bien que chacune de ces considérations ait été implémentée et testée pour entrainer des modèles et effectuer des prédictions, seulement une partie a été utile et donc gardée pour notre modèle final. \n",
    "\n",
    "Afin de ne pas rendre ce rapport plus long que nécessaire, tout en gardant un historique concis du travail effectué, nous expliquerons ici les options de traitements de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.1.\"></a>\n",
    "#### 3.4.1. Normalisation de chacune des colonnes entre 0 et 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première considération a été de normaliser chacune des colonnes entre 0 et 1. Cette modification a été implémentée afin d'uniformiser les données pour la régression logistique car ce modèle est très sensible aux différences d'ordre de grandeur entre les données. Les autres modèles sont beaucoups moins, voir pas du tout, affecté par ces différences.\n",
    "\n",
    "En effet, nos premiers modèles utilisants les informations de positions ( _TP_LNG, TP_LAT_ ), de hauteur ( _TP_Z_ ) et de précipitations ( _PCP_SUM, PCP_MAX, PCP_MAX3_ ) avaient affaire à des ordres de grandeurs très différents.\n",
    "\n",
    "Par exemple, les données de géolocalisations pour la longitude se trouvaient toutes autour de 45.5 $\\pm$ 0.5 tandis que la lattitude tournait autour de -73.5 $\\pm$ 0.5. Les données de précipitations allaient de 0 à 2500, avant traitement, et cette échelle variait d'une colonne de précipitation à une autre. Les hauteurs de trop-plein quant à elles variaient de 9 à 35 mètres en général.\n",
    "\n",
    "L'approche utilisée pour normaliser ces données a été de diviser chaque rangée de chaque colonne par la valeur maximale de cette colonne.\n",
    "\n",
    "Nous avons cependant remplacé par la suite cette approche en faveur de la standardisation des colonnes, qui sera expliquée dans la partie [3.4.3. Standardisation de chacune des colonnes](#3.4.3.). Ainsi, nous ne détaillerons pas les détails d'implémentations de la normalisation des colonnes dans cette sous-section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.2.\"></a>\n",
    "#### 3.4.2. Traitement des données de hauteur manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos premiers modèles utilisant l'information de hauteur des trop-pleins, il était important de ne pas avoir de valeurs manquantes qui pourraient fausser nos résultats. L'approche initiale a été d'assigner la valeur de 0 aux données manquantes, mais a rapidement été remplacé par la moyenne des hauteurs de trop-plein. \n",
    "\n",
    "En effet, il ne fait pas de sens pour un trop-plein d'avoir une hauteur de 0, sachant que la plupart des données se trouvaient autour de 10 à 30m et que les valeurs minimales avant traitement étaient de 9. La moyenne de 19.32 permettait de ne pas trop diverger de cette zone lors de nos prédictions.\n",
    "\n",
    "En revanche, le modèle retenu étant celui des ouvrages isolés, les données de trop-plein qui sont invariables à chaque ouvrage n'étaient plus pertinentes. Ainsi, ce traitement n'a pas été retenu pour notre modèle final et son implémentation ne sera pas détaillé ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.3.\"></a>\n",
    "#### 3.4.3. Standardisation de chacune des colonnes [TODO: EXPLIQUER RAISON]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La standardisation des colonnes a été utilisée à la place de la normalisation de celles ci en raison de **TODO**. \n",
    "\n",
    "Cette standardisation s'est avérée très utile lors de la réalisation de nos premières prédictions qui utilisaient des modèles entrainés sur l'ensemble des données. En revanche, nos prédictions subséquentes ont été réalisées avec des modèles spécialisés par ouvrage qui utilisaient des données relativement uniformes en ordre de grandeur. \n",
    "\n",
    "L'intérêt de la standardisation s'est donc vu grandement atténué. Il n'en reste qu'aucun des modèles utilisés ne souffre d'une telle standardisation et que celle ci pourrait s'avérer à nouveau utile si nous nous étions retrouvés à ajouter des données d'échelles différentes à nos modèles. De plus, le coût de standardisation était faible et celui ci n'est ajouté que lorsque des changements au traitement de données sont effectués. Nous avons donc décidé de conserver cette étape. \n",
    "\n",
    "Pour chacune des colonnes contenant des valeurs continues dans nos données de prédiction, nous effectuons la modification suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standardize_col (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardize_col(col)\n",
    "    mean_col = mean(col);\n",
    "    std_col = std(col);\n",
    "    \n",
    "    res = (col .- mean_col) ./ std_col;\n",
    "    \n",
    "    return res;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Filtrage des mois de précipitations et surverses [TODO: UPDATE NUMERING FROM HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme abordé puis implémenté dans la section [2. Analyse exploratoire](#2.), nous ne conservons que les données de précipitations et de surverses entre Mai et Octobre. \n",
    "\n",
    "En effet, la très grande majorité des précipitations se produisent durant cette période et c'est aussi à ce moment que la majorité des surverses sont causés par la pluie. En dehors de cette période, la neige constituerait le facteur le plus probable pour une surverse, dans le cas où les données sont manquantes. De plus, nos prédictions s'effectuent sur des données situés entre Mai et Octobre, nous n'avons pas à tenir compte des tendances des autres périodes, qui représentent une incertitude considérable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rechargeons les données de précipitations pour leur traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations = CSV.read(\"data/precipitations.csv\",missingstring=\"-99999\");\n",
    "rename!(precipitations, Symbol(\"St-Hubert\")=>:StHubert);\n",
    "precipitations = filter(row -> month(row.date) > 4, precipitations);\n",
    "precipitations = filter(row -> month(row.date) < 11, precipitations);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.5.\"></a>\n",
    "#### 3.4.5. Traitement des données de précipitations abérantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La description des données de précipitations semble indiquer des valeurs maximales assez élevées par rapport à la moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Union…</th><th>Type</th></tr></thead><tbody><p>7 rows × 8 columns</p><tr><th>1</th><td>date</td><td></td><td>2013-05-01</td><td></td><td>2019-10-31</td><td>1288</td><td></td><td>Date</td></tr><tr><th>2</th><td>heure</td><td>11.5</td><td>0</td><td>11.5</td><td>23</td><td></td><td></td><td>Int64</td></tr><tr><th>3</th><td>McTavish</td><td>1.42821</td><td>0</td><td>0.0</td><td>2082</td><td></td><td>1585</td><td>Union{Missing, Int64}</td></tr><tr><th>4</th><td>Bellevue</td><td>1.16081</td><td>0</td><td>0.0</td><td>295</td><td></td><td>4010</td><td>Union{Missing, Int64}</td></tr><tr><th>5</th><td>Assomption</td><td>1.40768</td><td>0</td><td>0.0</td><td>326</td><td></td><td>1789</td><td>Union{Missing, Int64}</td></tr><tr><th>6</th><td>Trudeau</td><td>1.21048</td><td>0</td><td>0.0</td><td>366</td><td></td><td>182</td><td>Union{Missing, Int64}</td></tr><tr><th>7</th><td>StHubert</td><td>1.22368</td><td>0</td><td>0.0</td><td>307</td><td></td><td>5206</td><td>Union{Missing, Int64}</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Union… & Union… & Type\\\\\n",
       "\t\\hline\n",
       "\t1 & date &  & 2013-05-01 &  & 2019-10-31 & 1288 &  & Date \\\\\n",
       "\t2 & heure & 11.5 & 0 & 11.5 & 23 &  &  & Int64 \\\\\n",
       "\t3 & McTavish & 1.42821 & 0 & 0.0 & 2082 &  & 1585 & Union\\{Missing, Int64\\} \\\\\n",
       "\t4 & Bellevue & 1.16081 & 0 & 0.0 & 295 &  & 4010 & Union\\{Missing, Int64\\} \\\\\n",
       "\t5 & Assomption & 1.40768 & 0 & 0.0 & 326 &  & 1789 & Union\\{Missing, Int64\\} \\\\\n",
       "\t6 & Trudeau & 1.21048 & 0 & 0.0 & 366 &  & 182 & Union\\{Missing, Int64\\} \\\\\n",
       "\t7 & StHubert & 1.22368 & 0 & 0.0 & 307 &  & 5206 & Union\\{Missing, Int64\\} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "7×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ variable   │ mean    │ min        │ median │ max        │ nunique │\n",
       "│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mAny\u001b[39m        │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m        │ \u001b[90mUnion…\u001b[39m  │\n",
       "├─────┼────────────┼─────────┼────────────┼────────┼────────────┼─────────┤\n",
       "│ 1   │ date       │         │ 2013-05-01 │        │ 2019-10-31 │ 1288    │\n",
       "│ 2   │ heure      │ 11.5    │ 0          │ 11.5   │ 23         │         │\n",
       "│ 3   │ McTavish   │ 1.42821 │ 0          │ 0.0    │ 2082       │         │\n",
       "│ 4   │ Bellevue   │ 1.16081 │ 0          │ 0.0    │ 295        │         │\n",
       "│ 5   │ Assomption │ 1.40768 │ 0          │ 0.0    │ 326        │         │\n",
       "│ 6   │ Trudeau    │ 1.21048 │ 0          │ 0.0    │ 366        │         │\n",
       "│ 7   │ StHubert   │ 1.22368 │ 0          │ 0.0    │ 307        │         │"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(precipitations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction permet de traiter les valeurs manquantes pour la somme des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_with_missing (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sum_with_missing(col)\n",
    "    somme = 0;\n",
    "    for i=1:size(col, 1)\n",
    "        if !isequal(col[i], missing)\n",
    "            somme += col[i];\n",
    "        end\n",
    "    end\n",
    "    return somme;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphe suivant permet d'observer ce phénomène, avec la station McTavish comme example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_per_day = by(precipitations, :date,\n",
    "                            McTavish= :McTavish => sum_with_missing,\n",
    "                            Bellevue= :Bellevue => sum_with_missing,\n",
    "                            Assomption= :Assomption => sum_with_missing,\n",
    "                            Trudeau= :Trudeau => sum_with_missing,\n",
    "                            StHubert= :StHubert => sum_with_missing);\n",
    "precipitations_to_plot = melt(precipitations_per_day, :date)\n",
    "plot(precipitations_to_plot, x=:date, y=:value, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, certaines données sont bien au dessus de la moyenne. Prenons les valeurs abérantes au dessus de 2000 pour McTavish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>1 rows × 7 columns</p><tr><th>1</th><td>2013-10-10</td><td>13</td><td>2082</td><td>0</td><td>0</td><td>0</td><td>missing</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-10-10 & 13 & 2082 & 0 & 0 & 0 &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-10-10 │ 13    │ 2082     │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_outliers = precipitations[!, :McTavish] .> 2000;\n",
    "idx_outliers[isequal.(idx_outliers, missing)] .= false;\n",
    "idx_outliers = convert(Array{Bool, 1}, idx_outliers);\n",
    "\n",
    "date_outlier = precipitations[idx_outliers, :date];\n",
    "precipitations[idx_outliers, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une seule date contient la valeur au dessus de 2000, quand est il des autres stations à cette date? Les autres stations ne rapportent pas de précipitations à cette date là. Y'a t'il eu des surverses dans nos ouvrages d'intérets, le 10 Octobre 2013?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>DATE</th><th>SURVERSE</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th></tr></thead><tbody><p>4 rows × 3 columns</p><tr><th>1</th><td>3260-01D</td><td>2013-10-10</td><td>0</td></tr><tr><th>2</th><td>4240-01D</td><td>2013-10-10</td><td>0</td></tr><tr><th>3</th><td>4350-01D</td><td>2013-10-10</td><td>0</td></tr><tr><th>4</th><td>4380-01D</td><td>2013-10-10</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ID\\_OUVRAGE & DATE & SURVERSE\\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3260-01D & 2013-10-10 & 0 \\\\\n",
       "\t2 & 4240-01D & 2013-10-10 & 0 \\\\\n",
       "\t3 & 4350-01D & 2013-10-10 & 0 \\\\\n",
       "\t4 & 4380-01D & 2013-10-10 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "4×3 DataFrame\n",
       "│ Row │ ID_OUVRAGE │ DATE       │ SURVERSE │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────┼────────────┼────────────┼──────────┤\n",
       "│ 1   │ 3260-01D   │ 2013-10-10 │ 0        │\n",
       "│ 2   │ 4240-01D   │ 2013-10-10 │ 0        │\n",
       "│ 3   │ 4350-01D   │ 2013-10-10 │ 0        │\n",
       "│ 4   │ 4380-01D   │ 2013-10-10 │ 0        │"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_ouvrages = [\"3260-01D\", \"3350-07D\", \"4240-01D\", \"4350-01D\", \"4380-01D\"];\n",
    "filter(row -> row.DATE == date_outlier[1] && row.ID_OUVRAGE ∈ important_ouvrages, surverses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visiblement, il y'a pas eu de surverses à cette date là, remplaçons donc cette donnée par 0 afin qu'elle n'induise pas en erreur notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>date</th><th>heure</th><th>McTavish</th><th>Bellevue</th><th>Assomption</th><th>Trudeau</th><th>StHubert</th></tr><tr><th></th><th>Date</th><th>Int64</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th><th>Int64⍰</th></tr></thead><tbody><p>1 rows × 7 columns</p><tr><th>1</th><td>2013-10-10</td><td>13</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& date & heure & McTavish & Bellevue & Assomption & Trudeau & StHubert\\\\\n",
       "\t\\hline\n",
       "\t& Date & Int64 & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰ & Int64⍰\\\\\n",
       "\t\\hline\n",
       "\t1 & 2013-10-10 & 13 & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1×7 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ date       │ heure │ McTavish │ Bellevue │ Assomption │ Trudeau │\n",
       "│     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m   │ \u001b[90mInt64⍰\u001b[39m     │ \u001b[90mInt64⍰\u001b[39m  │\n",
       "├─────┼────────────┼───────┼──────────┼──────────┼────────────┼─────────┤\n",
       "│ 1   │ 2013-10-10 │ 13    │ 0        │ 0        │ 0          │ 0       │"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitations[idx_outliers, :McTavish] .= 0;\n",
    "precipitations[idx_outliers, :StHubert] .= 0;\n",
    "precipitations[idx_outliers, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plus grosse donnée abérante a été résolue, regardons le graphique de précipitations à nouveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_per_day = by(precipitations, :date,\n",
    "                            McTavish= :McTavish => sum_with_missing,\n",
    "                            Bellevue= :Bellevue => sum_with_missing,\n",
    "                            Assomption= :Assomption => sum_with_missing,\n",
    "                            Trudeau= :Trudeau => sum_with_missing,\n",
    "                            StHubert= :StHubert => sum_with_missing);\n",
    "precipitations_to_plot = melt(precipitations_per_day, :date)\n",
    "plot(precipitations_to_plot, x=:date, y=:value, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons combien de données au dessus de 200 on obtient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_outliers = precipitations[!, :McTavish] .>= 200;\n",
    "idx_outliers[isequal.(idx_outliers, missing)] .= false;\n",
    "idx_outliers = convert(Array{Bool, 1}, idx_outliers);\n",
    "\n",
    "date_outlier = precipitations[idx_outliers, :date];\n",
    "precipitations[idx_outliers, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe 7 valeurs au dessus de 200 pour 29,327 entrées. La partie qui suit est assez arbitraire: Nous regardons chacune des 7 dates au dessus de 240 et vérifions s'il y a surverse, si ce n'est pas le cas, nous enlevons les surverses abérantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations[precipitations.date .== Date(2013, 7, 17), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous pouvons voir que le 240 apparait de nul part, et constitue une valeur extrèmes de précipitations. Il n'a pas plu de la journée et d'un coup, 240 mm d'eau s'est déversé sur la station. Bien que cela reste possible, s'il n'y a pas eu de surverses à cette journée là, il est peu probable que cette donnée soit utile à notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(row -> row.DATE == Date(2013, 7, 17) && row.ID_OUVRAGE ∈ important_ouvrages, surverses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme il y a eu surverse, il est fort probable que le haut taux de pluie à cette journée ait eu lieu et ait causé la surverse, nous ne toucherons donc pas à cette donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répétons le processus pour chacun des autres ouvrages, et éliminons les données abérantes qui ne causent pas de surverses. Les étapes sont les mêmes que pour précédemment, nous éviterons donc de les redétailler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations[precipitations.date .== Date(2017, 7, 20), :Bellevue] .= 0;\n",
    "precipitations[precipitations.date .== Date(2017, 7, 20), :Trudeau] .= 0; # VOIR SI GARDER LUI\n",
    "\n",
    "precipitations[precipitations.date .== Date(2013, 6, 24), :Assomption] .= 0;\n",
    "precipitations[precipitations.date .== Date(2014, 8, 5), :Assomption] .= 0;\n",
    "precipitations[precipitations.date .== Date(2015, 6, 10), :Assomption] .= 0;\n",
    "precipitations[precipitations.date .== Date(2018, 7, 26), :Trudeau] .= 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, nous avons éliminé toutes les précipitations hors du commun ne menant pas à des surverses. Celles ci sont probablement dûes à des erreurs de mesure, ou autres, mais dans tous les cas faussent nos résultats. Cette approche reste tout de fois très arbitraire et sera discuté dans la section [5.3. Améliorations possibles](#5.3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Traitement des données de précipitations manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données _precipitations.csv_ possédait aussi un nombre considérable de données manquantes. Il fallait alors trouver une solution pour travailler avec ces données en limitant la perte d'informations.\n",
    "\n",
    "Certaines journées étaient entièrement dépourvues de données de précipitations pour une station. L'approche utilisée à donc été d'assigner un taux de précipitation nul à ces journées. Une amélioration possible sera abordé à la section [5.3. Améliorations possibles](#5.3.). \n",
    "\n",
    "Pour les journées possédant des certaines valeurs manquantes mais pas toutes, nous prennons la moyenne du reste des valeurs de la journée pour la station concernée, et l'appliquons à chacune des valeurs manquantes. La plupart du temps, ces valeurs sont de 0 ou proche, la moyenne générale de chaque station n'est donc pas tant affectée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante permet de trouver la moyenne de précipitation d'une journée contenant des valeurs manquantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_wo_missing (generic function with 1 method)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean_wo_missing(col)\n",
    "    mean = 0;\n",
    "\n",
    "    for i=1:size(col, 1)\n",
    "        if !isequal(col[i, 1], missing)\n",
    "            mean += col[i, 1]\n",
    "        end\n",
    "    end\n",
    "    mean = mean ÷ size(col, 1)\n",
    "    return mean;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons cette fonction à nos données de précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_by_day = by(precipitations, :date,  \n",
    "                            McTavish = :McTavish=>mean_wo_missing, \n",
    "                            Bellevue = :Bellevue=>mean_wo_missing, \n",
    "                            Assomption = :Assomption=>mean_wo_missing,\n",
    "                            Trudeau = :Trudeau=>mean_wo_missing,\n",
    "                            StHubert = :StHubert=>mean_wo_missing)\n",
    "\n",
    "for i=1:size(precipitations,1)\n",
    "    if isequal(precipitations[i, :McTavish], missing)\n",
    "        precipitations[i,:McTavish] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:McTavish][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Bellevue], missing)\n",
    "        precipitations[i,:Bellevue] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Bellevue][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Assomption], missing)\n",
    "        precipitations[i,:Assomption] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Assomption][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :Trudeau], missing)\n",
    "        precipitations[i,:Trudeau] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:Trudeau][1]\n",
    "    end\n",
    "    if isequal(precipitations[i, :StHubert], missing)\n",
    "        precipitations[i,:StHubert] = filter(row-> row.date == precipitations[i,:date], precipitation_by_day)[!,:StHubert][1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons maintenant les données de précipitations, après traitement de données abérantes et manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_per_day = by(precipitations, :date,\n",
    "                            McTavish= :McTavish => mean,\n",
    "                            Bellevue= :Bellevue => mean,\n",
    "                            Assomption= :Assomption => mean,\n",
    "                            Trudeau= :Trudeau => mean,\n",
    "                            StHubert= :StHubert => mean);\n",
    "precipitations_to_plot = melt(precipitations_per_day, :date)\n",
    "plot(precipitations_to_plot, x=:date, y=:value, color=:variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce jeu de données semble maintenant près à être utilisé pour la suite du processus de traitement de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.5.\"></a>\n",
    "#### 3.4.5. Traitement des données de surverses manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ce qui concerne les surverses, nous éliminons toutes les entrées qui ne contiennent pas des informations de surverses, ainsi que toutes celles en dehors de la période de Mai à Octobre.\n",
    "\n",
    "En effet, nous ne sommes intéressés que par les données qui vont servir à effectuer une prédiction et la variable de surverse constitue l'élément à prédire par nos modèles dans un contexte d'apprentissage supervisé. Il n'est donc pas possible d'entrainer, dans ce même contexte, un modèle sans cette variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, comme expliqué à la section [2. Analyse exploratoire](#2.), nous ne considèrerons que les surverses dûes à la précipitations dans ce projet. Voici le code qui permet de nettoyer nos données de surverses, déjà employé à la section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "surverses = CSV.read(\"data/surverses.csv\", missingstring=\"-99999\");\n",
    "surverses = filter(row -> month(row.DATE) > 4, surverses);\n",
    "surverses = filter(row -> month(row.DATE) < 11, surverses);\n",
    "surverses[!,:RAISON] = coalesce.(surverses[:,:RAISON],\"Inconnue\");\n",
    "\n",
    "surverses = filter(row -> row.RAISON ∈ [\"P\",\"Inconnue\",\"TS\"], surverses);\n",
    "select!(surverses, [:NO_OUVRAGE, :DATE, :SURVERSE]);\n",
    "rename!(surverses, :NO_OUVRAGE => :ID_OUVRAGE);\n",
    "surverses = filter(row -> row.ID_OUVRAGE ∈ important_ouvrages, surverses);\n",
    "dropmissing!(surverses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Ajout de la somme et du taux maximal de précipitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les précipitations étant séparés en heures, plutôt qu'en journées comme le reste des données, nous devons la convertir en ce dernier afin de pouvoir utiliser ces données.\n",
    "\n",
    "Plusieurs stratégies de conversion s'offrent à nous, pour chaque jour, à chaque station, nous pouvons considérer:\n",
    "- La somme des précipitations de la journée\n",
    "- Le taux maximal de précipitations de la journée\n",
    "- La moyenne de précipitations de la journée\n",
    "- Le mode de précipitations de la journée\n",
    "\n",
    "Nous avons décidé d'utiliser les deux premiers, car notre interprétation d'une surverse nous dit que celle ci est généralement causé par un débit inatendu d'eau sur une courte période plutôt qu'un flux continu. Ce choix est cependant arbitraire et constitue une amélioration possible à notre projet, comme discuté à la section [5.3. Améliorations possibles](#5.3.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somme des précipitations quotidiennes par station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_sum = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>sum, \n",
    "            Bellevue = :Bellevue=>sum,\n",
    "            Assomption = :Assomption=>sum, \n",
    "            Trudeau = :Trudeau=>sum, \n",
    "            StHubert = :StHubert=>sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taux horaire maximal de précipitations dans une journée, par station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max = by(precipitations, :date,  \n",
    "            McTavish = :McTavish=>maximum,\n",
    "            Bellevue = :Bellevue=>maximum, \n",
    "            Assomption = :Assomption=>maximum,\n",
    "            Trudeau = :Trudeau=>maximum,\n",
    "            StHubert = :StHubert=>maximum);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie a été discutée à la section [2. Analyse exploiratoire](#2.), et nous n'afficherons pas de graphes ici afin de ne pas dupliquer l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Ajout du taux maximal de précipitation sur 3 heures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partant de l'hypothèse qu'une surverse est causée par un débit inatendu d'eau dans un trop-plein, sur une durée limitée, il est naturel que le taux maximal sur 1h soit considéré. \n",
    "\n",
    "Une autre possibilité serait le taux sur 3h maximal de précipitations, offrant une plus grosse marge. Encore une fois assez arbitraire comme choix, nous avons estimé que celà pourrait s'ajouter comme variable explicative à notre modèle afin d'aider à la prédiction.\n",
    "\n",
    "Il reste que cette donnée est très corrélée avec la somme et le maximum de précipitations, il pourrait donc causer problèmes pour la régression logistique ou la classification bayésienne naive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_max3 = by(precipitations, :date,\n",
    "                McTavish = :McTavish=>maximum3,\n",
    "                Bellevue = :Bellevue=>maximum3,\n",
    "                Assomption = :Assomption=>maximum3,\n",
    "                Trudeau = :Trudeau=>maximum3,\n",
    "                StHubert = :StHubert=>maximum3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction maximum3 a été définie à la section [2.1. Analyse exploratoire] lors de la visualisation de cette donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Conservation des données pour la station la plus proche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite, nous avons supposé que la station la plus proche aurait le plus d'influence sur les surverses d'un ouvrage. Ainsi, nous avons récupéré les localisations géographiques des stations pluviométriques à l'aide d'une recherche internet et bati un DataFrame à partir de celles ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>STATION</th><th>LAT</th><th>LNG</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>McTavish</td><td>45.5047</td><td>-73.5792</td></tr><tr><th>2</th><td>Bellevue</td><td>45.4272</td><td>-73.9292</td></tr><tr><th>3</th><td>Assomption</td><td>45.8094</td><td>-73.4347</td></tr><tr><th>4</th><td>Trudeau</td><td>45.4678</td><td>-73.7417</td></tr><tr><th>5</th><td>StHubert</td><td>45.5175</td><td>-73.4169</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& STATION & LAT & LNG\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & McTavish & 45.5047 & -73.5792 \\\\\n",
       "\t2 & Bellevue & 45.4272 & -73.9292 \\\\\n",
       "\t3 & Assomption & 45.8094 & -73.4347 \\\\\n",
       "\t4 & Trudeau & 45.4678 & -73.7417 \\\\\n",
       "\t5 & StHubert & 45.5175 & -73.4169 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×3 DataFrame\n",
       "│ Row │ STATION    │ LAT     │ LNG      │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m  │\n",
       "├─────┼────────────┼─────────┼──────────┤\n",
       "│ 1   │ McTavish   │ 45.5047 │ -73.5792 │\n",
       "│ 2   │ Bellevue   │ 45.4272 │ -73.9292 │\n",
       "│ 3   │ Assomption │ 45.8094 │ -73.4347 │\n",
       "│ 4   │ Trudeau    │ 45.4678 │ -73.7417 │\n",
       "│ 5   │ StHubert   │ 45.5175 │ -73.4169 │"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df = DataFrame(STATION = String[], LAT = Float64[], LNG = Float64[]);\n",
    "\n",
    "push!(station_df, [\"McTavish\", 45.504742, -73.579167]);\n",
    "push!(station_df, [\"Bellevue\", 45.427222, -73.929167]);\n",
    "push!(station_df, [\"Assomption\", 45.809444, -73.434722]);\n",
    "push!(station_df, [\"Trudeau\", 45.467778, -73.741667]);\n",
    "push!(station_df, [\"StHubert\", 45.5175, -73.416944]);\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, nous avons comparé les longitudes et latitudes de chaque station avec l'ouvrage en cours, afin de déterminer le plus proche. La fonction suivante a été utilisé pour cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findDistance (generic function with 1 method)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findDistance(oLat, oLng, sLat, sLng)\n",
    "    lat = (sLat - oLat) ^ 2;\n",
    "    lng = (sLng - oLng) ^ 2;\n",
    "\n",
    "    return sqrt(lat + lng);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ainsi déterminé la station la plus proche de l'ouvrage en cours, et ajouté à cet ouvrage les données de précipitations de la station (somme, maximum, maximum3). Les détails de l'implémentation ne sont pas ajoutés ici car ils seront couverts dans une autre sous-section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revanche, nous nous sommes rendus compte que la station la plus proche n'était pas le seul facteur qui déterminait le taux de surverse d'un ouvrage. En raison de la nature de la pluie et de sa zone d'effet, un ouvrage peut être touché par la pluie sans que la station la plus proche de celui ci ne le soit. Il peut aussi être plus touché. Observer un autre ouvrage aiderait à obtenir cette information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Conservation des données pour toutes les stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À la lumière de la conclusion obtenue à la sous-section précédente, nous avons par la suite décidé de garder les informations de chaque station (somme, maximum, maximum3), afin d'effectuer nos prédictions par ouvrage.\n",
    "\n",
    "Nos modèles n'étaient en revanche pas tout à fait en mesure de correctement déterminer quel station influençait le plus le taux de surverses d'un ouvrage donné, lorsque les informations de précipitations de plusieurs stations se ressemblaient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Conservation des données pour les deux stations les plus proches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de résoudre les problèmes encontrés dans les deux sous-sections précédentes, nous avons décidé de garder en mémoire pour chaque couple d'ouvrage / date, les informations des deux ouvrages les plus proches. En effet, ce choix, bien qu'arbitraire encore une fois, est un juste milieu entre nos solutions. Il est aussi plus probable qu'un ouvrage se trouve à l'intersection de deux stations et soit touché par une zone de précipitations qu'il ne le soit de trois ou plus et que la précipitation ne touche qu'une seule de ces stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'implémentation de cette section. Tout d'abord, ajoute les colonnes de précipitations à nos surverses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = surverses;\n",
    "\n",
    "train_data[!, :FS_dist] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_dist] = zeros(size(train_data, 1));\n",
    "train_data[!, :FS_sum] = zeros(size(train_data, 1));\n",
    "train_data[!, :FS_max] = zeros(size(train_data, 1));\n",
    "train_data[!, :FS_max3] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_sum] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_max] = zeros(size(train_data, 1));\n",
    "train_data[!, :SS_max3] = zeros(size(train_data, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite, on remplit ces colonnes avec les données des deux stations les plus proches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:size(train_data, 1)\n",
    "    curr_ouvrage = train_data[i, 1];\n",
    "    ouvrage_data = filter(row -> row.ID_OUVRAGE == curr_ouvrage, ouvrages);\n",
    "    \n",
    "    closest_station = nothing;\n",
    "    closest_distance = 9999;\n",
    "    \n",
    "    second_closest_station = nothing;\n",
    "    second_closest_distance = 9999;\n",
    "    \n",
    "    # Pour chaque station\n",
    "    for j=1:5\n",
    "       current_station = station_df[j, :STATION];\n",
    "       dist = findDistance(ouvrage_data[1, :TP_LAT], ouvrage_data[1, :TP_LNG], station_df[j, :LAT], station_df[j, :LNG]);\n",
    "       \n",
    "        if dist < closest_distance\n",
    "            second_closest_distance = closest_distance;\n",
    "            second_closest_station = closest_station;\n",
    "            closest_distance = dist;\n",
    "            closest_station = current_station;\n",
    "        elseif dist < second_closest_distance\n",
    "            second_closest_distance = dist;\n",
    "            second_closest_station = current_station;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    train_data[i, :FS_dist] = closest_distance;\n",
    "    train_data[i, :SS_dist] = second_closest_distance;\n",
    "    \n",
    "    # Add data for first station\n",
    "    sum_p = pcp_sum[∈([train_data[i, :DATE]]).(pcp_sum.date), Symbol(closest_station)];\n",
    "    train_data[i, :FS_sum] = sum_p[1];\n",
    "    max_p = pcp_max[∈([train_data[i, :DATE]]).(pcp_max.date), Symbol(closest_station)];\n",
    "    train_data[i, :FS_max] = max_p[1];\n",
    "    max3_p = pcp_max3[∈([train_data[i, :DATE]]).(pcp_max3.date), Symbol(closest_station)];\n",
    "    train_data[i, :FS_max3] = max3_p[1];\n",
    "    \n",
    "    # Add data for second station\n",
    "    s_sum_p = pcp_sum[∈([train_data[i, :DATE]]).(pcp_sum.date), Symbol(second_closest_station)];\n",
    "    train_data[i, :SS_sum] = s_sum_p[1];\n",
    "    s_max_p = pcp_max[∈([train_data[i, :DATE]]).(pcp_max.date), Symbol(second_closest_station)];\n",
    "    train_data[i, :SS_max] = s_max_p[1];\n",
    "    s_max3_p = pcp_max3[∈([train_data[i, :DATE]]).(pcp_max3.date), Symbol(second_closest_station)];\n",
    "    train_data[i, :SS_max3] = s_max3_p[1];\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons ainsi les données de précipitations des deux stations les plus proches, par ouvrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID_OUVRAGE</th><th>DATE</th><th>SURVERSE</th><th>FS_dist</th><th>SS_dist</th><th>FS_sum</th><th>FS_max</th><th>FS_max3</th></tr><tr><th></th><th>String</th><th>Date</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 11 columns (omitted printing of 3 columns)</p><tr><th>1</th><td>4240-01D</td><td>2017-08-24</td><td>0</td><td>0.149987</td><td>0.168295</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>4240-01D</td><td>2014-06-15</td><td>0</td><td>0.149987</td><td>0.168295</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>4240-01D</td><td>2013-09-16</td><td>0</td><td>0.149987</td><td>0.168295</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>3350-07D</td><td>2017-05-29</td><td>1</td><td>0.0927373</td><td>0.12027</td><td>64.0</td><td>26.0</td><td>53.0</td></tr><tr><th>5</th><td>3350-07D</td><td>2018-06-26</td><td>0</td><td>0.0927373</td><td>0.12027</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& ID\\_OUVRAGE & DATE & SURVERSE & FS\\_dist & SS\\_dist & FS\\_sum & FS\\_max & FS\\_max3 & \\\\\n",
       "\t\\hline\n",
       "\t& String & Date & Int64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 4240-01D & 2017-08-24 & 0 & 0.149987 & 0.168295 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 4240-01D & 2014-06-15 & 0 & 0.149987 & 0.168295 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 4240-01D & 2013-09-16 & 0 & 0.149987 & 0.168295 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 3350-07D & 2017-05-29 & 1 & 0.0927373 & 0.12027 & 64.0 & 26.0 & 53.0 & $\\dots$ \\\\\n",
       "\t5 & 3350-07D & 2018-06-26 & 0 & 0.0927373 & 0.12027 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×11 DataFrame. Omitted printing of 5 columns\n",
       "│ Row │ ID_OUVRAGE │ DATE       │ SURVERSE │ FS_dist   │ SS_dist  │ FS_sum  │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mDate\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼────────────┼────────────┼──────────┼───────────┼──────────┼─────────┤\n",
       "│ 1   │ 4240-01D   │ 2017-08-24 │ 0        │ 0.149987  │ 0.168295 │ 0.0     │\n",
       "│ 2   │ 4240-01D   │ 2014-06-15 │ 0        │ 0.149987  │ 0.168295 │ 0.0     │\n",
       "│ 3   │ 4240-01D   │ 2013-09-16 │ 0        │ 0.149987  │ 0.168295 │ 0.0     │\n",
       "│ 4   │ 3350-07D   │ 2017-05-29 │ 1        │ 0.0927373 │ 0.12027  │ 64.0    │\n",
       "│ 5   │ 3350-07D   │ 2018-06-26 │ 0        │ 0.0927373 │ 0.12027  │ 0.0     │"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_first(train_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes _dist_ correspondent à la distance entre l'ouvrage et la station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.4.\"></a>\n",
    "#### 3.4.4. Mise à l'échelle des données de la seconde station la plus proche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, une autre considération a été de mettre à l'échelle la contribution de la deuxième station la plus proche d'un ouvrage par rapport à la première. \n",
    "\n",
    "Plusieurs approches ont été utilisées avant d'arriver à l'approche qui nous parraissait la plus approprié: Nous avons utilisé une fonction d'adoucicement afin de ne pas trop pénaliser la seconde station. \n",
    "\n",
    "Voici notre raisonnement: \n",
    "- Si une station est deux fois plus loin de l'ouvrage qu'une autre, sa contribution devrait tourner autour de 80% de la première station, plutot que juste 50%. \n",
    "- Si une station est environ aussi loin de l'ouvrage qu'une autre, sa contribution devrait frôler les 100%.\n",
    "- Si une station est beaucoup plus loin, sa contribution devrait diminuer en conséquence.\n",
    "\n",
    "Nous avons ainsi généré les distances des deux stations les plus proches pour les 5 ouvrages d'intérets, et nous avons manuellement généré une fonction qui nous semble appropriée. Encore une fois, comme cette fonction a été générée manuellement selon nos observations et intuitions, elle constitue une potentielle faiblesse de notre modèle à améliorer, comme discutée à la section [5.3. Améliorations possibles](#5.3.).\n",
    "\n",
    "La fonction en question calcule le ratio de distance de la deuxième station par rapport à la première, puis trouve la racine carrée de ce ratio et le passe en argument à un logarithm naturel, ce résultat est ensuite soustrait à un afin d'obtenir la contribution de la seconde station.\n",
    "\n",
    "Contribution = $ 1 - \\ln(\\sqrt(\\frac{seconde closest distance}{closest distance})) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'implémentation de la fonction en question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contribution_second (generic function with 1 method)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function contribution_second(closest_distance, second_closest_distance)\n",
    "    ratio = second_closest_distance / closest_distance;\n",
    "    logratio = log(sqrt(ratio));\n",
    "    return 1 - logratio; \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction est finalement appliquée aux données de précipitations de la deuxième station la plus proche avant d'être ajoutée aux données de l'ouvrage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4.6.\"></a>\n",
    "#### 3.4.6. OneHot des dates pour les mois et jours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, un autre traitement général des données a été de considérer les jours et les mois de l'année comme variable explicative de précipitation.\n",
    "\n",
    "Nous avons donc encodé les mois entre 5 et 10 et les jours de 1 à 31 et passé cette information à notre modèle.\n",
    "\n",
    "Ces données ont aussi dûes être standardisées afin de ne pas causer de problèmes d'échelle pour la régression logistique.\n",
    "\n",
    "Par la suite, nous avons retiré cette variable explicative de notre modèle en raison de son faible pouvoir prédictif par rapport aux autres données. Nous ne détaillerons donc pas ici l'implémentation de ces variables explicatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.5.\"></a>\n",
    "### 3.5. Isolation des ouvrages d'intérêts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu à la section [2.7. Isolation des ouvrages d'intérêts](#2.7.), nous avons décidé de séparer notre jeu de données final en 5 jeux de données, soit un par ouvrage d'intérêt. **TODO: CONTINUER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.5.1.\"></a>\n",
    "#### 3.5.1. Sous-échantillonage de l'ensemble des colonnes d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.5.2.\"></a>\n",
    "#### 3.5.2. Sur-échantillonage de l'ensemble des colonnes d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.\"></a>\n",
    "## 4. Sélection de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.1.\"></a>\n",
    "### 4.1. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que les données sont prêtes à être utilisées, il est temps de passer à l'étape de sélection de modèles. En effet, le choix du ou des modèles est crucial dans le domaine de la prédiction car, selon les données reçues, certains modèles vont mener à des meilleures prédictions. Il est donc primordial de bien déterminer le type de modèle qui serait adapté à notre situation afin d'obtenir les meilleures performances et résultats possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.2.\"></a>\n",
    "### 4.2. Choix des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modèles que nous avons considéré pour cet exercice sont:\n",
    "\n",
    "- Les arbres de décision\n",
    "- La forêt aléatoire\n",
    "- La machine à vecteur de support (SVM)\n",
    "- La régression logistique\n",
    "- La classification bayésienne naive\n",
    "- L'ensemble de modèles\n",
    "\n",
    "Chacun de ces modèles sera présenté dans une sous-section de la section [4. Sélection de modèles](#4.), où les avantages et désavantages du modèle seront présentés. Pour les modèles aillant été retenus, nous allons détailler les notions théoriques sur lesquels reposent ces modèles et comment nous les avons appliqué. Pour les modèles non retenus, nous expliqueront pourquoi ils n'ont pas été retenu en faveur des autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.\"></a>\n",
    "### 4.3. Arbres de décision et forêt aléatoire [TODO: METTRE A JOUR TABLE DES MATIERES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.1.\"></a>\n",
    "#### 4.3.1. Théorie des arbres de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle d'arbres de décision est un algorithme d'apprentissage machine très puissant capable d'effectuer des tâches de classification, mais aussi de régression. Dans notre cas, c'est la partie classification qui nous intéresse ici car nous cherchons à déterminer si une surverse a eu lieu ou pas, selon certaines variables explicatives.\n",
    "\n",
    "Les avantages des arbres de décision sont:\n",
    "- A\n",
    "- B\n",
    "- C\n",
    "\n",
    "Les désavantages des arbres de décision sont:\n",
    "- A\n",
    "- B\n",
    "- C\n",
    "\n",
    "Les arbres de décision agissent sur chaque variable en **TODO: CONTINUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.2.\"></a>\n",
    "#### 4.3.2. Théorie des forêts aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.3.\"></a>\n",
    "#### 4.3.3. Définition des fonctions utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.4.\"></a>\n",
    "#### 4.3.4. Application à l'ensemble de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3.5.\"></a>\n",
    "#### 4.3.5. Application aux ouvrages isolés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.4.\"></a>\n",
    "### 4.4. Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.5.\"></a>\n",
    "### 4.5. Machine à vecteurs de support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.6.\"></a>\n",
    "### 4.6. Classification bayésienne naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.7.\"></a>\n",
    "### 4.7. Ensemble de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.\"></a>\n",
    "## 5. Retour et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3.\"></a>\n",
    "### 5.3. Difficultés rencontrées [TODO: UPDATE TABLE DES MATIÈRES]\n",
    "\n",
    "Lors de cet exercice, nous avons rencontré un certain nombre de difficultés qui nous en ralentit dans la réalisation du projet. Nous allons discuter ici de ces difficultés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3.1.\"></a>\n",
    "#### 5.3.1. Interprétation des données\n",
    "\n",
    "Une des plus grande difficultés de ce projet fut de correctement interpréter les données. En effet, une erreur de notre part fut de confondre la signification d'émissaire et de trop-plein. Ne sachant pas initialement ce que ces termes représentaient, une recherche Google Image nous a mené à penser que le trop-plein était une sorte de conteneur dans lequel l'eau s'accumulait et l'émissaire comme étant le tuyeau de déversement vers le fleuve. \n",
    "<br>\n",
    "\n",
    "Cela nous a ainsi mené à effectuer des suppositions qui s'avéraient erronées et ont faussé nos résultats pendant une bonne partie de l'exercice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3.2.\"></a>\n",
    "#### 5.3.2. Données manquantes de précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3.3.\"></a>\n",
    "#### 5.3.3. Remplacement des données abérantes de précipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3.4.\"></a>\n",
    "#### 5.3.4. Données des journées alentours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3.5.\"></a>\n",
    "#### 5.3.5. Explorer plus de procédés d'aggrégation pour les précipitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: Moyenne ou mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## 6. Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Référence style APA ou IEEE\n",
    "+ [1]: http://collections.banq.qc.ca/ark:/52327/bs44911\n",
    "\n",
    "+ [2]: http://donnees.ville.montreal.qc.ca/dataset/ouvrage-surverse\n",
    "\n",
    "+ [3]: https://climat.meteo.gc.ca/climate_data/hourly_data_f.html?hlyRange=2008-01-08%7C2019-11-12&dlyRange=2002-12-23%7C2019-11-12&mlyRange=%7C&StationID=30165&Prov=QC&urlExtension=_f.html&searchType=stnName&optLimit=yearRange&StartYear=1840&EndYear=2019&selRowPerPage=25&Line=17&searchMethod=contains&Month=11&Day=12&txtStationName=montreal&timeframe=1&Year=2019\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
